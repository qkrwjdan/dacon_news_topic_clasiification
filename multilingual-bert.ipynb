{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fc53b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import BertModel, TFBertModel, BertTokenizer\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccf6e3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_'+string])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d51c5367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random seed 고정\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 3\n",
    "VALID_SPLIT = 0.2\n",
    "MAX_LEN = 40 # EDA에서 추출된 Max Length\n",
    "DATA_IN_PATH = 'data_in/KOR'\n",
    "DATA_OUT_PATH = \"data_out/KOR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8e4aaeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf7f0f851bc74d16baeab9e074a0790d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "575e1678fbeb44618567fa886b88a08c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "064a0e2adbf44cb8a3c3e0f12bb081c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\", cache_dir='bert_ckpt', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3f351ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./data/train_data.csv\")\n",
    "test_data = pd.read_csv(\"./data/test_data.csv\")\n",
    "submission = pd.read_csv(\"./data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c7b0420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_tokenizer(sent, MAX_LEN):\n",
    "    \n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        text = sent,\n",
    "        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "        max_length = MAX_LEN,           # Pad & truncate all sentences.\n",
    "        pad_to_max_length = True,\n",
    "        return_attention_mask = True   # Construct attn. masks.\n",
    "        \n",
    "    )\n",
    "    \n",
    "    input_id = encoded_dict['input_ids']\n",
    "    attention_mask = encoded_dict['attention_mask'] # And its attention mask (simply differentiates padding from non-padding).\n",
    "    token_type_id = encoded_dict['token_type_ids'] # differentiate two sentences\n",
    "    \n",
    "    return input_id, attention_mask, token_type_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b08a66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/45654 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "d:\\workspace\\dacon_news_topic_clasiification\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2126: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 45654/45654 [00:07<00:00, 6323.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sents: 45654, # labels: 45654\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "token_type_ids = []\n",
    "train_data_labels = []\n",
    "\n",
    "for train_sent, train_label in tqdm(zip(train_data[\"title\"], train_data[\"topic_idx\"]), total=len(train_data)):\n",
    "    try:\n",
    "        input_id, attention_mask, token_type_id = bert_tokenizer(train_sent, MAX_LEN)\n",
    "        \n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        train_data_labels.append(train_label)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(train_sent)\n",
    "        pass\n",
    "\n",
    "train_movie_input_ids = np.array(input_ids, dtype=int)\n",
    "train_movie_attention_masks = np.array(attention_masks, dtype=int)\n",
    "train_movie_type_ids = np.array(token_type_ids, dtype=int)\n",
    "train_movie_inputs = (train_movie_input_ids, train_movie_attention_masks, train_movie_type_ids)\n",
    "\n",
    "train_data_labels = np.asarray(train_data_labels, dtype=np.int32) #레이블 토크나이징 리스트\n",
    "\n",
    "print(\"# sents: {}, # labels: {}\".format(len(train_movie_input_ids), len(train_data_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e6cb70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2c292e8ffe4b66a1a48a32ee62b603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb155b3f67040dcb6a83e3bcdf53638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.08G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "class TFBertClassifier(tf.keras.Model):\n",
    "    def __init__(self, model_name, dir_path, num_class):\n",
    "        super(TFBertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = TFBertModel.from_pretrained(model_name, cache_dir=dir_path)\n",
    "        self.dropout = tf.keras.layers.Dropout(self.bert.config.hidden_dropout_prob)\n",
    "        self.classifier = tf.keras.layers.Dense(num_class, \n",
    "                                                kernel_initializer=tf.keras.initializers.TruncatedNormal(self.bert.config.initializer_range), \n",
    "                                                name=\"classifier\")\n",
    "        \n",
    "    def call(self, inputs, attention_mask=None, token_type_ids=None, training=False):\n",
    "        \n",
    "        #outputs 값: # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "        outputs = self.bert(inputs, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs[1] \n",
    "        pooled_output = self.dropout(pooled_output, training=training)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        return logits\n",
    "\n",
    "cls_model = TFBertClassifier(model_name='bert-base-multilingual-cased',\n",
    "                                  dir_path='bert_ckpt',\n",
    "                                  num_class=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2787aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(3e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "cls_model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90b467e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_out/KOR\\tf2_bert_naver_movie -- Folder create complete \n",
      "\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x00000276582FB2E0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x00000276582FB2E0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:From d:\\workspace\\dacon_news_topic_clasiification\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "1142/1142 [==============================] - ETA: 0s - loss: 0.5543 - accuracy: 0.8161WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "1142/1142 [==============================] - 3603s 3s/step - loss: 0.5543 - accuracy: 0.8161 - val_loss: 0.5937 - val_accuracy: 0.7899\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78995, saving model to data_out/KOR\\tf2_bert_naver_movie\\weights.h5\n",
      "Epoch 2/3\n",
      "1142/1142 [==============================] - 3395s 3s/step - loss: 0.3663 - accuracy: 0.8755 - val_loss: 0.5987 - val_accuracy: 0.7789\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.78995\n",
      "Epoch 3/3\n",
      "1142/1142 [==============================] - 3373s 3s/step - loss: 0.2946 - accuracy: 0.8979 - val_loss: 0.5625 - val_accuracy: 0.7973\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.78995 to 0.79728, saving model to data_out/KOR\\tf2_bert_naver_movie\\weights.h5\n",
      "{'loss': [0.5543033480644226, 0.36634501814842224, 0.29456624388694763], 'accuracy': [0.816143274307251, 0.8754757046699524, 0.8979273438453674], 'val_loss': [0.5937450528144836, 0.5987128019332886, 0.5624560117721558], 'val_accuracy': [0.7899463176727295, 0.7788851261138916, 0.7972840070724487]}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"tf2_bert_naver_movie\"\n",
    "\n",
    "# overfitting을 막기 위한 ealrystop 추가\n",
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001,patience=2)\n",
    "# min_delta: the threshold that triggers the termination (acc should at least improve 0.0001)\n",
    "# patience: no improvment epochs (patience = 1, 1번 이상 상승이 없으면 종료)\\\n",
    "\n",
    "checkpoint_path = os.path.join(DATA_OUT_PATH, model_name, 'weights.h5')\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create path if exists\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "    \n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "# 학습과 eval 시작\n",
    "history = cls_model.fit(train_movie_inputs, train_data_labels, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE,\n",
    "                    validation_split = VALID_SPLIT, callbacks=[earlystop_callback, cp_callback])\n",
    "\n",
    "#steps_for_epoch\n",
    "\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "864246b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "291122d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9131it [00:00, 29247.85it/s]\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "token_type_ids = []\n",
    "test_data_labels = []\n",
    "\n",
    "for test_sent in tqdm(zip(test_data[\"title\"])):\n",
    "    try:\n",
    "        input_id, attention_mask, token_type_id = bert_tokenizer(test_sent, MAX_LEN)\n",
    "\n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(test_sent)\n",
    "        pass\n",
    "\n",
    "test_movie_input_ids = np.array(input_ids, dtype=int)\n",
    "test_movie_attention_masks = np.array(attention_masks, dtype=int)\n",
    "test_movie_type_ids = np.array(token_type_ids, dtype=int)\n",
    "test_movie_inputs = (test_movie_input_ids, test_movie_attention_masks, test_movie_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "908fc57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "results = cls_model.predict(test_movie_inputs, batch_size=1024)\n",
    "#results=tf.argmax(results, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6406289",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17396/2654396112.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_movie_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\workspace\\dacon_news_topic_clasiification\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1725\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1726\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1727\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1728\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1729\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\workspace\\dacon_news_topic_clasiification\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\workspace\\dacon_news_topic_clasiification\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    922\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32md:\\workspace\\dacon_news_topic_clasiification\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\workspace\\dacon_news_topic_clasiification\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32md:\\workspace\\dacon_news_topic_clasiification\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\workspace\\dacon_news_topic_clasiification\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result = cls_model.predict(test_movie_inputs, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bc554c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
