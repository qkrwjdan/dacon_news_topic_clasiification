{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ff304b4",
   "metadata": {},
   "source": [
    "# Klue/bert-base를 Augmented Data로 학습시키기\n",
    "\n",
    "Augmentation을 사용하여 데이터의 갯수를 증가시킨 데이터로 모델을 학습시킵니다.   \n",
    "증강된 데이터는 원본 데이터와 비슷한 정보를 가지고 있기 때문에, 학습 데이터와 검증 데이터가 섞인다면 정확한 성능 측정이 되지 않을 수 있습니다.  \n",
    "따라서, 학습 데이터와 검증 데이터가 섞이지 않도록 주의해야합니다.  \n",
    "이번 노트북에서는 학습 데이터와 검증 데이터를 나눈뒤, 학습 데이터에 데이터 증강 기법을 사용하고 모델을 훈련시킵니다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f18602",
   "metadata": {},
   "source": [
    "필요한 라이브러리들을 불러오고, 학습에 사용되는 GPU를 확인합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1c2820b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용가능한 GPU수 :  1\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm.notebook import tqdm, tnrange\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"사용가능한 GPU수 : \",torch.cuda.device_count())\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"CPU 사용\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b1ab43",
   "metadata": {},
   "source": [
    "Reproduction을 위한 Seed 고정  \n",
    "출처 : https://dacon.io/codeshare/2363?dtype=vote&s_id=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "365a9139",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "    \n",
    "seed_everything(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847cdfa2",
   "metadata": {},
   "source": [
    "이번 노트북에서는 klue/bert-base 모델을 사용합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9347d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"klue/bert-base\"\n",
    "batch_size = 32\n",
    "task = \"nli\"\n",
    "MODEL_P = \"models/klue-bert-base-augmented.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62446db5",
   "metadata": {},
   "source": [
    "huggingface 에서 tokenizer를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3f12cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c7b7b0",
   "metadata": {},
   "source": [
    "huggingface 에서 model를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "086da8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels = 7\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint,num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e006d6c",
   "metadata": {},
   "source": [
    "dataset을 가져옵니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecb701f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data/train_data.csv\",index_col=False)\n",
    "test = pd.read_csv(\"data/test_data.csv\",index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355feff8",
   "metadata": {},
   "source": [
    "train 데이터와 test 데이터를 나눠줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18b385e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataset_val = train_test_split(dataset,test_size = 0.2,random_state = RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bd7294",
   "metadata": {},
   "source": [
    "이번 노트북에서는 RD(Random Deletion)와 RS(Random Swap) 기법을 사용하여 augmentation을 진행합니다.   \n",
    "\n",
    "문장을 토큰화 해주도록 하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "071ad8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\workspace\\dacon_news_topic_clasiification\\venv\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    }
   ],
   "source": [
    "dataset_train[\"tokenized\"] = [tokenizer.tokenize(sentence) for sentence in dataset_train[\"title\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc01884",
   "metadata": {},
   "source": [
    "토큰화가 잘 되었는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e66470d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>topic_idx</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4824</th>\n",
       "      <td>4824</td>\n",
       "      <td>KT 화상회의 가능한 기업용 전화 출시</td>\n",
       "      <td>1</td>\n",
       "      <td>[KT, 화상, ##회의, 가능, ##한, 기업, ##용, 전화, 출시]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21714</th>\n",
       "      <td>21714</td>\n",
       "      <td>문 대통령 해리 해리스 주한 미국대사와 함께</td>\n",
       "      <td>6</td>\n",
       "      <td>[문, 대통령, 해리, 해리, ##스, 주한, 미국, ##대사, ##와, 함께]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29145</th>\n",
       "      <td>29145</td>\n",
       "      <td>김기식 사퇴 찬성 51%…文대통령 지지율 66.2%로 하락리얼미터</td>\n",
       "      <td>6</td>\n",
       "      <td>[김기, ##식, 사퇴, 찬성, 51, %, …, 文, 대통령, 지지율, 66, ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18342</th>\n",
       "      <td>18342</td>\n",
       "      <td>민주콩고서 수백명 에볼라 사태 끝내자 거리행진</td>\n",
       "      <td>4</td>\n",
       "      <td>[민주, ##콩, ##고, ##서, 수백, ##명, 에볼라, 사태, 끝내, ##자,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9010</th>\n",
       "      <td>9010</td>\n",
       "      <td>충남 올겨울 첫 한파주의보…눈 최대 15㎝ 쌓일 듯</td>\n",
       "      <td>3</td>\n",
       "      <td>[충남, 올겨울, 첫, 한파, ##주의, ##보, …, 눈, 최대, 15, ##㎝,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                 title  topic_idx  \\\n",
       "4824    4824                 KT 화상회의 가능한 기업용 전화 출시          1   \n",
       "21714  21714              문 대통령 해리 해리스 주한 미국대사와 함께          6   \n",
       "29145  29145  김기식 사퇴 찬성 51%…文대통령 지지율 66.2%로 하락리얼미터          6   \n",
       "18342  18342             민주콩고서 수백명 에볼라 사태 끝내자 거리행진          4   \n",
       "9010    9010          충남 올겨울 첫 한파주의보…눈 최대 15㎝ 쌓일 듯          3   \n",
       "\n",
       "                                               tokenized  \n",
       "4824            [KT, 화상, ##회의, 가능, ##한, 기업, ##용, 전화, 출시]  \n",
       "21714       [문, 대통령, 해리, 해리, ##스, 주한, 미국, ##대사, ##와, 함께]  \n",
       "29145  [김기, ##식, 사퇴, 찬성, 51, %, …, 文, 대통령, 지지율, 66, ....  \n",
       "18342  [민주, ##콩, ##고, ##서, 수백, ##명, 에볼라, 사태, 끝내, ##자,...  \n",
       "9010   [충남, 올겨울, 첫, 한파, ##주의, ##보, …, 눈, 최대, 15, ##㎝,...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cb7372",
   "metadata": {},
   "source": [
    "RD를 적용하기 위해 random_deletion 함수를 정의합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "894c016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_deletion(words, p):\n",
    "    if len(words) == 1:\n",
    "        return words\n",
    "\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        r = random.uniform(0, 1)\n",
    "        if r > p:\n",
    "            new_words.append(word)\n",
    "\n",
    "    if len(new_words) == 0:\n",
    "        rand_int = random.randint(0, len(words)-1)\n",
    "        return [words[rand_int]]\n",
    "\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e5fded",
   "metadata": {},
   "source": [
    "토큰화된 문장에 random_deletion함수를 적용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcdb9d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = [random_deletion(tokenized,0.2) for tokenized in dataset_train[\"tokenized\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e109e74",
   "metadata": {},
   "source": [
    "토큰이 랜덤으로 삭제된 것을 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7ca5062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['KT', '화상', '##회의', '가능', '##한', '기업', '##용', '전화', '출시'],\n",
       " ['KT', '##회의', '가능', '##한', '기업', '##용', '출시'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[\"tokenized\"].iloc[0] , rd[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d1e70a",
   "metadata": {},
   "source": [
    "랜덤으로 삭제된 데이터를 DataFrame의 형태로 만들어줍니다. 나중에 dataset_train과 합칠 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "896cd9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_augmented_dataset = pd.DataFrame({\"tokenized\" : rd, \"topic_idx\": dataset_train[\"topic_idx\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b9cba3",
   "metadata": {},
   "source": [
    "이번엔 RS를 적용하기 위해 random_swap 함수를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "029d8a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_swap(words, n):\n",
    "    new_words = words.copy()\n",
    "    for _ in range(n):\n",
    "        new_words = swap_word(new_words)\n",
    "\n",
    "    return new_words\n",
    "\n",
    "def swap_word(new_words):\n",
    "    random_idx_1 = random.randint(0, len(new_words)-1)\n",
    "    random_idx_2 = random_idx_1\n",
    "    counter = 0\n",
    "\n",
    "    while random_idx_2 == random_idx_1:\n",
    "        random_idx_2 = random.randint(0, len(new_words)-1)\n",
    "        counter += 1\n",
    "        if counter > 3:\n",
    "            return new_words\n",
    "\n",
    "    new_words[random_idx_1], new_words[random_idx_2] = new_words[random_idx_2], new_words[random_idx_1]\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82544a8",
   "metadata": {},
   "source": [
    "토큰화된 문장에 random_swap함수를 적용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ff38592",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = [random_swap(tokenized,2) for tokenized in dataset_train[\"tokenized\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e2a810",
   "metadata": {},
   "source": [
    "토큰의 위치가 임의로 바뀐 것을 볼 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2e20cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['KT', '화상', '##회의', '가능', '##한', '기업', '##용', '전화', '출시'],\n",
       " ['KT', '화상', '##용', '##한', '가능', '기업', '##회의', '전화', '출시'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[\"tokenized\"].iloc[0] , rs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72959bd1",
   "metadata": {},
   "source": [
    "DataFrame의 형태로 만들어줍니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bde92a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_augmented_dataset = pd.DataFrame({\"tokenized\" : rs, \"topic_idx\": dataset_train[\"topic_idx\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae7a77d",
   "metadata": {},
   "source": [
    "RD, RS가 적용된 데이터셋과 학습 데이터셋을 합치고, 순서를 섞어줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4c3f21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = pd.concat([dataset_train,rd_augmented_dataset,rs_augmented_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7642669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [미, ##중, ##갈, ##등, 한복, ##판, ##에, 선, 中, 화웨이, 멍,...\n",
       "1    [SK, 박종훈, 한, 이닝, ##에, 몸, ##에, 맞, ##는, 공, 3, ##...\n",
       "2    [김광석, 뮤지컬, 시름, 김광석, 없, ##에, 이유, ##는, …, 저작권, 시...\n",
       "3             [그래픽, 국내, 시장, ##별, 평균, 주식, ##보, ##유, 기간]\n",
       "4                         [박성, ##제, MBC, 신임, 보도, ##국장]\n",
       "5    [##배, ##구, V, ##리그, 올스타, ##전, 팬, ##표, 7, ##일, 시작]\n",
       "6        [건국, ##언, ##론, ##인, ##상, 이동, ##희, ·, 심재, ##윤]\n",
       "7    [북한, 고위급, 인사, 베이징, 도착, …, 귀, ##빈, 차량, ##으로, 이동...\n",
       "8    [38, ##점, 폭발, ##한, 거포, 디, ##우, ##프, 인삼, ##공사, ...\n",
       "9    [주말, N, 여행, 제주, ##권, 인류, ##무, ##형, ##문화, ##유산,...\n",
       "Name: tokenized, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train = dataset_train.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "dataset_train[\"tokenized\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb25604",
   "metadata": {},
   "source": [
    "데이터의 수가 늘어났습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14de269c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109569"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9615cb24",
   "metadata": {},
   "source": [
    "학습 데이터들은 토큰화가 된 상태이고, 테스트 데이터들은 문장의 형태로 서로 다릅니다.  \n",
    "그래서 학습에 필요한 데이터셋을 만드는 방식과 테스트에 필요한 데이터를 만드는 방식이 다릅니다.  \n",
    "따라서 서로 다른 데이터셋으로 정의해줍니다. \n",
    "\n",
    "학습데이터의 경우 토큰화가 되어있기 때문에 `tokenizer`의 `tokenize`함수를 사용할 수 없습니다. 따라서 `convert_tokens_to_ids`함수를 사용하여 토큰을 input_ids로 바꿔줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17bc3c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['미', '##중', '##갈', '##등', '한복', '##판', '##에', '선', '中', '화웨이', '멍', '##완', '##저우', '결백', '주장']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1107,\n",
       " 2284,\n",
       " 2577,\n",
       " 2491,\n",
       " 11641,\n",
       " 2025,\n",
       " 2170,\n",
       " 1261,\n",
       " 220,\n",
       " 21157,\n",
       " 1064,\n",
       " 2365,\n",
       " 11110,\n",
       " 29282,\n",
       " 3831]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset_train[\"tokenized\"].iloc[0])\n",
    "tokenizer.convert_tokens_to_ids(dataset_train[\"tokenized\"].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6b7f78",
   "metadata": {},
   "source": [
    "이때, [CLS]나 [SEP]과 같은 special token이 자동으로 추가되지 않습니다. 따라서 수동으로 token을 추가해주어야 합니다.   \n",
    "tokenizer의 cls 토큰하고 sep 토큰의 ids를 확인합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4e1632b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(tokenizer.cls_token),tokenizer.convert_tokens_to_ids(tokenizer.sep_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bb5c37",
   "metadata": {},
   "source": [
    "`convert_tokens_to_ids` 함수를 실행한 뒤, list의 맨 앞에 [CLS]토큰의 ids를, 맨 뒤에는 [SEP]토큰의 ids를 추가해줍니다.   \n",
    "적절한 attention_masks와 `__getitem__`함수, `__len__`함수를 만들어줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52a5e397",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_key, label_key, bert_tokenizer):\n",
    "        \n",
    "        self.sentences = [ bert_tokenizer.convert_tokens_to_ids(i) for i in dataset[sent_key] ]\n",
    "        for idx in range(len(self.sentences)):\n",
    "            self.sentences[idx].insert(0,2)\n",
    "            self.sentences[idx].append(3)\n",
    "        \n",
    "        self.attention_masks = [ [1 for i in range(len(sentence))] for sentence in self.sentences ]\n",
    "        self.labels = [np.int64(i) for i in dataset[label_key]]\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {'input_ids':self.sentences[i],'attention_mask': self.attention_masks[i],'label': self.labels[i]}\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48df6a92",
   "metadata": {},
   "source": [
    "테스트 데이터셋은 `tokenizer`의 `tokenize`함수를 사용합니다.  \n",
    "검증 데이터에는 라벨이 있지만, 테스트 데이터에는 라벨이 없기 때문에 테스트 데이터의 경우에는 라벨을 0으로 초기화해줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92068708",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_key, label_key, bert_tokenizer):\n",
    "        \n",
    "        self.sentences = [ bert_tokenizer(i,truncation=True,return_token_type_ids=False) for i in dataset[sent_key] ]\n",
    "        \n",
    "        if not label_key == None:\n",
    "            self.mode = \"train\"\n",
    "        else:\n",
    "            self.mode = \"test\"\n",
    "            \n",
    "        if self.mode == \"train\":\n",
    "            self.labels = [np.int64(i) for i in dataset[label_key]]\n",
    "        else:\n",
    "            self.labels = [np.int64(0) for i in dataset[sent_key]]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if self.mode == \"train\":\n",
    "            self.sentences[i][\"label\"] = self.labels[i]\n",
    "            return self.sentences[i]\n",
    "        else:\n",
    "            return self.sentences[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20e2167",
   "metadata": {},
   "source": [
    "데이터셋을 만들어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a0c0c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = TrainDataset(dataset_train, \"tokenized\", \"topic_idx\", tokenizer)\n",
    "data_val = TestDataset(dataset_val, \"title\", \"topic_idx\", tokenizer)\n",
    "data_test = TestDataset(test, \"title\", None, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87a18da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 4816, 2223, 7270, 7270, 2882, 2292, 9608, 17797, 2361, 2063, 7355, 2170, 8172, 27854, 3], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'label': 1}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2bff503f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2,\n",
       "  1107,\n",
       "  2284,\n",
       "  2577,\n",
       "  2491,\n",
       "  11641,\n",
       "  2025,\n",
       "  2170,\n",
       "  1261,\n",
       "  220,\n",
       "  21157,\n",
       "  1064,\n",
       "  2365,\n",
       "  11110,\n",
       "  29282,\n",
       "  3831,\n",
       "  3],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'label': 4}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f044b5e8",
   "metadata": {},
   "source": [
    "trainer에서 사용할 metric을 정의해줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a21cc459",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"glue\", \"qnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "abf73b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d27aa1",
   "metadata": {},
   "source": [
    "trainer에 들어갈 Arguments를 정의해줍니다.  \n",
    "증강된 데이터를 사용하면 한 epoch이 원래 데이터의 3배이기 때문에 epoch마다 평가를 진행할 경우 overfitting이 발생할 수 있습니다.   \n",
    "따라서 좀더 작은 단위인 step단위로 평가를 진행하기 위해 `evaluation_strategy`를 `epoch`이 아닌 `steps`로 사용했습니다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a65f3fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name = \"accuracy\"\n",
    "\n",
    "args = TrainingArguments(\n",
    "    MODEL_P,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf09a9b",
   "metadata": {},
   "source": [
    "trainer를 정의하고 학습을 진행합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "360465e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=data_train,\n",
    "    eval_dataset=data_val,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d7c4713",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 109569\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6850\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6850' max='6850' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6850/6850 13:25, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.529200</td>\n",
       "      <td>0.372666</td>\n",
       "      <td>0.877889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.380700</td>\n",
       "      <td>0.342845</td>\n",
       "      <td>0.882160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.346700</td>\n",
       "      <td>0.326366</td>\n",
       "      <td>0.888293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.314000</td>\n",
       "      <td>0.333488</td>\n",
       "      <td>0.887745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.300900</td>\n",
       "      <td>0.333628</td>\n",
       "      <td>0.885774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.282500</td>\n",
       "      <td>0.328829</td>\n",
       "      <td>0.888950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.254100</td>\n",
       "      <td>0.343085</td>\n",
       "      <td>0.891578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.197700</td>\n",
       "      <td>0.360881</td>\n",
       "      <td>0.891031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.177400</td>\n",
       "      <td>0.363702</td>\n",
       "      <td>0.891140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.169300</td>\n",
       "      <td>0.374855</td>\n",
       "      <td>0.890045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.168500</td>\n",
       "      <td>0.372407</td>\n",
       "      <td>0.887964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.156800</td>\n",
       "      <td>0.386013</td>\n",
       "      <td>0.886759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.153300</td>\n",
       "      <td>0.386282</td>\n",
       "      <td>0.889169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to models/klue-bert-base-augmented.pth\\checkpoint-500\n",
      "Configuration saved in models/klue-bert-base-augmented.pth\\checkpoint-500\\config.json\n",
      "Model weights saved in models/klue-bert-base-augmented.pth\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in models/klue-bert-base-augmented.pth\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in models/klue-bert-base-augmented.pth\\checkpoint-500\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to models/klue-bert-base-augmented.pth\\checkpoint-1000\n",
      "Configuration saved in models/klue-bert-base-augmented.pth\\checkpoint-1000\\config.json\n",
      "Model weights saved in models/klue-bert-base-augmented.pth\\checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in models/klue-bert-base-augmented.pth\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in models/klue-bert-base-augmented.pth\\checkpoint-1000\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to models/klue-bert-base-augmented.pth\\checkpoint-1500\n",
      "Configuration saved in models/klue-bert-base-augmented.pth\\checkpoint-1500\\config.json\n",
      "Model weights saved in models/klue-bert-base-augmented.pth\\checkpoint-1500\\pytorch_model.bin\n",
      "tokenizer config file saved in models/klue-bert-base-augmented.pth\\checkpoint-1500\\tokenizer_config.json\n",
      "Special tokens file saved in models/klue-bert-base-augmented.pth\\checkpoint-1500\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to models/klue-bert-base-augmented.pth\\checkpoint-2000\n",
      "Configuration saved in models/klue-bert-base-augmented.pth\\checkpoint-2000\\config.json\n",
      "Model weights saved in models/klue-bert-base-augmented.pth\\checkpoint-2000\\pytorch_model.bin\n",
      "tokenizer config file saved in models/klue-bert-base-augmented.pth\\checkpoint-2000\\tokenizer_config.json\n",
      "Special tokens file saved in models/klue-bert-base-augmented.pth\\checkpoint-2000\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to models/klue-bert-base-augmented.pth\\checkpoint-2500\n",
      "Configuration saved in models/klue-bert-base-augmented.pth\\checkpoint-2500\\config.json\n",
      "Model weights saved in models/klue-bert-base-augmented.pth\\checkpoint-2500\\pytorch_model.bin\n",
      "tokenizer config file saved in models/klue-bert-base-augmented.pth\\checkpoint-2500\\tokenizer_config.json\n",
      "Special tokens file saved in models/klue-bert-base-augmented.pth\\checkpoint-2500\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to models/klue-bert-base-augmented.pth\\checkpoint-3000\n",
      "Configuration saved in models/klue-bert-base-augmented.pth\\checkpoint-3000\\config.json\n",
      "Model weights saved in models/klue-bert-base-augmented.pth\\checkpoint-3000\\pytorch_model.bin\n",
      "tokenizer config file saved in models/klue-bert-base-augmented.pth\\checkpoint-3000\\tokenizer_config.json\n",
      "Special tokens file saved in models/klue-bert-base-augmented.pth\\checkpoint-3000\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to models/klue-bert-base-augmented.pth\\checkpoint-3500\n",
      "Configuration saved in models/klue-bert-base-augmented.pth\\checkpoint-3500\\config.json\n",
      "Model weights saved in models/klue-bert-base-augmented.pth\\checkpoint-3500\\pytorch_model.bin\n",
      "tokenizer config file saved in models/klue-bert-base-augmented.pth\\checkpoint-3500\\tokenizer_config.json\n",
      "Special tokens file saved in models/klue-bert-base-augmented.pth\\checkpoint-3500\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to models/klue-bert-base-augmented.pth\\checkpoint-4000\n",
      "Configuration saved in models/klue-bert-base-augmented.pth\\checkpoint-4000\\config.json\n",
      "Model weights saved in models/klue-bert-base-augmented.pth\\checkpoint-4000\\pytorch_model.bin\n",
      "tokenizer config file saved in models/klue-bert-base-augmented.pth\\checkpoint-4000\\tokenizer_config.json\n",
      "Special tokens file saved in models/klue-bert-base-augmented.pth\\checkpoint-4000\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to models/klue-bert-base-augmented.pth\\checkpoint-4500\n",
      "Configuration saved in models/klue-bert-base-augmented.pth\\checkpoint-4500\\config.json\n",
      "Model weights saved in models/klue-bert-base-augmented.pth\\checkpoint-4500\\pytorch_model.bin\n",
      "tokenizer config file saved in models/klue-bert-base-augmented.pth\\checkpoint-4500\\tokenizer_config.json\n",
      "Special tokens file saved in models/klue-bert-base-augmented.pth\\checkpoint-4500\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to models/klue-bert-base-augmented.pth\\checkpoint-5000\n",
      "Configuration saved in models/klue-bert-base-augmented.pth\\checkpoint-5000\\config.json\n",
      "Model weights saved in models/klue-bert-base-augmented.pth\\checkpoint-5000\\pytorch_model.bin\n",
      "tokenizer config file saved in models/klue-bert-base-augmented.pth\\checkpoint-5000\\tokenizer_config.json\n",
      "Special tokens file saved in models/klue-bert-base-augmented.pth\\checkpoint-5000\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to models/klue-bert-base-augmented.pth\\checkpoint-5500\n",
      "Configuration saved in models/klue-bert-base-augmented.pth\\checkpoint-5500\\config.json\n",
      "Model weights saved in models/klue-bert-base-augmented.pth\\checkpoint-5500\\pytorch_model.bin\n",
      "tokenizer config file saved in models/klue-bert-base-augmented.pth\\checkpoint-5500\\tokenizer_config.json\n",
      "Special tokens file saved in models/klue-bert-base-augmented.pth\\checkpoint-5500\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to models/klue-bert-base-augmented.pth\\checkpoint-6000\n",
      "Configuration saved in models/klue-bert-base-augmented.pth\\checkpoint-6000\\config.json\n",
      "Model weights saved in models/klue-bert-base-augmented.pth\\checkpoint-6000\\pytorch_model.bin\n",
      "tokenizer config file saved in models/klue-bert-base-augmented.pth\\checkpoint-6000\\tokenizer_config.json\n",
      "Special tokens file saved in models/klue-bert-base-augmented.pth\\checkpoint-6000\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to models/klue-bert-base-augmented.pth\\checkpoint-6500\n",
      "Configuration saved in models/klue-bert-base-augmented.pth\\checkpoint-6500\\config.json\n",
      "Model weights saved in models/klue-bert-base-augmented.pth\\checkpoint-6500\\pytorch_model.bin\n",
      "tokenizer config file saved in models/klue-bert-base-augmented.pth\\checkpoint-6500\\tokenizer_config.json\n",
      "Special tokens file saved in models/klue-bert-base-augmented.pth\\checkpoint-6500\\special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from models/klue-bert-base-augmented.pth\\checkpoint-3500 (score: 0.8915781404008323).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6850, training_loss=0.2580998591959041, metrics={'train_runtime': 806.1617, 'train_samples_per_second': 271.829, 'train_steps_per_second': 8.497, 'total_flos': 3109487374633926.0, 'train_loss': 0.2580998591959041, 'epoch': 2.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e67322",
   "metadata": {},
   "source": [
    "학습이 끝난 뒤, 평가를 통해 결과를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "896dfa59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='572' max='286' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [286/286 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.34308499097824097,\n",
       " 'eval_accuracy': 0.8915781404008323,\n",
       " 'eval_runtime': 7.7037,\n",
       " 'eval_samples_per_second': 1185.281,\n",
       " 'eval_steps_per_second': 37.125,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585ae70d",
   "metadata": {},
   "source": [
    "`predict`함수를 사용하여 테스트 데이터셋에 대한 예측을 진행합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e6d2d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "pred = trainer.predict(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f63b1d",
   "metadata": {},
   "source": [
    "결과를 csv파일로 저장하고 제출합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6daefe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d46f8774",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(pred,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6bfa026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "submission['topic_idx'] = pred\n",
    "submission.to_csv(\"results/klue-bert-base-simple-rd-rs.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e487be53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
