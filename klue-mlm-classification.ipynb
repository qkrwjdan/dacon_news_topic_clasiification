{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e0c9dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import logging\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm, tqdm_notebook, tnrange\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from datasets import load_dataset, load_metric, ClassLabel, Sequence\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel, AutoModelForMaskedLM, AutoModelForPreTraining, TrainingArguments, Trainer\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset,TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d691109b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5016d793",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"klue/bert-base\"\n",
    "# model_checkpoint = \"bert-base-multilingual-cased\"\n",
    "batch_size = 64\n",
    "task = \"nli\"\n",
    "MODEL_P = \"models/klue-bert-base-mlm.pth\"\n",
    "RANDOM_SEED = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2edc05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8e3c937",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data/train_data.csv\",index_col=False)\n",
    "test = pd.read_csv(\"data/test_data.csv\",index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ed9dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_token_dict = {0:4038,1:3674,2:3647,3:3697,4:3665,5:4559,6:3713}\n",
    "topic_dict = {0: \"과학\", 1:\"경제\", 2:\"사회\", 3:\"문화\", 4:\"세계\", 5:\"스포츠\", 6 : \"정치\"}\n",
    "tmp = []\n",
    "\n",
    "for title, topic_idx in zip(dataset[\"title\"],dataset[\"topic_idx\"]):\n",
    "    sentence = title + \".[SEP] 이 문장은 [MASK]\"\n",
    "    tmp.append(sentence)\n",
    "dataset[\"title\"] = tmp\n",
    "    \n",
    "tmp = []\n",
    "for title in test[\"title\"]:\n",
    "    sentence = title + \".[SEP] 이 문장은 [MASK]\"\n",
    "    tmp.append(sentence)\n",
    "\n",
    "test[\"title\"] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccc028bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataset_val = train_test_split(dataset,test_size = 0.2,random_state = RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9235e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>topic_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25339</th>\n",
       "      <td>25339</td>\n",
       "      <td>더민주 서영교 여파 지역위원장 심사기준 강화.[SEP] 이 문장은 [MASK]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24704</th>\n",
       "      <td>24704</td>\n",
       "      <td>맛집에 너그러운 한국인 해외여행서도 JMT 찾았다.[SEP] 이 문장은 [MASK]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>1834</td>\n",
       "      <td>특징주 삼성물산 지배구조 이슈 부각에 강세종합.[SEP] 이 문장은 [MASK]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17604</th>\n",
       "      <td>17604</td>\n",
       "      <td>생필품난 베네수엘라 콜롬비아와의 국경 1년 만에 재개방.[SEP] 이 문장은 [MASK]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19362</th>\n",
       "      <td>19362</td>\n",
       "      <td>금태섭 국민 10명 중 8명 판결문 공개 원해.[SEP] 이 문장은 [MASK]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                              title  topic_idx\n",
       "25339  25339        더민주 서영교 여파 지역위원장 심사기준 강화.[SEP] 이 문장은 [MASK]          6\n",
       "24704  24704     맛집에 너그러운 한국인 해외여행서도 JMT 찾았다.[SEP] 이 문장은 [MASK]          3\n",
       "1834    1834       특징주 삼성물산 지배구조 이슈 부각에 강세종합.[SEP] 이 문장은 [MASK]          1\n",
       "17604  17604  생필품난 베네수엘라 콜롬비아와의 국경 1년 만에 재개방.[SEP] 이 문장은 [MASK]          4\n",
       "19362  19362       금태섭 국민 10명 중 8명 판결문 공개 원해.[SEP] 이 문장은 [MASK]          6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e74b1fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_train = dataset_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c243da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_tokenize(dataset,sent_key,label_key,tokenizer):\n",
    "    if label_key is None :\n",
    "        labels = [np.int64(0) for i in dataset[sent_key]]\n",
    "    else :\n",
    "        labels = [np.int64(i) for i in dataset[label_key]]\n",
    "    \n",
    "    sentences = tokenizer(dataset[sent_key].tolist(),truncation=True,padding=True)\n",
    "#     sentences = tokenizer(dataset[sent_key].tolist(),truncation=True)\n",
    "\n",
    "    input_ids = sentences.input_ids\n",
    "    token_type_ids = sentences.token_type_ids\n",
    "    attention_mask = sentences.attention_mask\n",
    "    masked_token_idx = []\n",
    "    \n",
    "    for input_id in input_ids:\n",
    "        masked_token_idx.append(input_id.index(4))\n",
    "        \n",
    "    \n",
    "    return list([input_ids, token_type_ids, attention_mask, labels, masked_token_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96c14b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = bert_tokenize(dataset_train,\"title\",\"topic_idx\",tokenizer)\n",
    "validation_inputs = bert_tokenize(dataset_val,\"title\",\"topic_idx\",tokenizer)\n",
    "test_inputs = bert_tokenize(test,\"title\",None,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e6a3ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_inputs)):\n",
    "    train_inputs[i] = torch.tensor(train_inputs[i])\n",
    "    \n",
    "for i in range(len(validation_inputs)):\n",
    "    validation_inputs[i] = torch.tensor(validation_inputs[i])\n",
    "    \n",
    "for i in range(len(test_inputs)):\n",
    "    test_inputs[i] = torch.tensor(test_inputs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9fd7b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(*train_inputs)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data,sampler=train_sampler,batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(*validation_inputs)\n",
    "validation_sampler = RandomSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data,sampler=validation_sampler,batch_size=batch_size)\n",
    "\n",
    "test_data = TensorDataset(*test_inputs)\n",
    "test_sampler = RandomSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data,sampler=test_sampler,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffb99fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = next(iter(train_dataloader))\n",
    "data[3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd0a028e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[    2,  3833,  5499,  ...,     0,     0,     0],\n",
       "         [    2, 16070, 10234,  ...,     0,     0,     0],\n",
       "         [    2,  8967,  2265,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [    2,  1726, 11235,  ...,     0,     0,     0],\n",
       "         [    2, 20544,  3698,  ...,     0,     0,     0],\n",
       "         [    2,  4048, 18600,  ...,     0,     0,     0]]),\n",
       " tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " tensor([6, 4, 1, 3, 1, 0, 5, 4, 3, 2, 0, 5, 3, 5, 6, 0, 2, 2, 0, 0, 4, 2, 2, 6,\n",
       "         3, 6, 4, 4, 6, 4, 6, 2, 6, 2, 1, 1, 6, 4, 2, 3, 5, 4, 0, 6, 4, 6, 0, 5,\n",
       "         0, 6, 6, 5, 5, 4, 1, 6, 5, 6, 2, 6, 4, 1, 6, 2]),\n",
       " tensor([22, 24, 16, 13, 21, 21, 25, 19, 23, 18, 22, 22, 16, 21, 19, 17, 23, 20,\n",
       "         21, 16, 18, 18, 21, 18, 20, 19, 19, 22, 19, 19, 22, 10, 23, 16, 25, 25,\n",
       "         20, 27, 21, 16, 20, 26, 19, 21, 19, 17, 26, 21, 20, 20, 21, 20, 26, 18,\n",
       "         15, 22, 19, 20, 17, 19, 24, 26, 21, 23])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "476d36ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForPreTraining(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertPreTrainingHeads(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=32000, bias=True)\n",
       "    )\n",
       "    (seq_relationship): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint,num_labels=7)\n",
    "# model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForPreTraining.from_pretrained(model_checkpoint)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cbbcc973",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForPreTrainingOutput(loss=None, prediction_logits=tensor([[[ -6.0406,   3.1712,  -4.7043,  ...,  -6.7852,  -6.0219,  -6.4100],\n",
      "         [ -6.5202,   6.0657,  -7.2749,  ...,  -6.4878,  -8.5244,  -6.5877],\n",
      "         [ -8.7517,   7.6491,  -6.4469,  ...,  -2.6874,  -5.8746,  -6.4186],\n",
      "         ...,\n",
      "         [ -7.9496,   2.6318,  -6.0783,  ...,  -5.1762,  -6.1159,  -7.9961],\n",
      "         [ -6.8191,   5.3924,  -4.8108,  ...,  -4.5111,  -5.3303,  -6.0203],\n",
      "         [ -7.1067,   5.0341,  -4.6863,  ...,  -5.6264,  -5.4639,  -6.7108]],\n",
      "\n",
      "        [[ -6.5271,   3.6221,  -5.4519,  ...,  -5.8584,  -5.7478,  -5.1125],\n",
      "         [ -5.3117,   8.8945,  -4.5603,  ...,  -4.1524,  -2.3396,  -1.6568],\n",
      "         [ -6.4958,   5.0262,  -3.3150,  ...,  -5.1708,  -4.7854,  -4.2634],\n",
      "         ...,\n",
      "         [ -6.1085,   4.6625,  -5.5953,  ...,  -5.1957,  -3.4544,  -3.6032],\n",
      "         [ -5.6021,   8.5952,  -4.4087,  ...,  -4.1917,  -3.5906,  -4.4249],\n",
      "         [ -6.1020,   7.6569,  -4.2453,  ...,  -4.7865,  -4.0938,  -4.5708]],\n",
      "\n",
      "        [[ -5.9488,   2.8386,  -4.0771,  ...,  -6.1484,  -6.0774,  -5.9659],\n",
      "         [ -2.5275,   4.9975,  -6.1570,  ...,  -4.3374,  -2.8192,  -5.3540],\n",
      "         [ -5.5104,   6.1125,  -6.3826,  ...,  -6.7354,  -6.9716,  -6.6409],\n",
      "         ...,\n",
      "         [ -7.6446,   6.9945,  -6.2364,  ...,  -4.3830,  -4.3423,  -6.5522],\n",
      "         [ -6.3700,   5.8174,  -4.2275,  ...,  -4.4335,  -4.4233,  -4.3578],\n",
      "         [ -6.6230,   6.5226,  -5.1433,  ...,  -3.8284,  -3.0146,  -4.9783]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -5.8794,   2.4451,  -4.6033,  ...,  -7.1471,  -7.7325,  -6.5544],\n",
      "         [ -8.5412,   5.3535,  -8.4227,  ...,  -9.6394, -13.1222,  -9.8478],\n",
      "         [ -7.3186,   5.0227,  -5.3977,  ...,  -8.1875, -13.1281, -10.3766],\n",
      "         ...,\n",
      "         [ -5.8594,   4.9117,  -5.0512,  ...,  -6.9743,  -6.8061,  -6.2154],\n",
      "         [ -5.0884,   4.2951,  -4.3389,  ...,  -7.5672,  -6.9911,  -6.2124],\n",
      "         [ -4.8520,   4.0257,  -3.6387,  ...,  -5.2541,  -5.4684,  -5.1262]],\n",
      "\n",
      "        [[ -6.7143,   3.2108,  -3.6201,  ...,  -7.0249,  -5.6752,  -5.9616],\n",
      "         [ -5.2832,   5.7297,  -4.3567,  ...,  -4.3934,  -5.7794,  -5.8441],\n",
      "         [ -9.9044,   6.6343,  -5.9840,  ...,  -9.6083,  -9.3314,  -9.4698],\n",
      "         ...,\n",
      "         [ -5.2840,   6.3634,  -3.9041,  ...,  -6.6885,  -5.5581,  -6.3134],\n",
      "         [ -4.4788,   6.8700,  -5.0612,  ...,  -6.5279,  -4.8341,  -5.3368],\n",
      "         [ -6.2839,   4.7060,  -4.4142,  ...,  -6.6591,  -4.6636,  -5.1879]],\n",
      "\n",
      "        [[ -5.5589,   3.2959,  -5.0378,  ...,  -6.8225,  -5.6584,  -5.6049],\n",
      "         [ -7.1254,   5.9205,  -8.2911,  ...,  -9.2973,  -9.8846,  -6.5766],\n",
      "         [ -5.4208,   3.5982,  -7.0756,  ...,  -6.0980,  -4.1374,  -4.9395],\n",
      "         ...,\n",
      "         [ -4.1116,   6.5282,  -4.4576,  ...,  -6.3953,  -5.3517,  -4.4537],\n",
      "         [ -6.5038,   2.7152,  -5.6953,  ...,  -6.7531,  -5.5363,  -6.1570],\n",
      "         [ -4.1436,   7.5610,  -4.9506,  ...,  -5.9867,  -4.3230,  -5.0980]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), seq_relationship_logits=tensor([[-1.8245e-01, -4.5039e-01],\n",
      "        [ 2.5835e-01, -2.2467e-03],\n",
      "        [-1.6771e-01,  3.7928e-01],\n",
      "        [ 1.4854e-01,  5.9186e-01],\n",
      "        [ 6.0955e-01, -2.3492e-01],\n",
      "        [ 7.7759e-01, -2.4707e-01],\n",
      "        [-6.5508e-02,  1.1314e-01],\n",
      "        [-2.9042e-01,  3.5132e-01],\n",
      "        [ 7.5760e-01,  5.6575e-01],\n",
      "        [ 3.0261e-02,  8.0406e-02],\n",
      "        [-4.3801e-01, -6.0914e-01],\n",
      "        [ 1.8459e-01, -1.1994e-01],\n",
      "        [-4.6875e-01,  5.9108e-01],\n",
      "        [ 6.4062e-03, -6.1376e-01],\n",
      "        [ 1.2940e-02, -5.3038e-01],\n",
      "        [-2.1283e-01, -2.0505e-01],\n",
      "        [-3.1686e-01,  2.5653e-01],\n",
      "        [-3.0973e-02,  1.9723e-01],\n",
      "        [ 4.3504e-01,  9.1065e-01],\n",
      "        [-7.3757e-02,  1.5536e+00],\n",
      "        [-2.6622e-01,  2.9285e-01],\n",
      "        [ 4.0355e-01,  4.4695e-01],\n",
      "        [ 6.2121e-01, -2.4258e-01],\n",
      "        [ 2.8712e-01, -1.6897e-01],\n",
      "        [ 2.8439e-01, -7.5023e-01],\n",
      "        [-2.3326e-01,  4.7146e-02],\n",
      "        [ 7.5561e-02, -1.7255e-01],\n",
      "        [-5.1129e-01, -5.5289e-01],\n",
      "        [-1.6690e-01, -3.0613e-01],\n",
      "        [ 3.5367e-01, -5.7550e-01],\n",
      "        [-2.4718e-01, -8.6891e-01],\n",
      "        [ 2.7165e-01,  1.0020e+00],\n",
      "        [ 3.6869e-01, -2.4713e-01],\n",
      "        [ 3.5877e-01,  1.8352e+00],\n",
      "        [-2.5297e-01, -5.5938e-02],\n",
      "        [-6.5970e-02, -3.6575e-01],\n",
      "        [-3.0233e-01,  4.3340e-02],\n",
      "        [-2.1417e-01, -5.4391e-01],\n",
      "        [-4.9661e-01,  5.6658e-01],\n",
      "        [-3.4358e-01,  4.8478e-01],\n",
      "        [ 3.8704e-01, -4.0449e-01],\n",
      "        [-2.7779e-01, -2.5236e-01],\n",
      "        [ 8.8769e-01, -3.2177e-01],\n",
      "        [-4.6197e-01, -9.0757e-01],\n",
      "        [-1.7924e-01,  6.3616e-01],\n",
      "        [-1.7590e-01, -1.1027e-03],\n",
      "        [ 2.2017e-01,  4.7816e-02],\n",
      "        [-6.6353e-01, -2.6659e-01],\n",
      "        [ 6.6580e-02,  1.2833e-01],\n",
      "        [-8.6170e-01, -6.1770e-01],\n",
      "        [-5.2136e-01, -5.8495e-01],\n",
      "        [-1.9444e-01, -8.0233e-01],\n",
      "        [-3.7479e-01, -7.1073e-01],\n",
      "        [-4.3800e-01, -3.7249e-01],\n",
      "        [ 3.6965e-01, -7.2223e-01],\n",
      "        [ 9.3438e-02,  4.8960e-01],\n",
      "        [-5.0483e-03, -5.2299e-01],\n",
      "        [ 1.9774e-01, -1.1690e+00],\n",
      "        [ 6.8513e-01, -2.4889e-01],\n",
      "        [ 3.3310e-01,  4.5200e-01],\n",
      "        [-8.6836e-03, -7.4636e-02],\n",
      "        [-4.6375e-01,  9.1718e-01],\n",
      "        [-1.6168e-01,  2.7390e-01],\n",
      "        [-2.5259e-01,  5.1182e-01]], device='cuda:0', grad_fn=<AddmmBackward>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "data = tuple(t.to(device) for t in data)\n",
    "input_ids, token_ids, mask, label, masked_token_idx = data\n",
    "outputs = model(input_ids, token_type_ids=token_ids, attention_mask=mask)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "be35fbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_cls, logits_lm = outputs[1], outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "96d18841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2240, 32000])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_lm.view(-1, logits_lm.size(2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8ace2bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 35, 32000])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_lm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "76aab14d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22, 24, 16, 13, 21, 21, 25, 19, 23, 18, 22, 22, 16, 21, 19, 17, 23, 20,\n",
       "        21, 16, 18, 18, 21, 18, 20, 19, 19, 22, 19, 19, 22, 10, 23, 16, 25, 25,\n",
       "        20, 27, 21, 16, 20, 26, 19, 21, 19, 17, 26, 21, 20, 20, 21, 20, 26, 18,\n",
       "        15, 22, 19, 20, 17, 19, 24, 26, 21, 23], device='cuda:0')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_token_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "445364c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "24\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "16\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "13\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "21\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "21\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "25\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "19\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "23\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "18\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "22\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "22\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "16\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "21\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "19\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "17\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "23\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "20\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "21\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "16\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "18\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "18\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "21\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "18\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "20\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "19\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "19\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "22\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "19\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "19\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "22\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "10\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "23\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "16\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "25\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "25\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "20\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "27\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "21\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "16\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "20\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "26\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "19\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "21\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "19\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "17\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "26\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "21\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "20\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "20\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "21\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "20\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "26\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "18\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "15\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "22\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "19\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "20\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "17\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "19\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "24\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "26\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "21\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "23\n",
      "<class 'numpy.int64'>\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "SEQUENCE_LENGTH = 35\n",
    "mask_label = [topic_token_dict[lb] for lb in label.to('cpu').numpy() ]\n",
    "label_lms = []\n",
    "for idx, label in zip(masked_token_idx.to('cpu').numpy(),mask_label):\n",
    "    label_lm = np.full(SEQUENCE_LENGTH, dtype=np.int, fill_value=-1)\n",
    "    print(idx)\n",
    "    print(type(idx))\n",
    "    print(label_lm)\n",
    "    label_lm[idx] = label\n",
    "    label_lms.append(label_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "12ff4703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 35)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(label_lms)\n",
    "label_lms_np = np.array(label_lms)\n",
    "label_lms_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "09521d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1, -1, -1,  ..., -1, -1, -1], device='cuda:0')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_lms_pt = torch.tensor(label_lms_np,dtype=torch.int64).to(device)\n",
    "label_lms_pt.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "cbcdeed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2240, 32000]) torch.Size([2240])\n",
      "tensor(7.8615, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(logits_lm.view(-1, logits_lm.size(2)).shape , label_lms_pt.view(-1).shape)\n",
    "criterion_lm = torch.nn.CrossEntropyLoss(ignore_index=-1, reduction='mean')\n",
    "loss_lm = criterion_lm(logits_lm.view(-1, logits_lm.size(2)), label_lms_pt.view(-1))\n",
    "print(loss_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "811a7232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8cad83fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (43) to match target batch_size (64).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_33724/1715209599.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlabels_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlabels_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_cls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mloss_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion_cls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits_cls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_cls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\workspace\\dacon_news_topic_clasiification\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\workspace\\dacon_news_topic_clasiification\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[0;32m    962\u001b[0m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\workspace\\dacon_news_topic_clasiification\\venv\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2466\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2467\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2468\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\workspace\\dacon_news_topic_clasiification\\venv\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2260\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2261\u001b[1;33m         raise ValueError('Expected input batch_size ({}) to match target batch_size ({}).'\n\u001b[0m\u001b[0;32m   2262\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[0;32m   2263\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (43) to match target batch_size (64)."
     ]
    }
   ],
   "source": [
    "criterion_cls = torch.nn.CrossEntropyLoss()\n",
    "labels_cls = [1 for _ in range(len(input_ids))]\n",
    "labels_cls = torch.tensor(labels_cls).to(device)\n",
    "loss_cls = criterion_cls(logits_cls, labels_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "60e33284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7543, device='cuda:0', grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b5845916",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_cls + loss_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9a989270",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "41f72ca7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_33724/383757286.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmasked_token_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "# masked_token_ids.to('cpu').numpy(), label.to('cpu').numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b6d1bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits = outputs[0].to(\"cpu\").detach().numpy()\n",
    "# print(logits.shape)\n",
    "# print(len(logits[0][0]))\n",
    "# print(np.argmax(logits,axis=2).shape)\n",
    "# out = np.argmax(logits,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6fb2e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predict_tensor(logits,idx):\n",
    "    tmp = []\n",
    "    for b,i in zip(logits,idx):\n",
    "        tmp.append(b[i])\n",
    "    \n",
    "    pred = torch.tensor(tmp,requires_grad=True)\n",
    "    \n",
    "    return pred\n",
    "\n",
    "# pred = get_predict_tensor(logits,[18])\n",
    "# pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e371ab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = get_predict_tensor(logits,masked_token_ids.to('cpu').numpy())\n",
    "# pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3536c491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer = [topic_token_dict[lb] for lb in label.to('cpu').numpy() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e864ce8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans = torch.tensor(answer)\n",
    "# loss_fn(pred,ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34decab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.argmax(outputs[0],axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7dd94490",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(tokenizer.convert_ids_to_tokens(data[0][0]))\n",
    "# print(data[0][0])\n",
    "# print(data[1][0])\n",
    "# print(data[2][0])\n",
    "# print(tokenizer.convert_ids_to_tokens(out[0]))\n",
    "# print(out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2717503a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters:\n",
    "lr = 2e-5\n",
    "adam_epsilon = 1e-8\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 100\n",
    "\n",
    "num_warmup_steps = 0\n",
    "\n",
    "warmup_ratio = 0.1\n",
    "num_training_steps = len(train_dataloader)*epochs\n",
    "warmup_step = int(num_training_steps * warmup_ratio)\n",
    "\n",
    "### In Transformers, optimizer and schedules are splitted and instantiated like this:\n",
    "optimizer = AdamW(model.parameters(), lr=lr,eps=adam_epsilon)  # To reproduce BertAdam specific behavior set correct_bias=False\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=num_training_steps)  # PyTorch scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3dd3f8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\or7l0\\AppData\\Local\\Temp/ipykernel_9176/3438676793.py:11: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  for _ in tnrange(1,epochs+1,desc='Epoch'):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9533423f8bf4a0b90262b6586d28611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<====================== Epoch 1 ======================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\or7l0\\AppData\\Local\\Temp/ipykernel_9176/3438676793.py:17: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for step, batch in enumerate(tqdm_notebook(train_dataloader)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e9bc877750d452c9e4534407c80e54b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.7876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.9956, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(9.0803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.9618, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(9.4560, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(9.0171, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.8775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.9959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.7198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.8343, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.8219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.7221, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(9.0508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.5869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.7670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.6760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.9379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.8623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.7835, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.9347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.7801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.6433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.5852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.9398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.7076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.7564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.8658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.6349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.6679, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.6124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.7603, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.8893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.7608, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.4436, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.7530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.4178, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.7123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.5847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.3884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.2748, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.6707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.9825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.3098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.0885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.3251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.0730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.5792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.2423, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.5919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.0750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.0879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.1360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.0085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.1460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.9452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.7215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.7575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.7588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.6552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.7666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.5139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.0141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.7904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.5913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.7787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.7073, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.4486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.6359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.3358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.6183, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.7106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.4833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.3038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.3278, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.3473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.0186, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.2360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.2228, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.9323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.0736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.1170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.2792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.9935, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.7748, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.9781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.7399, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.5620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.5369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.5688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.5550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.5771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.3416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.6480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.3671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.3112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.5090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.0494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.2814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.1500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.2615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.9549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.9266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.0424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.1224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.9964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.8731, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.6377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.5730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.9535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.4989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.3629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.4043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.3146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.5201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.2332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.5550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.1860, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.4824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.9413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.4441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.2701, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.0574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.1111, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.7448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.1416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.7501, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.2562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.6224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.3135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.2533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.4068, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.3810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.2567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.3107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.4763, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.2203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.1825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.9239, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.2386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.0674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.9989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.7387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.0679, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.6237, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.6805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.3679, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.4668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.5279, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.3765, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.3848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.3968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.2669, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.4146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.0581, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.1277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.1799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.0658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.0044, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7228, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6376, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.8287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.9932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7292, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.4953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.4562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3065, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.1638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.1306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.1335, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0159, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.9445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.9773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.5737, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.5058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6501, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.5560, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.5151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.3772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.3727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.5987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.5332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.2127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.2961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.2902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.0950, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.2989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.4168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.0632, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.2498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.2094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.3614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.1898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.1653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.1550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.0763, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.1939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.1528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.0296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.0215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.1316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.0688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.1423, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8950, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.1424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.0376, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9190, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7577, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7120, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7456, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8849, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9597, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7596, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6560, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7468, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6892, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8222, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7534, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6501, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7368, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5393, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5868, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6315, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4330, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5748, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6100, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7334, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5247, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5342, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6067, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5595, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4560, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6046, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6304, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6368, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5899, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4526, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4401, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6655, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3835, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4765, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3196, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5108, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4706, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4635, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4411, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5565, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3886, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7187, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4763, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7178, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5739, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9279, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4346, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4510, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2974, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6159, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8077, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4274, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4249, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5204, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4921, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2647, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4635, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2886, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7356, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5300, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4454, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6190, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5132, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4696, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5362, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6599, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4261, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4404, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3880, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1892, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2721, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4330, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\tAverage Training loss: 2.4027236539563868\n",
      "<====================== Epoch 2 ======================>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b19bff9a9b46463494eaf9b62b329ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4405, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3838, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4077, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3765, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4921, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5206, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2472, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2784, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5861, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5278, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4675, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4259, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4468, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3998, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4991, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6196, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4897, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4346, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3596, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3991, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2334, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2712, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5077, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2563, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4073, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3849, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6603, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4454, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4100, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2179, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5444, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5186, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5077, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4370, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4675, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2769, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1998, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3892, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3847, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2899, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4503, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5466, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2608, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2330, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2679, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4345, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2599, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4341, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3108, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4587, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2412, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3993, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5228, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5190, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2290, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4204, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3635, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3111, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2731, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5295, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2806, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2829, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2213, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3067, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4069, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5618, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3838, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3089, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4308, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4679, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4510, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3565, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3780, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3827, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3204, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3261, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4356, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3784, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3993, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3860, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2499, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5372, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4317, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3187, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3850, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5634, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4307, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6122, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4346, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4761, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1368, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4610, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2187, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3669, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2897, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3159, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4101, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2081, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4157, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4261, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2778, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5608, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3143, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4196, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3635, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4081, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5698, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5835, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4187, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4856, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5436, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3190, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2998, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2870, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4412, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3256, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2713, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2310, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2669, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4589, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\tAverage Training loss: 0.38211079051427793\n",
      "<====================== Epoch 3 ======================>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cccc9e8b961a42a7828569ccaf847e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2710, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3249, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2534, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3849, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5378, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2111, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2213, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4210, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3269, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4185, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4073, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2952, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1657, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2265, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3870, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2443, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5405, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4856, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4679, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1956, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6956, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2206, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2921, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3712, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5068, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4429, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2679, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3761, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4015, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2221, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3218, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2111, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2404, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2911, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2905, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2698, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3897, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2097, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2544, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1178, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4701, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2682, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1826, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3864, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2310, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5241, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4735, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5624, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2640, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4790, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4069, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2737, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4185, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3226, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4419, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1995, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4404, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2905, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2244, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3712, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3599, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1743, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2856, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2265, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5573, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5624, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1713, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1721, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2911, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4743, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2503, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2313, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2558, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2881, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2806, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2256, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3790, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2595, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4743, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5921, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4099, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4247, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3110, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4972, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3856, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5735, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1958, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2778, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3712, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2827, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3940, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4110, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2748, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4635, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1741, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6247, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1580, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4401, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1372, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4577, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3269, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3694, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2698, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2468, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3111, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2790, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1937, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2850, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2850, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3706, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2341, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2299, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4313, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3072, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3958, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2373, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2608, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1644, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2282, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4310, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4221, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1544, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3089, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1952, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3998, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\tAverage Training loss: 0.3264555291985463\n",
      "<====================== Epoch 4 ======================>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7757be4139fb45598bec4a0a31387317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3687, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3601, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2261, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2630, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1546, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2466, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3135, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9176/3438676793.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mlogits_cls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits_lm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mmask_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtopic_token_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlb\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mb_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0mlabel_lms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mSEQUENCE_LENGTH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m35\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss_set = []\n",
    "learning_rate = []\n",
    "\n",
    "# criterion_lm = torch.nn.CrossEntropyLoss(ignore_index=-1, reduction='mean')\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=-1, reduction='mean')\n",
    "criterion_lm = torch.nn.CrossEntropyLoss(ignore_index=-1, reduction='mean')\n",
    "criterion_cls = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "model.zero_grad()\n",
    "\n",
    "for _ in tnrange(1,epochs+1,desc='Epoch'):\n",
    "    print(\"<\" + \"=\"*22 + F\" Epoch {_} \"+ \"=\"*22 + \">\")\n",
    "    batch_loss = 0\n",
    "    \n",
    "    # train\n",
    "    model.train()\n",
    "    for step, batch in enumerate(tqdm_notebook(train_dataloader)):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_token_type_ids, b_input_mask, b_labels, b_masked_token_idx = batch\n",
    "#         print(b_input_ids)\n",
    "#         print(b_token_type_ids)\n",
    "#         print(b_input_mask)\n",
    "#         print(b_labels)\n",
    "#         print(b_masked_token_idx)\n",
    "        outputs = model(b_input_ids, token_type_ids=b_token_type_ids, attention_mask=b_input_mask)\n",
    "        \n",
    "        # calculate loss\n",
    "        logits_cls, logits_lm = outputs[1], outputs[0]\n",
    "        \n",
    "        mask_label = [topic_token_dict[lb] for lb in b_labels.to('cpu').numpy() ]\n",
    "        label_lms = []\n",
    "        SEQUENCE_LENGTH = 35\n",
    "        \n",
    "        for idx, label in zip(b_masked_token_idx.to('cpu').numpy(),mask_label):\n",
    "            label_lm = np.full(SEQUENCE_LENGTH, dtype=np.int, fill_value=-1)\n",
    "            label_lm[idx] = label\n",
    "            label_lms.append(label_lm)\n",
    "            \n",
    "        label_lms_np = np.array(label_lms)\n",
    "        label_lms_pt = torch.tensor(label_lms_np,dtype=torch.int64).to(device)\n",
    "        loss_lm = criterion_lm(logits_lm.view(-1, logits_lm.size(2)), label_lms_pt.view(-1))\n",
    "        \n",
    "        labels_cls = [1 for _ in range(len(b_input_ids))]\n",
    "        labels_cls = torch.tensor(labels_cls).to(device)\n",
    "        loss_cls = criterion_cls(logits_cls, labels_cls)\n",
    "        \n",
    "        loss = loss_cls + loss_lm\n",
    "        loss.backward()\n",
    "        print(loss)\n",
    "        \n",
    "#         logits = outputs[0].to(\"cpu\").detach().numpy()\n",
    "        \n",
    "#         pred = get_predict_tensor(logits,b_masked_token_idx.to('cpu').numpy())\n",
    "#         answer = [topic_token_dict[lb] for lb in b_labels.to('cpu').numpy() ]\n",
    "        \n",
    "#         answer = torch.tensor(answer)\n",
    "#         loss = loss_fn(pred,answer)\n",
    "#         loss = loss.to(device)\n",
    "#         loss.backward()\n",
    "#         print(loss)\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_loss += loss.item()\n",
    "        \n",
    "    avg_train_loss = batch_loss / len(train_dataloader)\n",
    "    train_loss_set.append(avg_train_loss)\n",
    "    print(F'\\n\\tAverage Training loss: {avg_train_loss}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2efc5ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = next(iter(validation_dataloader))\n",
    "data[3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cf165ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForPreTrainingOutput(loss=None, prediction_logits=tensor([[[ -7.5324,   4.7769,  -5.8239,  ...,  -8.4287,  -9.7536,  -7.3671],\n",
      "         [ -2.6904,   5.2286,  -7.6973,  ...,  -4.0463,  -4.3348,  -2.6985],\n",
      "         [-10.5770,   3.3772,  -8.3321,  ...,  -7.8780,  -8.0841,  -7.6637],\n",
      "         ...,\n",
      "         [ -6.8220,   4.7606,  -7.0810,  ...,  -6.2672,  -7.0951,  -5.3995],\n",
      "         [ -8.4229,   4.9718,  -5.2277,  ...,  -6.9559,  -7.2738,  -7.1324],\n",
      "         [ -7.0484,   6.0130,  -4.7348,  ...,  -6.9919,  -6.7588,  -6.2325]],\n",
      "\n",
      "        [[ -7.1345,   4.0415,  -5.9587,  ...,  -9.2324, -10.2824,  -6.4977],\n",
      "         [ -7.1295,   3.5847,  -7.3339,  ...,  -7.0343,  -7.6060,  -5.6498],\n",
      "         [ -7.9517,   5.5693,  -7.9232,  ...,  -7.9006,  -8.1612,  -7.1819],\n",
      "         ...,\n",
      "         [ -7.5906,   4.8099,  -7.0088,  ...,  -8.9138,  -7.2824,  -6.7442],\n",
      "         [ -6.7460,   6.2802,  -6.3477,  ...,  -9.5336,  -8.1012,  -5.8430],\n",
      "         [ -5.6934,   6.4480,  -7.0061,  ...,  -8.9291,  -7.5552,  -5.6127]],\n",
      "\n",
      "        [[ -7.3862,   3.6596,  -5.7117,  ...,  -8.4478, -10.1165,  -6.4786],\n",
      "         [ -5.2218,   6.8572,  -5.5739,  ...,  -5.7153,  -4.8194,  -2.7996],\n",
      "         [ -9.0185,   6.8353,  -3.8380,  ...,  -8.0095,  -6.0963,  -7.1762],\n",
      "         ...,\n",
      "         [ -8.5553,   5.4342,  -3.4770,  ...,  -6.9162,  -5.7826,  -5.5875],\n",
      "         [ -6.7528,   6.9543,  -3.2223,  ...,  -6.1456,  -5.6564,  -3.9821],\n",
      "         [ -9.3486,   5.0101,  -2.7097,  ...,  -6.1869,  -5.8097,  -5.7885]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.1039,   4.6552,  -5.7913,  ...,  -8.2202, -10.6628,  -6.3578],\n",
      "         [ -6.0754,   6.1995,  -3.6374,  ...,  -4.8036,  -5.9007,  -3.7680],\n",
      "         [ -4.8083,   5.8909,  -4.0835,  ...,  -4.3608,  -2.4643,  -3.1369],\n",
      "         ...,\n",
      "         [ -7.1560,   5.9996,  -4.4696,  ...,  -7.1804,  -8.0245,  -5.6013],\n",
      "         [ -8.8412,   3.5869,  -4.6522,  ...,  -8.9205,  -9.6662,  -6.9421],\n",
      "         [ -8.8731,   4.4203,  -4.3574,  ...,  -7.5763,  -7.0456,  -6.4506]],\n",
      "\n",
      "        [[ -7.3190,   5.1335,  -6.1078,  ...,  -8.7845, -10.7607,  -7.2337],\n",
      "         [ -7.8296,   7.9109,  -7.6587,  ...,  -9.6845,  -6.8148,  -6.0924],\n",
      "         [ -7.4343,   5.1351,  -9.1510,  ...,  -8.0808,  -6.0718,  -6.3410],\n",
      "         ...,\n",
      "         [ -7.9840,   5.6068,  -7.5562,  ...,  -9.7645,  -6.4557,  -6.1917],\n",
      "         [ -8.8699,   1.8719,  -5.8988,  ..., -10.0644,  -7.1982,  -7.1271],\n",
      "         [ -8.9924,   3.3148,  -5.9679,  ...,  -9.7903,  -6.7622,  -7.7073]],\n",
      "\n",
      "        [[ -7.8791,   3.7846,  -5.9215,  ...,  -8.9244, -11.6521,  -7.5128],\n",
      "         [ -5.7357,   7.1983,  -5.4575,  ..., -10.9973,  -6.3403,  -5.4927],\n",
      "         [ -8.8765,   6.1102,  -5.7364,  ..., -10.4847,  -8.8089,  -5.8630],\n",
      "         ...,\n",
      "         [ -6.0628,   5.7781,  -5.2368,  ...,  -9.7412,  -6.6285,  -6.3066],\n",
      "         [ -5.7657,   5.6317,  -5.4241,  ...,  -9.8001,  -6.6403,  -6.2474],\n",
      "         [ -6.5557,   6.5688,  -4.0565,  ...,  -7.7324,  -5.8058,  -4.9901]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), seq_relationship_logits=tensor([[-4.7851,  6.3930],\n",
      "        [-4.6229,  6.5956],\n",
      "        [-4.9063,  6.2041],\n",
      "        [-4.3708,  6.8264],\n",
      "        [-4.5532,  6.4925],\n",
      "        [-4.3562,  6.7678],\n",
      "        [-4.8018,  6.2852],\n",
      "        [-4.5908,  6.5024],\n",
      "        [-5.0854,  6.0408],\n",
      "        [-4.5097,  6.8874],\n",
      "        [-4.7630,  6.5274],\n",
      "        [-4.5293,  6.5490],\n",
      "        [-4.5308,  6.7865],\n",
      "        [-4.6717,  6.7112],\n",
      "        [-4.7278,  6.2418],\n",
      "        [-4.8044,  6.4900],\n",
      "        [-4.8525,  6.6282],\n",
      "        [-4.4650,  6.5166],\n",
      "        [-4.8904,  6.2657],\n",
      "        [-4.8535,  6.2572],\n",
      "        [-4.7516,  6.4586],\n",
      "        [-4.4541,  7.0299],\n",
      "        [-4.5674,  6.1340],\n",
      "        [-4.9011,  6.0900],\n",
      "        [-4.6715,  6.3096],\n",
      "        [-4.5073,  7.1112],\n",
      "        [-4.6248,  6.6331],\n",
      "        [-4.8381,  6.2122],\n",
      "        [-4.6999,  6.1967],\n",
      "        [-4.9585,  6.2675],\n",
      "        [-4.5074,  6.7275],\n",
      "        [-4.7658,  6.1603],\n",
      "        [-4.6613,  6.7394],\n",
      "        [-4.6107,  6.5832],\n",
      "        [-4.7453,  6.6186],\n",
      "        [-4.8668,  6.1405],\n",
      "        [-4.7878,  6.5925],\n",
      "        [-4.7338,  6.5403],\n",
      "        [-4.4025,  6.7953],\n",
      "        [-5.0481,  6.0888],\n",
      "        [-4.4065,  6.6655],\n",
      "        [-4.3920,  7.1847],\n",
      "        [-4.2751,  7.1656],\n",
      "        [-4.8300,  6.0401],\n",
      "        [-4.2587,  7.2513],\n",
      "        [-4.7364,  5.8951],\n",
      "        [-4.9546,  6.2546],\n",
      "        [-4.3826,  6.8743],\n",
      "        [-4.4539,  6.8394],\n",
      "        [-4.4597,  6.8869],\n",
      "        [-4.7307,  6.4406],\n",
      "        [-4.4511,  6.7521],\n",
      "        [-4.8477,  6.0060],\n",
      "        [-4.6268,  6.7443],\n",
      "        [-4.6467,  6.4520],\n",
      "        [-4.6195,  6.8112],\n",
      "        [-4.6543,  6.1657],\n",
      "        [-4.6304,  6.7551],\n",
      "        [-4.5324,  6.5939],\n",
      "        [-4.5010,  6.2550],\n",
      "        [-4.1905,  6.1164],\n",
      "        [-4.7820,  6.4170],\n",
      "        [-4.4660,  6.6065],\n",
      "        [-4.4652,  6.7825]], device='cuda:0', grad_fn=<AddmmBackward>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "data = tuple(t.to(device) for t in data)\n",
    "input_ids, token_ids, mask, label, masked_token_idx = data\n",
    "outputs = model(input_ids, token_type_ids=token_ids, attention_mask=mask)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82f3299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_cls, logits_lm = outputs[1], outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b1893b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 35, 32000])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_lm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f905e12",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9176/1924529737.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlogits_lm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogits_lm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits_lm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits_lm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits_lm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits_lm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "logits_lm = logits_lm.to('cpu').detach().numpy()\n",
    "print(logits_lm.shape)\n",
    "print(len(logits_lm[0][0]))\n",
    "print(np.argmax(logits_lm,axis=2).shape)\n",
    "out = np.argmax(logits_lm,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f2778e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3647,  3665, 13723, 26602, 18556,  1570,  2260,   121, 12461,\n",
       "       11647, 23679,  2307, 18928,  5754,  3665,  2302,  2178,    18,\n",
       "          18,  1504,  6265,  2073,  3665,    18,  3665,  3665,  3665,\n",
       "        3665,  3665,  3665,  3665,  3665,  3665,  3665,  3665],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "307b90aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '홍콩', '시위대', '실탄', '맞아', '중', '##태', '…', '시진핑', '초상', '불태우', '##며', '애도', '시위', '##종합', '##2', '##보', '.', '[SEP]', '이', '문장', '##은', '[MASK]', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "tensor([    2,  6616, 13723, 26602, 18556,  1570,  2260,   121, 12461, 11647,\n",
      "        23679,  2307, 18928,  5754, 27854,  2302,  2178,    18,     3,  1504,\n",
      "         6265,  2073,     4,     3,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(22, device='cuda:0')\n",
      "['사회', '세계', '시위대', '실탄', '맞아', '중', '##태', '…', '시진핑', '초상', '불태우', '##며', '애도', '시위', '세계', '##2', '##보', '.', '.', '이', '문장', '##은', '세계', '.', '세계', '세계', '세계', '세계', '세계', '세계', '세계', '세계', '세계', '세계', '세계']\n",
      "[ 3647  3665 13723 26602 18556  1570  2260   121 12461 11647 23679  2307\n",
      " 18928  5754  3665  2302  2178    18    18  1504  6265  2073  3665    18\n",
      "  3665  3665  3665  3665  3665  3665  3665  3665  3665  3665  3665]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(data[0][3]))\n",
    "print(data[0][3])\n",
    "print(data[1][3])\n",
    "print(data[2][3])\n",
    "print(data[3][3])\n",
    "print(data[4][3])\n",
    "print(tokenizer.convert_ids_to_tokens(out[3]))\n",
    "print(out[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c33498",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
