{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52b7ca8c",
   "metadata": {},
   "source": [
    "# 교차 검증 학습 \n",
    " \n",
    "모델을 학습할 때, 검증을 위해 우리는 train data와 validation data를 분리합니다.  \n",
    "이 경우, validation data는 모델의 학습에 영향을 미치지 않습니다.  \n",
    "따라서 모델이 학습하는 data의 수가 줄어들고, train data에 overfitting 됩니다.  \n",
    "  \n",
    "이를 해결하기 위해 train data와 validation data를 나누는 과정을 여러번 반복하고   \n",
    "다양한 데이터셋을 사용하여 모델을 학습하는 방법을 cross validation (교차 검증 학습) 이라고 합니다.   \n",
    "  \n",
    "cross validation을 사용할 경우 모든 데이터를 학습과 평가에 사용할 수 있다는 장점이 있지만   \n",
    "학습시간이 오래걸린다는 단점이 있습니다..  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea58f04",
   "metadata": {},
   "source": [
    "cross validation에는 다양한 방법이 있지만 이번 노트북에서는 Stratified k-fold cross validation을 사용해보았습니다.  \n",
    "stratified k-fold cross validation을 사용하면  \n",
    "Label의 분포가 불균형한 데이터일 경우 Label의 갯수를 고려하여 train, validation data를 나눠줍니다.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acce2c5c",
   "metadata": {},
   "source": [
    "모델은 klue/bert-base 모델을 사용했습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "541daced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용가능한 GPU수 :  1\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm.notebook import tqdm, tnrange\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"사용가능한 GPU수 : \",torch.cuda.device_count())\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"CPU 사용\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee18bde",
   "metadata": {},
   "source": [
    "Reproduction을 위한 Seed 고정  \n",
    "출처 : https://dacon.io/codeshare/2363?dtype=vote&s_id=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "952759ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "    \n",
    "seed_everything(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b223bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"klue/bert-base\"\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fab9cbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data/train_data.csv\")\n",
    "test = pd.read_csv(\"data/test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b849ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "955c91d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_tokenize(dataset,sent_key,label_key,tokenizer):\n",
    "    if label_key is None :\n",
    "        labels = [np.int64(0) for i in dataset[sent_key]]\n",
    "    else :\n",
    "        labels = [np.int64(i) for i in dataset[label_key]]\n",
    "    \n",
    "    sentences = tokenizer(dataset[sent_key].tolist(),truncation=True,padding=True)\n",
    "\n",
    "    input_ids = sentences.input_ids\n",
    "    token_type_ids = sentences.token_type_ids\n",
    "    attention_mask = sentences.attention_mask\n",
    "    \n",
    "    return [input_ids, token_type_ids, attention_mask, labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac3d446",
   "metadata": {},
   "source": [
    "sklearn의 StratifiedKFold를 불러오고 예측한 데이터를 저장할 수 있는 변수를 만듭니다.  \n",
    "`StratifiedKFold()`에서 `n_split=5`는 5개의 train data와 validation data를 만들겠다는 이야기입니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db4cdc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TEST_DATA = len(test)\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "final_test_pred = np.zeros([NUM_TEST_DATA,7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2df5ae7",
   "metadata": {},
   "source": [
    "parameter들을 정의합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9834cb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-5\n",
    "adam_epsilon = 1e-8\n",
    "epochs = 3\n",
    "num_warmup_steps = 0\n",
    "num_labels = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf2ada4",
   "metadata": {},
   "source": [
    "`train()`, `evaluate()`, `predict()`를 정의합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7bcb168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_dataloader):\n",
    "    train_loss_set = []\n",
    "    learning_rate = []\n",
    "    batch_loss = 0\n",
    "\n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        model.train()\n",
    "\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_token_type_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        outputs = model(b_input_ids, token_type_ids=b_token_type_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss = outputs[0]\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = batch_loss / len(train_dataloader)\n",
    "\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        print(\"\\n\\tCurrent Learning rate: \",param_group['lr'])\n",
    "        learning_rate.append(param_group['lr'])\n",
    "\n",
    "    train_loss_set.append(avg_train_loss)\n",
    "    print(F'\\n\\tAverage Training loss: {avg_train_loss}')\n",
    "    \n",
    "def evaluate(model, validation_dataloader):\n",
    "    # validation\n",
    "    model.eval()\n",
    "    eval_accuracy,nb_eval_steps = 0, 0\n",
    "\n",
    "    for batch in tqdm(validation_dataloader):\n",
    "    \n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_token_type_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, token_type_ids=b_token_type_ids, attention_mask=b_input_mask)\n",
    "            \n",
    "        logits = logits[0].to('cpu').numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "        labels_flat = label_ids.flatten()\n",
    "\n",
    "        tmp_eval_accuracy = accuracy_score(labels_flat,pred_flat)\n",
    "\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    print(F'\\n\\tValidation Accuracy: {eval_accuracy/nb_eval_steps}')\n",
    "    \n",
    "def predict(model, test_dataloader):\n",
    "    pred = []\n",
    "    model.eval()\n",
    "\n",
    "    for batch in tqdm(test_dataloader):\n",
    "\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_token_type_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, token_type_ids=b_token_type_ids, attention_mask=b_input_mask)\n",
    "        logits = logits[0].to('cpu').numpy()\n",
    "\n",
    "        for p in logits:\n",
    "            pred.append(p)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81053b6",
   "metadata": {},
   "source": [
    "`StratifiedKFold()`의 `split()`함수를 사용하면 인자로 주어진 데이터를 train data와 validation data로 나눈 index를 돌려줍니다.   DataFrame에 index를 사용하여 train data와 validation data를 나눌 수 있습니다.   \n",
    "나눠진 데이터로 학습과 평가를 진행한 뒤 test data를 예측합니다.     \n",
    "예측한 데이터는 최종 예측 데이터(`final_test_pred`)에 합쳐집니다.  \n",
    "총 학습에 걸리는 시간은 한번 학습하는데 걸리는 시간 * `n_splits`로 넘겨준 수 ( 여기서는 5 )입니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d173dfc4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0632f3abd834dfd83a59ff8e72e1e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<====================== Epoch 1 ======================>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54fb045412ee40f2875852585c8d7715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCurrent Learning rate:  1.3333333333333333e-05\n",
      "\n",
      "\tAverage Training loss: 0.3570210219845306\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f91877e5a24d2aa68af66146c16d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tValidation Accuracy: 0.8528289891926255\n",
      "<====================== Epoch 2 ======================>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f6fadda8114d989424a1467d44bda0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCurrent Learning rate:  6.666666666666667e-06\n",
      "\n",
      "\tAverage Training loss: 0.20184547494079155\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a71b4826594c928fd58cb80736cfa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tValidation Accuracy: 0.8533852511125238\n",
      "<====================== Epoch 3 ======================>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6eac43e30b42ec8ea8297c7996d575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCurrent Learning rate:  0.0\n",
      "\n",
      "\tAverage Training loss: 0.1371668318915303\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "363f9608bca24a8abaff0ad708a4d954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tValidation Accuracy: 0.8527097902097902\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c535e61e6dc34508872791a9f9f89d27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78dbe7488b304d099686f1ea1c35bc93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<====================== Epoch 1 ======================>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f2f719bb1c4dba88acea53ee5c1119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCurrent Learning rate:  1.3333333333333333e-05\n",
      "\n",
      "\tAverage Training loss: 0.3597159437988534\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "494d9be9f2a9427494e3c6ef890a09c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tValidation Accuracy: 0.8473756357279084\n",
      "<====================== Epoch 2 ======================>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdcd7ffd436d46e6bb09d6f735d6eded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCurrent Learning rate:  6.666666666666667e-06\n",
      "\n",
      "\tAverage Training loss: 0.2004227205620012\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "540e899b58f84d22a796dbae6c6fe082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tValidation Accuracy: 0.8455181182453909\n",
      "<====================== Epoch 3 ======================>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d2cfae9587148d79191fb00911ab4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCurrent Learning rate:  0.0\n",
      "\n",
      "\tAverage Training loss: 0.13471043498773982\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae2d95e2ef5470096ca674f283ccf1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tValidation Accuracy: 0.8490146217418945\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63fe7ec82504496799824416f832543c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59b5aaac6b541ba89de679cd396738f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<====================== Epoch 1 ======================>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbdc16bce5304ab6a42388b73a8b33ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCurrent Learning rate:  1.3333333333333333e-05\n",
      "\n",
      "\tAverage Training loss: 0.38425392524099494\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21c7944c42043a0a2fd0aaaf604d965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tValidation Accuracy: 0.8886880165289256\n",
      "<====================== Epoch 2 ======================>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f61cb0526cf8421482b2fefadcf4b498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCurrent Learning rate:  6.666666666666667e-06\n",
      "\n",
      "\tAverage Training loss: 0.22122074047106785\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926dcc17ecd34639b66a275297569d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tValidation Accuracy: 0.8908733312142403\n",
      "<====================== Epoch 3 ======================>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce733e8364443e68cb60d071590e590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCurrent Learning rate:  0.0\n",
      "\n",
      "\tAverage Training loss: 0.15173925946535127\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dda250a3c4d4b8f8495f7e4011090fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tValidation Accuracy: 0.8887774157660521\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04368537f3ee442eaed715b36d7745c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb1573b7829042ac90148cb817f00d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<====================== Epoch 1 ======================>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be34ad89a713436ca8401b07d4a73a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCurrent Learning rate:  1.3333333333333333e-05\n",
      "\n",
      "\tAverage Training loss: 0.41829780071660644\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d5e0f5683a429893d954b154d07305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tValidation Accuracy: 0.9458041958041958\n",
      "<====================== Epoch 2 ======================>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd8631a34ee411c8c043cdf231979c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCurrent Learning rate:  6.666666666666667e-06\n",
      "\n",
      "\tAverage Training loss: 0.25026649765787734\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a6b81e1c3444cebd241c4817632087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tValidation Accuracy: 0.9434003496503497\n",
      "<====================== Epoch 3 ======================>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d465a3f8b84d478bd410b87665b819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCurrent Learning rate:  0.0\n",
      "\n",
      "\tAverage Training loss: 0.17853587064092846\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bbc9bc7a5d94666a3bc1a2c4102188e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tValidation Accuracy: 0.9446022727272727\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f479104021c4b2c9a1d167fbc1af41a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b282d4f2eb774bb4a8268da35fbfb150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<====================== Epoch 1 ======================>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68fd5fa3b3c74469b2712b8f6214418d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCurrent Learning rate:  1.3333333333333333e-05\n",
      "\n",
      "\tAverage Training loss: 0.3941842956262952\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f80a61638a2d4d72ae1db30d285c9117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tValidation Accuracy: 0.9101617132867132\n",
      "<====================== Epoch 2 ======================>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83d09dc40c10420fb596139725b5dbf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCurrent Learning rate:  6.666666666666667e-06\n",
      "\n",
      "\tAverage Training loss: 0.231594713246564\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d0b2d7c507450da7860d2287542456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tValidation Accuracy: 0.8965909090909091\n",
      "<====================== Epoch 3 ======================>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "055b85f668bf4265a6c9ece3672871a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCurrent Learning rate:  0.0\n",
      "\n",
      "\tAverage Training loss: 0.16084701035354423\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0d6c4f502a4552827a275e1885b009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tValidation Accuracy: 0.8984702797202796\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "575a262c47d44d1aa0a0c104e9be807d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for train_idx, validation_idx in skf.split(dataset[\"title\"],dataset[\"topic_idx\"]):\n",
    "    \n",
    "    dataset_train = pd.DataFrame()\n",
    "    dataset_val = pd.DataFrame()\n",
    "    \n",
    "    dataset_train[\"title\"] = dataset[\"title\"][train_idx]\n",
    "    dataset_train[\"topic_idx\"] = dataset[\"topic_idx\"][train_idx]\n",
    "    \n",
    "    dataset_val[\"title\"] = dataset[\"title\"][validation_idx]\n",
    "    dataset_val[\"topic_idx\"] = dataset[\"topic_idx\"][validation_idx]\n",
    "    \n",
    "    train_inputs = bert_tokenize(dataset_train,\"title\",\"topic_idx\",tokenizer)\n",
    "    validation_inputs = bert_tokenize(dataset_val,\"title\",\"topic_idx\",tokenizer)\n",
    "    test_inputs = bert_tokenize(test,\"title\",None,tokenizer)\n",
    "    \n",
    "    for i in range(len(train_inputs)):\n",
    "        train_inputs[i] = torch.tensor(train_inputs[i])\n",
    "\n",
    "    for i in range(len(validation_inputs)):\n",
    "        validation_inputs[i] = torch.tensor(validation_inputs[i])\n",
    "\n",
    "    for i in range(len(test_inputs)):\n",
    "        test_inputs[i] = torch.tensor(test_inputs[i])\n",
    "    \n",
    "    train_data = TensorDataset(*train_inputs)\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data,sampler=train_sampler,batch_size=batch_size)\n",
    "\n",
    "    validation_data = TensorDataset(*validation_inputs)\n",
    "    validation_sampler = RandomSampler(validation_data)\n",
    "    validation_dataloader = DataLoader(validation_data,sampler=validation_sampler,batch_size=batch_size)\n",
    "\n",
    "    test_data = TensorDataset(*test_inputs)\n",
    "    test_dataloader = DataLoader(test_data,batch_size=batch_size)\n",
    "    \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint,num_labels=num_labels)\n",
    "    model.zero_grad()\n",
    "    \n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=lr,eps=adam_epsilon,correct_bias=False)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=num_warmup_steps,\n",
    "                                                num_training_steps=len(train_dataloader)*epochs) \n",
    "    \n",
    "    for _ in tnrange(1,epochs+1,desc='Epoch'):\n",
    "        print(\"<\" + \"=\"*22 + F\" Epoch {_} \"+ \"=\"*22 + \">\")\n",
    "        # train\n",
    "        train(model, train_dataloader)\n",
    "        \n",
    "        # validation\n",
    "        evaluate(model, validation_dataloader)\n",
    "        \n",
    "    # predict\n",
    "    pred = predict(model, test_dataloader)\n",
    "    final_test_pred += pred\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fdb0be",
   "metadata": {},
   "source": [
    "5번의 교차 학습동안 서로 다른 train, validation data를 통해 학습한 model이 예측한 값은 `final_test_pred`에 더해져 있습니다.   \n",
    "이 예측값을 `argmax`하여 최종 예측값을 만들어냅니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b96c890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.64885781e+01,  8.76850499e-01,  7.11387616e+00,\n",
       "         1.47765276e+01, -1.25753672e+01, -1.30626745e+01,\n",
       "        -1.64131484e+01],\n",
       "       [-7.75764048e+00, -1.09310429e+01,  1.44481805e+00,\n",
       "         3.52703748e+01, -6.21469492e+00, -8.14098918e+00,\n",
       "        -6.04971761e+00],\n",
       "       [ 6.70001668e+00, -1.93561076e+00,  2.65456839e+01,\n",
       "        -2.21080732e+00, -1.30748584e+01, -1.39026191e+01,\n",
       "        -4.75335102e+00],\n",
       "       [ 1.87000976e+01, -6.19321951e+00,  1.93904028e+01,\n",
       "        -6.24161780e+00, -1.12162007e+01, -1.08564138e+01,\n",
       "        -4.77193654e+00],\n",
       "       [-6.87773919e+00, -8.77894616e+00, -3.71424071e-01,\n",
       "         3.61361575e+01, -6.00767535e+00, -7.74340332e+00,\n",
       "        -7.06648469e+00],\n",
       "       [ 1.80406456e+01,  1.09737453e+01,  7.30523503e+00,\n",
       "         6.01799917e+00, -1.61820772e+01, -1.36202390e+01,\n",
       "        -1.70074041e+01],\n",
       "       [-7.52531660e+00, -7.46243680e+00, -4.82346600e+00,\n",
       "        -8.39387345e+00,  1.94720095e+00,  3.75804706e+01,\n",
       "        -5.65621084e+00],\n",
       "       [-7.87091279e+00, -9.79337132e+00,  3.71154729e+00,\n",
       "         3.43135633e+01, -7.61105728e+00, -9.29340065e+00,\n",
       "        -5.72103143e+00],\n",
       "       [-7.77291954e+00, -7.21042627e+00, -6.72831759e-03,\n",
       "        -8.71588206e+00,  3.52121673e+01, -8.03304327e+00,\n",
       "        -1.62070907e+00],\n",
       "       [-7.16261888e+00,  1.35976373e+01, -7.52921772e+00,\n",
       "        -9.38308322e+00,  2.70150633e+01, -1.06027548e+01,\n",
       "        -6.75247562e+00]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1eb50fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9131"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61117e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 2, 2, 3, 0, 5, 3, 4, 4], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_pred = np.argmax(final_test_pred,axis = 1)\n",
    "total_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4672d873",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "submission['topic_idx'] = total_pred\n",
    "submission.to_csv(\"results/klue-bert-base-kfold5.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07053756",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
