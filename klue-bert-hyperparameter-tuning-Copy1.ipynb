{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56d0afe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import logging\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from datasets import load_dataset, load_metric, ClassLabel, Sequence\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a73d2b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"klue/bert-base\"\n",
    "batch_size = 32\n",
    "task = \"nli\"\n",
    "MODEL_P = \"models/klue-bert-base-augmented.pth\"\n",
    "RANDOM_SEED = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24482327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 17):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "    \n",
    "seed_everything(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f60b4519",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec520800",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data/train_data.csv\",index_col=False)\n",
    "test = pd.read_csv(\"data/test_data.csv\",index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d35649c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\or7l0\\AppData\\Local\\Temp/ipykernel_24564/4196436711.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['title'][i] = dataset['title'][i].replace(\"...\",\" 스포츠\")\n",
      "C:\\Users\\or7l0\\AppData\\Local\\Temp/ipykernel_24564/4196436711.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['title'][i] = test['title'][i].replace(\"...\",\" 스포츠\")\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dataset['title'])):\n",
    "    if \"...\" in dataset['title'][i]:\n",
    "        dataset['title'][i] = dataset['title'][i].replace(\"...\",\" 스포츠\")\n",
    "        \n",
    "for i in range(len(test['title'])):\n",
    "    if \"...\" in test['title'][i]:\n",
    "        test['title'][i] = test['title'][i].replace(\"...\",\" 스포츠\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3552fea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NBA 카지노업체와 스폰서 계약…美프로스포츠 사상 처음\n",
      "셰이크 살만 AFC 회장 평양 방문…최휘 국가체육지도위원장 스포츠\n",
      "데얀·김치우 OUT 조영욱 IN…서울 과감한 재건 성과 스포츠\n",
      "아시안게임 만리장성 맞서는 농구 단일팀 이문규 감독 스포츠\n",
      "한화 4천20일 만의 PS vs 넥센 4년 만의 PO 스포츠\n",
      "아시안게임 경기장 잔디 점검한 김학범 중동팀에 유리한 스포츠\n",
      "아가메즈·비예나 등 V리그 외국인 선수 대거 입국…KOVO 스포츠\n",
      "1보 류현진 한국인 첫 MLB 올스타전 선발로 1이닝 스포츠\n",
      "아시안게임 여자축구 전가을 황금세대 책임감으로 새 역 스포츠\n",
      "프로농구 KBL 음주 운전 kt 박철호에 36경기 출전  스포츠\n",
      "먼저 2승 최태웅 감독 우승 기회 왔다. 철저히 준비 스포츠\n",
      "홈런왕 루스 유니폼 67억원에 낙찰…역대 스포츠경매 최고가\n",
      "4쿼터 3점포 4방 OK저축은행 2연패 탈출…신한은행 스포츠\n",
      "패럴림픽 김정숙 여사 아이스하키 관람…장애인스포츠 많이 알려지길\n",
      "WNBA 박지수 LA 스파크스 상대로 4분 39초 출전… 스포츠\n",
      "NBA 경기 도중 난투극 론도 3경기 폴 2경기 출전 정 스포츠\n",
      "류현진 박찬호 이래 18년 만의 한국인 MLB 개막전 승 스포츠\n",
      "아시안게임 동점골 이민아 선수들 속상해해…태극 낭자 스포츠\n",
      "관리의 힘 SK 김광현 5이닝 무실점 컨디션 괜찮아 스포츠\n",
      "MLB 애틀랜타 9회 2사 후 극적인 뒤집기…18년 만의 스포츠\n",
      "프로농구 SK 챔프전 사상 최초로 2패 후 3연승 1승 스포츠\n",
      "베이브 류스 류현진 고교 시절 홈런 1개…통산 타율  스포츠\n",
      "머리에 사구 NC 손시헌 의식 있어…2∼3일 입원 예정 스포츠\n",
      "연장 2골 레스터 FA컵 32강 재경기서 더비카운티에 스포츠\n",
      "한국 남자배구 U21 세계선수권서 중국에 03 패배… 스포츠\n",
      "아시안게임 라건아 효과 누린 남자농구 몽골 잡고  스포츠\n",
      "신인 최다홈런 친 알론소 NL신인상 수상…만장일치는 실패 스포츠\n",
      "아시안게임 이란전 끝낸 김학범호 회복훈련으로 우즈베크 스포츠\n",
      "세인트루이스 33번 김광현 명문 구단 입단 영광·SK 스포츠\n",
      "셰이크 살만 AFC 회장 평양 방문…北 방북목적 등 언급 스포츠\n",
      "일본인 좌완 기쿠치 MLB 시범경기 데뷔전서 시속 153 스포츠\n",
      "프로야구 시범경기 궂은 날씨로 고척 제외하고 모두 취소 스포츠\n",
      "오지환·박해민 포함 아시안게임 예비 엔트리 109명 발 스포츠\n",
      "천병혁의 야구세상 고요와 폭풍 류현진의 최대 무기는 스포츠\n",
      "한화에 뒤집기 LG 류중일 감독 500승…NC 유영준  스포츠\n",
      "손흥민 시즌 6호골 토트넘 유럽 챔스서 아포엘에 3 스포츠\n",
      "사이영상 디그롬 MLB 메츠와 5년 1천561억원에  스포츠\n",
      "1강 전북 무너뜨린 2골…인천 문선민 K리그1 2라운 스포츠\n",
      "뉴올리언스 론도 신들린 21도움…골든스테이트에 19점차 대 스포츠\n",
      "봄 배구 공격득점 500점 박정아 오늘은 50점 주고 스포츠\n",
      "울산 수원과 33 무승부로 ACL행…인천도 강원 꺾고  스포츠\n",
      "화이트 시즌 최다 41점…프로농구 SK 2위 경쟁 안 끝 스포츠\n",
      "비예나 29점 대한항공 삼성화재에 32 승리…4연승 스포츠\n",
      "SI 선정 2018 올해의 스포츠인에 NBA 챔피언 골든스테이트\n",
      "프로야구 잔여 경기 일정 발표…10월 13일 정규리그 종료 스포츠\n",
      "디그롬 ERA 2.43으로 시즌 끝…류현진 2⅔이닝 1 스포츠\n",
      "아시안게임 금메달 깨물어보는 아들 이정후 영상 찍는  스포츠\n",
      "프로농구 SK LG 꺾고 2위 1경기차 추격…최준용 4쿼 스포츠\n",
      "호랑이 김학범 U23 축구대표팀 감독 현재 40∼5 스포츠\n",
      "SK 로맥 시즌 31호포…비거리 140ｍ로 문학 최장거리 스포츠\n",
      "LG워치 스포츠·스타일 내일 출시…최신 안드로이드 탑재\n",
      "아시안게임 나상호 룸메이트 손흥민과 최상의 시너지 효 스포츠\n",
      "이재성·이동국 연속골 전북 울산 20으로 꺾고 선두 스포츠\n",
      "윙백 아쉬움 뒤로 손흥민 27일 C.팰리스전 20호골 스포츠\n",
      "아시안게임 키르기스스탄전 앞둔 김학범 스스로 만든 가 스포츠\n",
      "KT e스포츠라이브로 배틀그라운드 대회 5G 멀티뷰 중계\n",
      "월드컵 3전 전패 위기감 신태용호 멕시코전서 운명 스포츠\n",
      "박미희 흥국 감독 통합우승 vs 5개팀 사령탑 봄배구 스포츠\n",
      "아시안게임 붉은색 vs 붉은색…한국·베트남 관중 뜨거운 스포츠\n",
      "아시안게임 양현종 쾌투박병호 홈런…한국 일본 꺾고  스포츠\n",
      "U20월드컵 이낙연 총리·FIFA 인판티노 회장 결승 스포츠\n",
      "NBA 보스턴 시카고에 팀 최다 기록 56점 차 완승 스포츠\n",
      "영화 봄 여름 가을 겨울 그리고 스포츠 봄을 현대무용으로 옮기다.\n",
      "월드컵 천재 사령탑 멕시코 오소리오 감독 한국전  스포츠\n",
      "OK저축은행·GS칼텍스 프로배구 남녀 선두 도약…돌풍의 핵 스포츠\n",
      "수원 승부차기 끝 전북 제치고 7년 만에 AFC 챔스리그 스포츠\n",
      "손흥민 亞 최초 EPL 2회 월간 MVP…여전히 배고프 스포츠\n",
      "MLB 컵스 팬 인종주의 손동작 논란…구단 구장 접근 스포츠\n",
      "챔스 사나이 호날두 조별리그 6경기 전 경기 득점 스포츠\n",
      "챔프전 만장일치 MVP 이재영 여자부 6번째 통합 M 스포츠\n",
      "벤투호 상승세 한국 축구 FIFA 랭킹 53위로 올해 스포츠\n",
      "2승 삼성 보니야 팬이 날 너무 사랑하는 것 같아 기 스포츠\n",
      "호날두 FIFA 올해의 선수상 2년 연속 수상…메시 또  스포츠\n",
      "상명대서 15년 만에 코리아텐더 4강 신화 재현한 이상 스포츠\n",
      "류현진 6⅔이닝 1실점…시즌 12승·한미 통산 150승 무 스포츠\n",
      "월드컵 지친 몸·무거운 마음 떨친 수비진 스웨덴 방어 스포츠\n",
      "女배구 현대건설 새 용병 거포 헤일리 28일 GS칼텍 스포츠\n",
      "천병혁의 야구세상 신인 계약금은 폭락했는데…천장 찌른  스포츠\n",
      "사과로 시작한 신년사…정운찬 KBO총재 2019년은 혁신 스포츠\n",
      "월드컵 멕시코 한국전 찾을 3만 자국팬에 욕설 자제 스포츠\n",
      "신태용호 답답한 90분…약체 볼리비아와 00 무승 스포츠\n",
      "MLB스카우트 몰고 다니는 린드블럼 미국 진출 내 의지 스포츠\n",
      "라모스 R.마드리드서 뛴 100번째 유럽 대항전서 헤딩 스포츠\n",
      "SK 문경은 7차전이라는 각오로 vs DB 이상범 절 스포츠\n",
      "프로농구전망대 절대 1강 현대모비스 2약 DB 스포츠\n",
      "K리그 × 마블MARVEL 콜라보 MD 9월 첫째 스포츠\n",
      "전태풍 2득점 비디오 판독 후 3점으로 정정…1점차 승부 스포츠\n",
      "반갑다 여자배구…용병 거포 출격 KOVO컵 21일 순천 스포츠\n",
      "15년 만에 외국인 챔피언전 MVP 화이트 팀 우승만 신 스포츠\n",
      "월드컵 전패·아시아 꼴찌 최악 위기에서 반전 이룬  스포츠\n",
      "아시안게임 광복절에 승전보를…김학범호 공격옵션 다변화 스포츠\n",
      "5년만에 챔프전 SK 문경은 감독 이번엔 달라…초짜티 스포츠\n",
      "U20월드컵 눈 찢었던 발베르데 이번엔 한국 관중 스포츠\n",
      "전북 수원과 19일 AFC 챔스리그 8강 2차전…대역전 스포츠\n",
      "아시안게임 이란에 완패 남자농구 허재 감독 공수  스포츠\n",
      "월드컵 독일파 손흥민·구자철 독일전 투톱…장현수  스포츠\n",
      "제임스 떠난 클리블랜드 4연패 제임스 영입 레이커스는 첫 스포츠\n",
      "프랑스 마크롱 대통령 PSG회장에게 축하 좋은 소식 있 스포츠\n",
      "아시안게임 일본전 결승 솔로포 김하성 금메달 꼭  스포츠\n",
      "아시안게임 여자농구 김한별 같은 유니폼 입었다면 남북 스포츠\n",
      "월드컵 ESPN의 톱50 선수 중 손흥민 37위…아 스포츠\n",
      "203.5cm 거포 디우프 트라이아웃 최대어 주목…평 스포츠\n",
      "SNS돋보기 손흥민 EPL 아시아선수 최다 골…자랑스 스포츠\n",
      "토종 득점 1위 문선민 연말 시상식 오겠다는 목표 이 스포츠\n",
      "홍명보 자선경기 22일…2002 레전드 vs K리그 올스 스포츠\n",
      "13년 만에 에버턴 복귀한 루니 등번호 10번 골잡이  스포츠\n",
      "이동국 K리그 500경기 출전…역대 4번째·필드플레이어  스포츠\n",
      "남자배구 신인 드래프트 16일 개최…홍콩 출신 알렉스 관심 스포츠\n",
      "18년 만에 정상 SK냐 16년 만에 역전 우승 DB냐… 스포츠\n",
      "아시안게임 다이빙캐치 후 홈런 박병호 더는 후회  스포츠\n",
      "신태용 감독 월드컵 멤버 80 구상…박주호·홍정호도 가 스포츠\n",
      "인터뷰 류현진 같은 실수 안하려 해…전반기 내 점수  스포츠\n",
      "최준용의 쐐기 3점포…프로농구 SK 전자랜드 꺾고 3연승 스포츠\n",
      "한선수 5년 연속 배구 연봉킹…양효진은 7년 연속  스포츠\n",
      "아시안게임 토너먼트 앞둔 김학범호 아무리 강조해도 모 스포츠\n",
      "FIFA K리그 구단에 월드컵 보상금 지급…전북 7억7 스포츠\n",
      "임창용 4천34일 만에 QS안치홍 만루포…넥센 2경기 연 스포츠\n",
      "아시안게임 남자 3대3 농구 키르기스스탄·대만 연이어 스포츠\n",
      "월드컵 영상 안 봐 vs 안보면 그쪽 손해…스웨 스포츠\n",
      "프로야구전망대 잔치 끝 레이스 재개…LG 넥센·두산 스포츠\n",
      "NBA 미네소타 버틀러 부상에 최악의 대진…올해도 PO 스포츠\n",
      "검찰 조국 재소환 후 신병처리 검토 스포츠동생은 오늘 기소\n",
      "아시안게임 3대3 남자농구 가볍게 8강 안착…몽골에  스포츠\n",
      "당대 최고 포수 양의지 125억원에 NC행…역대 두  스포츠\n",
      "박항서 서로 도움 되는 경기…北 감독 박 뛰어난 감 스포츠\n",
      "최지만 역전승 일등 공신…추격 3점포에 2루타 치고 쐐기 스포츠\n",
      "월드컵 러시아 팬도 손흥민 보러왔어요…인기 스타는  스포츠\n",
      "강민호 투런포 2방으로 KBO 최초 팀 4천500홈런 돌파 스포츠\n",
      "스포츠10대뉴스 ③한국축구 러시아 월드컵 16강 좌절… 스포츠\n",
      "파울링요 데뷔골·말컹 헤딩골 경남 전남에 30 완승 스포츠\n",
      "스포츠 공정위 회부 김호철 남자배구대표팀 감독의 징계는\n",
      "MLB 슈퍼루키 게레로 주니어 드디어 터졌다…멀티홈런 폭 스포츠\n",
      "전북서 10년째 이동국 12일 홈 경기서 팬에게 자동 스포츠\n",
      "두산 PO 5차전 웃으면서 봤죠…SK 두산 만나면 좋 스포츠\n",
      "김연경 13점 한국 女배구 올림픽 예선서 멕시코에 3 스포츠\n",
      "2018 KBO리그 3월 24일 플레이볼…역대 가장 빠 스포츠\n",
      "1위표 22장…류현진 NL사이영상 경쟁서 셔저보다 2배  스포츠\n",
      "산체스 8회 2사까지 노히트 역투…워싱턴 NLCS  스포츠\n",
      "월드컵 심판이 눈감은 반칙 휘슬…더 안타까운 태극전 스포츠\n",
      "남태희 결승골 뒤 안타까운 부상…내일 호주 병원서 검사 스포츠\n",
      "인삼공사만 만나면 펄펄…KCC 선두 2.5경기 차 추 스포츠\n",
      "1점차 신승 김승기 KGC인삼공사 감독 이 경기력으론 스포츠\n",
      "K리그 IFFHS 선정 세계프로축구리그 순위 7년 연속  스포츠\n",
      "7경기 연속포 두산 김재환 기록에 특별한 욕심 없다 스포츠\n",
      "대범한 19세 신인 안우진 경기 끝내고 싶다고 말씀드렸죠 스포츠\n",
      "여자배구 대표팀 VNL 1 2주차 선수 14명 확정…1 스포츠\n",
      "UEFA 챔스리그 4강 마드리드 더비 성사…레알 vs 아 스포츠\n",
      "아시안게임 2연패 도전 남자농구 라틀리프 앞세워  스포츠\n",
      "추신수·강정호·최지만 MLB 시범경기서 나란히 2타수 무 스포츠\n",
      "프로축구 개인상 투표 종료…말컹 첫 1 2부 MVP 석 스포츠\n",
      "프로농구전망대 12연패 kt 10일 2승 제물 삼 스포츠\n",
      "30년 지기 최태웅석진욱장병철 감독 사령탑 지략  스포츠\n",
      "2018 KBO리그 관중 200만명 돌파에 10만6천 스포츠\n",
      "절대 1강 전북 AFC 챔스리그 3연승 도전…이동국 스포츠\n",
      "콜 PS 3승·ERA 0.40 괴력…휴스턴 양키스에 1 스포츠\n",
      "송파구 건물 옥상 화재 스포츠인명피해 없어\n",
      "아시안게임 한국축구와 또 8강전 우즈베크 유린보예프  스포츠\n",
      "7연패 도전 우리은행 vs 박지수의 KB…여자농구 내달 3 스포츠\n",
      "류현진 경쟁자 셔저 마지막 주 최고 선수로 선정…6월 스포츠\n",
      "월드컵 손흥민 만회 골 한국 멕시코에 12로 패 스포츠\n",
      "KBO 개막엔트리 평균 연봉 2억8천443만원…작년보다 1 스포츠\n",
      "NBA 골든스테이트 뉴올리언스에 완승…PO 2라운드 기선 스포츠\n",
      "최지만 고교 선배 류현진 앞에서 16호 홈런…다저스 98 스포츠\n",
      "아시안게임 농구 단일팀 이문규 감독 대만전 두 번  스포츠\n",
      "아시안게임 여자축구 윤덕여 감독 선수들이 새 역사 써 스포츠\n",
      "김지한 19점 현대캐피탈 KB손보 제압…인삼공사도 승 스포츠\n",
      "MLB 다저스 에이스 커쇼 16일 신시내티 상대로 시즌  스포츠\n",
      "아시안게임 이란 상대 고군분투한 라건아 오늘 경기는  스포츠\n",
      "첫 3연승한 LG 현주엽 감독 현재 전력 어느 팀에도  스포츠\n",
      "2018년 피날레도 화려했던 황의조 아시안컵 준비 잘 스포츠\n",
      "남자부 MVP 경쟁…센터 첫 수상 신영석 vs 3년  스포츠\n",
      "아시안게임 김학범 박항서 감독께 죄송…끝까지 정신력  스포츠\n",
      "NBA 휴스턴 오클라호마시티 꺾고 16연승…50승 고지 스포츠\n",
      "아시안게임 지소연 결승골…여자축구 3회 연속 동메달  스포츠\n",
      "프로축구 제주 9명이 싸운 대구에 41 완승…권순형 2 스포츠\n",
      "인터뷰 류현진 5월 한달 굉장히 잘 던져…이상하게 잘 스포츠\n",
      "손흥민 기성용 앞에서 EPL 아시아선수 한시즌 최다골 기 스포츠\n",
      "통일농구 환송만찬…北 경기는 승패있지만 통일의 길엔 없어 스포츠\n",
      "인천 연고 프로스포츠단 발달장애 스포츠교실 공동 운영\n",
      "전광인 우승하러 왔습니다…최태웅 감독 MVP 받으러  스포츠\n",
      "3연패 당한 류현진 8월 힘드네요…포수 스미스 잘못은 스포츠\n",
      "버튼 43점 폭발…프로농구 DB LG 잡고 거침없는 1 스포츠\n",
      "아시안게임 여자농구 Uified Korea 첫 경 스포츠\n",
      "아시안게임 여자농구 코리아 금메달로 가는 길 박지 스포츠\n",
      "데얀 결승골 수원 가시마 꺾고 AFC 챔스리그 16강 스포츠\n",
      "MLB 전설 지터 리베라처럼 만장일치로 명예의 전당  스포츠\n",
      "아시안게임 목소리 높인 박항서 베트남이 일본 못 이길 스포츠\n",
      "배구 간판 김연경 4강 희망 상대 일본 시원하게 꺾고  스포츠\n",
      "아시안게임 여자축구 김혜리 2차전 상대 누구든 120 스포츠\n",
      "남자농구 월드컵 예선 2R 한국시리아전 내달 17일 고 스포츠\n",
      "아시안게임 2연패 노리던 한국 남자농구 이란에 막혀  스포츠\n",
      "벼랑 끝 삼성화재 한국전력에 30 완승…송희채 18득점 스포츠\n",
      "고예림 18점 현대건설 인삼공사에 31 역전승…시즌 스포츠\n",
      "김봉길호 AFC U23 챔피언십 첫판서 베트남에 힘겨운 스포츠\n",
      "인종 장벽 허문 로빈슨 탄생 100년…살아있으면 분노 스포츠\n",
      "천금의 스틸 SK 김선형 말로 표현 못 하겠다는 것이 스포츠\n",
      "월드컵 전국 뒤덮은 붉은 물결…패배 아쉽지만 다음 스포츠\n",
      "펠리페나경복 쌍포 우리카드 시즌 3승…한국전력 3연패 스포츠\n",
      "삼성화재 KB손보에 역전승으로 3연패 끝…KGC인삼공사  스포츠\n",
      "최강한파 대구 낮 최고 기온 영하 7.6도 스포츠83년만에 가장 낮아\n",
      "김인혁 토종 최다 서브 10개 폭발…한국전력 현대 31 스포츠\n",
      "퇴장 공방 전북 신바람 6연승…최강희 감독 통산 2 스포츠\n",
      "아시안게임 한국 2차전 상대 말레이 키르기스스탄에 3 스포츠\n",
      "어빙 28점 NBA 보스턴 브루클린 꺾고 3연승…시즌 스포츠\n",
      "V리그 대한항공 한국전력에 대역전극…2위 포기 못 해 스포츠\n",
      "터키 갈라타사라이 홈 록키 그림 응원현수막이 테러 메 스포츠\n",
      "아시안게임 이승우·황희찬 연속 골 한국 축구 일본에 스포츠\n",
      "아시안게임 3대3 농구 김낙현 통한의 반칙…나 때문 스포츠\n",
      "손흥민 스카이스포츠 선정 TOP 100 중 26위…아시아 유일\n",
      "류현진 13일 2019 MLB 최고 연봉 스트래즈버그와  스포츠\n",
      "프로농구 KBL 제9대 총재에 이정대 전 현대모비스 부회장 스포츠\n",
      "도박 전창진 전 농구감독 무죄 뒤집고 2심 유죄…반성 스포츠\n",
      "日 프로야구 전인미답 400승 한국계 가네다 마사이치 별세 스포츠\n",
      "UMBC 전체 톱 시드 버지니아대 제압…美 대학농구 최 스포츠\n",
      "아시안게임 황재균 연타석포 한국야구 인도네시아에  스포츠\n",
      "월드컵 통쾌한 반란이 시작된다…스웨덴전 앞두고 마지 스포츠\n",
      "워싱턴 아기상어 도가니…WS 우승 안긴 행운의 뚜루루 스포츠\n",
      "아스널 벵거 감독 EPL 810번째 경기서 승리…퍼거슨 스포츠\n",
      "여자배구 드림팀 5일 태국과 대결…1승 1패 한국 이 스포츠\n",
      "MLB 에인절스 FA 시장 큰 손 되나…구단주 게릿  스포츠\n",
      "박기원 감독 2년 전 정규리그 작년 챔프전 올해는 모 스포츠\n",
      "다저스 꺾은 MLB 워싱턴 창단 50년 만에 첫 내셔널리 스포츠\n",
      "현대건설 잔류 FA 원톱 양효진 다음 시즌 좋은 성적으로 스포츠\n",
      "전직 빅리거 향한 기대감…김현수 0.350·박병호초이스  스포츠\n",
      "이학주 등 삼성 선수 32명 11월 2일부터 오키나와 마 스포츠\n",
      "UEFA 챔스 결승 R.마드리드 창 vs 유벤투스  스포츠\n",
      "ML 크리스 데이비스 44타수 연속 무안타…역대 최악 기 스포츠\n",
      "아시안게임 남자배구 결승 이끈 김호철 감독 내 역할은 스포츠\n",
      "아시아 남자배구 강호 이란 올림픽 예선서 쿠바에 3 스포츠\n",
      "중계권 수입 증가 EPL 에이전트 지급액도 한해 2천억 스포츠\n",
      "러시아에서 6번째 우승을…브라질 2018 월드컵 플랜 스포츠\n",
      "아시안게임 김연경 32점 대폭발…한국 여자배구 일본  스포츠\n",
      "월드컵 D30 ② 태극전사 생존 경쟁…최강 베스트  스포츠\n",
      "화이트삭스 FA 투수 카이클 영입 발표…3년 5천550만 스포츠\n",
      "탬파베이 최지만 연속 범타 후 교체…시즌 타율 0.263 스포츠\n",
      "네이버 스포츠 주제판에 AI 콘텐츠 자동 추천 시범 적용\n",
      "6경기 연속 QS 넥센 최원태 AG 대표 뽑힌다면  스포츠\n",
      "프로농구 DB 시즌 첫 연승…최하위 삼성은 속절없이 7연패 스포츠\n",
      "ML 슈퍼스타 하퍼 이적 후 첫 친정방문…팬들은 환영해 스포츠\n",
      "6위 뉴올리언스 3위 포틀랜드 잡고 NBA PO 1차전  스포츠\n",
      "류현진 메츠전 7⅔이닝 무실점…시즌 8승으로 NL 다승  스포츠\n",
      "류현진 아시아 최초 사이영상 1위 표 획득…수상엔 실패 스포츠\n",
      "프로농구 DB kt 대파하고 3연승…단독 6위 PO 진 스포츠\n",
      "아시안게임 패배는 잊어라…인도 상대로 설욕 나서는 여자 스포츠\n",
      "최룡해 北 노동당 부위원장 리우 도착…스포츠외교 돌입종합2보\n",
      "손흥민 20·21호골 펑·펑…차범근·박지성 모두 넘었다 스포츠\n",
      "이런 게 찰떡 호흡…류현진 포수 마틴과 ERA 1.6 스포츠\n",
      "WNBA 박지수 또 만난 시애틀전서 4득점…팀은 741 스포츠\n",
      "삼성 기어 스포츠·기어 아이콘X 내일 국내 출시\n",
      "3년 재계약 차상현 GS칼텍스 감독 2년 연속 봄배 스포츠\n",
      "현지 언론 PS 전망 어둡지만 강정호·벨이 55홈런 합 스포츠\n",
      "신입생 어나이 3년차 알레나에 판정승…기업은행 2연 스포츠\n",
      "프로농구 현대모비스 두 경기 연속 100득점…역시 우승 스포츠\n",
      "로봇 심판 5년내 MLB에 도입…MLB 심판들 노사계약 스포츠\n",
      "FIFA 러시아월드컵 후원사 계약 난항…34개 중 12개 스포츠\n",
      "아시안게임 손흥민 결승골 한국 키르기스에 10 승리 스포츠\n",
      "아시안게임 단일팀 이문규 감독 12일 훈련했지만 서너 스포츠\n",
      "ERA 1.73·32이닝 연속 무실점·7연승…류현진의 놀라 스포츠\n",
      "SK 헤인즈 뛴 경기 1승 6패…개인 득점도 평균 8.7 스포츠\n",
      "SK 떠나 일본 야구로 간 투수 산체스 내년 연봉 36억 스포츠\n",
      "아시안게임 파란 천 뒤에 가려진 단일팀…첫 승 위한 담 스포츠\n",
      "천병혁의 야구세상 LG 108억 vs NC 27억…관중 스포츠\n",
      "손흥민 26분 뛴 토트넘 유로파 32강 겐트 원정서 0 스포츠\n",
      "KBO 사무총장·KBOP 분업…야구 산업화 초석 다지기 스포츠\n",
      "아시안게임 김학범호 살림꾼 장윤호 부상과 맞바꾼  스포츠\n",
      "두산 LG전 15연승…두산은 우승에 한 발 더 LG는  스포츠\n",
      "SON 활용법·수비 조직력·20의 명단…유럽평가전 체크 스포츠\n",
      "폭염에 관중 20 줄었지만…KBO리그 8년 연속 관중 6 스포츠\n",
      "중앙대OB 올스타전야제 3X3최강전 우승…한양대에 21 스포츠\n",
      "디우프 38점 인삼공사 GS칼텍스 제압…현대건설과 결 스포츠\n",
      "U19축구팀 카타르와 1112위전…이강인은 경고누적  스포츠\n",
      "15년 만에 감독으로 북한 가는 허재 선수 때보다 더 설 스포츠\n",
      "아시안게임 남자농구 태국 꺾고 3연승…난적 필리핀 스포츠\n",
      "KCC전자랜드 5차전…1차전 승리팀 vs 5차전 징크스  스포츠\n",
      "세계 최강 양궁 마지막날 金金金…여자 축구 일본에  스포츠\n",
      "아시안게임 라건아·로숙영 남녀 농구 동반 2연패 책임 스포츠\n",
      "월드컵 16강 좌절에도 값진 1승…광장에 가득 찬 대 스포츠\n",
      "남자배구 벨기에전 03 완패…전패로 도쿄올림픽 세계예선 스포츠\n",
      "축포 4방 벤투호 우즈베크 꺾고 6경기 연속 무패 신 스포츠\n",
      "월드컵 32개 팀 중 31위…야후스포츠 한국에 박한 평가\n",
      "아산 회생 기회 생겼다…20일까지 시민구단 전환 시 참 스포츠\n",
      "월드컵 D30 ⑤ 태극전사 16강 전진기지 베이스캠프 스포츠\n",
      "U20월드컵 베네수엘라 응원단 국기 압수 논란 한국  스포츠\n",
      "KCC 1위 현대모비스 또 제압…상대 전적 3승 1패 우 스포츠\n",
      "아시안게임 여자농구 이문규 감독 첫 승 영광…우리 플 스포츠\n",
      "프로배구 화제의 신인 김명관·알렉스 11월 출격은  스포츠\n",
      "ZiPS 예측 강정호 99경기 출전해 타율 0.250· 스포츠\n",
      "한국 여자배구 사제 더비 브라질에 03 완패…VNL  스포츠\n",
      "NBA 최고령 41세 카터 애틀랜타로 이적…21번째 시즌 스포츠\n",
      "에이스의 숙명 손흥민 집중마크 이겨내야 한 단계 도약 스포츠\n",
      "수원 염기훈 기록의 사나이 우뚝…K리그 역대 1호 100 스포츠\n",
      "통일농구 방북단 평양行…조명균 평화 진전 계기 됐으면 스포츠\n",
      "손흥민 풀타임케인 해트트릭 토트넘 아포엘에 30  스포츠\n",
      "류현진 에인절스 잡으면 코리안 빅리거 세 번째 MLB 통 스포츠\n",
      "이용찬 6년만의 완투승 두산 LG전 17연승…LG 8 스포츠\n",
      "찬란한 5월…류현진 메츠전 7⅔이닝 무실점 역투·이달 ER 스포츠\n",
      "인삼공사 김승기 감독 30점 차 대승 선수들 정신력이  스포츠\n",
      "프로농구전망대 헤인즈 이번 주에는 복귀…윌리엄스는 D 스포츠\n",
      "아시안게임 남자농구 허재 감독 변형수비로 클락슨 막은 스포츠\n",
      "쌍용차 스포츠마케팅으로 유럽 브랜드 경쟁력 강화\n",
      "박지수 WNBA 신인 드래프트 전체 17순위로 미네소타에 스포츠\n",
      "커쇼의 불쇼…다저스 충격의 역전패로 NLCS 진출 실 스포츠\n",
      "프로농구 개막 ③ 헤인즈의 1만점·양동근의 900스틸… 스포츠\n",
      "50세 구대성 1이닝 무실점 깜짝투…이젠 더 못 스포츠\n",
      "6연패 수렁 SK 문경은 감독 쏜튼 적응에 시간을 줘야 스포츠\n",
      "역대 최고 2루수 정근우 올해 목표는 138경기 이상 스포츠\n",
      "단독 21연패 여자농구 KDB생명 이달 말 18년 만 스포츠\n",
      "여자배구 대표팀 19일 VNL 1주차 참가 위해 세르비아 스포츠\n",
      "전세진 멀티골 U19 축구대표팀 AFC 챔피언십 결 스포츠\n",
      "이면도로에 쌓인 눈 스포츠 출근길 조심하세요\n",
      "아시안게임 상처 컸던 영광…선동열 감독 국가대표  스포츠\n",
      "KBL 전창진 전 감독 대법판결 남았고 리그 구성원으로 스포츠\n",
      "월드컵 죽도록 뛰고 눈물 쏟은 태극전사 국민 생각하며 스포츠\n",
      "월드컵 멕시코 에르난데스 오늘까지 즐기고 한국전 준비 스포츠\n",
      "U20월드컵 축구 수도 수원의 열렬한 응원전 3만34 스포츠\n",
      "탬파베이 6년만에 AL 디비전시리즈 진출…최지만 1타수 스포츠\n",
      "박지현 20점…한국 인도네시아 꺾고 아시아 U18 女농 스포츠\n",
      "아시안게임 남자농구 클락슨의 필리핀 꺾었다…4강 진출 스포츠\n",
      "NBA 피 말리는 서부 PO 경쟁…5위부터 9위까지 1경기 스포츠\n",
      "8강행 무산 여자축구 U17월드컵서 콜롬비아와 1 스포츠\n",
      "올해 프로야구 미스터 올스타 부상은 KIA 세단 더  스포츠\n",
      "프로농구 현대모비스 DB잡고 4연승…라건아 쐐기블록슛 스포츠\n",
      "2명 퇴장 빌바오 MSN 총출동 바르사에 21 승리 스포츠\n",
      "아시안게임 김학범 우즈베크전은 창과 창의 대결…절실함 스포츠\n",
      "FC서울 지독한 불운에 눈물…인천과 11 무승부 7경 스포츠\n",
      "프로농구전망대 잔치 끝난 프로농구 이제는 치열한 순 스포츠\n",
      "아시안게임 AG행 막차 탄 황재균 3경기 연속 홈 스포츠\n",
      "MLB 가문의 영광…조부 따라 홈런·부친 따라 사이클링 스포츠\n",
      "아시안게임 오자마자 더블더블 박지수…단일팀 합류 효 스포츠\n",
      "1년 자격정지 김호철 감독 체육회 재심 청구…팬들에 스포츠\n",
      "NBA 클리블랜드 연패는 탈출했지만…꼴찌 올랜도에 1점차 스포츠\n",
      "프로농구 삼성 kt에 1점 차 승리 거두고 3연승 6강 스포츠\n",
      "5세트 승부사 김연경 18점…엑자시바시 챔프전 2승  스포츠\n",
      "간절함이 만든 승리 기업은행 선두 GS칼텍스 꺾고 5 스포츠\n",
      "아시안게임 코트 위의 작은 통일…여자농구 코리아 감 스포츠\n",
      "아시안게임 캡틴 손흥민 금메달은 국민의 것…눈물도 스포츠\n",
      "프로야구전망대 마지막 주 관전포인트 5위 싸움·두산  스포츠\n",
      "아시안게임 대표팀에 승선하지 못했던 KBL유망주들의 위 스포츠\n",
      "대투수가 탄생했던 그 경기…김광현 벌써 5번째 KS 4차 스포츠\n",
      "내 축구철학은 승리하는 것…박항서 다큐 14일 베트남 스포츠\n",
      "복사근 부상 아가메즈 16일 PO 1차전 출격…90 스포츠\n",
      "10점 만점 네이마르 기적의 주역…후반 43분부터 2 스포츠\n",
      "총 홈런 6천776개·한 경기 13홈런…2019 MLB 홈 스포츠\n",
      "아시안게임 프리킥 실점…한국 축구 베트남에 31 스포츠\n",
      "500골 메시 역시 해결사…4골 중 1골 후반 30분  스포츠\n",
      "류현진 양키스전 홈런 3방에 4⅓이닝 7실점…ERA 2 스포츠.\n",
      "펠리페 트리플크라운…우리카드 OK저축은행에 혈전 끝 승리 스포츠\n",
      "다시 라이트로 김희진 올림픽 본선 진출과 메달만 보고 스포츠\n",
      "유리천장 깬 박미희 감독 그냥 엄마 말고 강한 엄마  스포츠\n",
      "바르셀로나 시즌 첫 엘클라시코 레알 마드리드에 32 스포츠\n",
      "프로농구 선두 DB 삼성 잡고 8연승 질주…두경민 26점 스포츠\n",
      "아시안게임 4위 마감 박항서 매직…베트남 축구의 희망 스포츠\n",
      "한화 26년 만에 전반기 최고 성적…승률 0.584·2위 스포츠\n",
      "귀화 추진 배구 선수 알렉스 프로행 도전…태극마크도 스포츠\n",
      "英언론 U20월드컵 우승한 어린 사자들 EPL서는 스포츠\n",
      "스포츠10대뉴스 ⑦아시안게임 야구 금메달에도 병역 논란 스포츠\n",
      "MLB 인종장벽 허문 재키 로빈슨 첫 계약서 경매…57억원 스포츠\n",
      "NBA 휴스턴 3쿼터만 50점…플레이오프 2R 진출 1승  스포츠\n",
      "총에 맞은 오티스 보스턴 구단 비행기로 미국 이송…입원  스포츠\n",
      "FIFA 보고서에 한국잉글랜드 월드컵 개최지 투표 거래 스포츠\n",
      "전북 현대 K리그 2연패…역대 최다 잔여경기 남기고 우승 스포츠\n",
      "아시안게임 銀 합작한 여자농구 중국도 하나된 남북의  스포츠\n",
      "정규리그 MVP 대한항공 집안싸움…정지석 밀어주기가  스포츠\n",
      "영상 식지 않은 박항서 매직…북한과 친선경기도 응원 스포츠\n",
      "레알 마드리드 국왕컵 32강 첫 경기서 3부리그 팀에 2 스포츠\n",
      "마지막 올스타전 김주성 진짜 은퇴할 때는 우는 대신 웃으 스포츠\n",
      "통일농구 선수단 평양도착…北 열렬히 축하…만날수록 정 통 스포츠\n",
      "제라드 4골 관여 리버풀 레전드 R.마드리드와 자선경 스포츠\n",
      "류현진 시범경기 마지막 등판 5이닝 4실점 3자책…패전투 스포츠\n",
      "김연경 출전 한국태국 배구 올스타전 4월 8일 화성 스포츠\n",
      "FIFA 2026년 월드컵부터 출전국 48개국으로 만장 스포츠\n",
      "UEFA챔피언스리그 본선 32개팀 확정…EPL 5개팀 참가 스포츠\n",
      "MLB 휴스턴·양키스 ALDS 첫 승리…애틀랜타·워싱턴 N 스포츠\n",
      "U20월드컵 종가 잉글랜드 베네수엘라 꺾고 역대 스포츠\n",
      "프로농구 현대모비스 삼성 30점차 대파…3위 SK 바짝  스포츠\n",
      "축구 꿈나무들의 대열전 2018 칠십리 축구연맹전 22 스포츠\n",
      "손흥민 20호골 꽝…차범근 넘어 31년 만에 한국인 시 스포츠\n",
      "선수 몸값만 1조1천600억원…맨시티 역대 가장 비싼  스포츠\n",
      "아시안게임 박항서 매직 잠재운 김학범의 필승 전술… 스포츠\n",
      "류현진 MLB 통산 평균자책점 2점대 진입…압도적인 20 스포츠\n",
      "극적 역전승 김종민 감독 한 세트만 따면 반전 오리라 스포츠\n",
      "아시안게임 3연속 우승 노리는 선동열호 격전지 자카르 스포츠\n",
      "월드컵 조별리그 첫 탈락 독일 뢰프 충격적 패배… 스포츠\n",
      "손흥민 시즌 최종전서 리그 15호골·득점 TOP 10 진 스포츠\n",
      "아시안게임 김연경의 황금 세대를 살려라…산적한 숙제 안 스포츠\n",
      "SK 외국인 켈리 vs 두산 토종 이용찬 KS 3차전 선 스포츠\n",
      "검찰 칼날 위에 선 미르·K스포츠…의혹 밝혀질까\n",
      "월드컵 훈련장 찾은 독일 기자 솔직히 한국팀에 관심  스포츠\n",
      "19호골 손흥민 팀내 두 번째 높은 평점 8.64 스포츠\n",
      "롯데 듀브론트 4연승 하고도 아내는 100 만족 못할 스포츠\n",
      "통합 6연패 눈앞 위성우 감독 다 쏟아내 준 선수들  스포츠\n",
      "아시안게임 밤마다 시험까지 봤어요…소통 길 열리니  스포츠\n",
      "LG 오지환 KIA 양현종과 51번째 대결에서 첫 홈런… 스포츠\n",
      "아시안게임 박항서호 응원하자 베트남팬 열기에 자카르 스포츠\n",
      "얼빠진 프로배구 작년 공으로 플레이…경기 중 알아차려종 스포츠\n",
      "MLB닷컴 판타지랭킹…추신수 176위·류현진 188위·강정 스포츠\n",
      "태극전사 16강 실패 아쉬움 품고 귀국…환호와 날계란 스포츠\n",
      "논란 딛고 MVP로 우뚝 선 두경민 코트·생활 모두 인정 스포츠\n",
      "프로농구 kt 서동철 감독 소외 계층 어린이 위해 1천만 스포츠\n",
      "朴대통령 스포츠로 건강하고 행복한 대한민국을\n",
      "한국도로공사 현대건설 완파…정규시즌 우승까지 승점 3 스포츠\n",
      "선두 두산 산체스 넘어 SK에 2연승…LG 난타전서 삼 스포츠\n",
      "다저스 감독 류현진 30일 애리조나전 등판…9월엔 조정할 스포츠\n",
      "4위 LG 속절없이 5연패…5위 넥센에 1.5경기 차로  스포츠\n",
      "아시안게임 내전 아픔 속에 16강 진출한 시리아의 위 스포츠\n",
      "아시안게임 NBA 선수 클락슨 필리핀 대표 출전 확정 스포츠\n",
      "프로농구 DB 2차 연장 끝에 LG 꺾고 2연패 뒤 첫  스포츠\n",
      "프로농구 SK 18년 만에 우승 감격…MVP는 화이트 스포츠\n",
      "아시안게임 필리핀 대표 NBA 가드 클락슨 자카르 스포츠\n",
      "류현진 한국인 첫 MLB 올스타 선발 투수…엄청난 영광 스포츠\n",
      "서울 안델손 결승골로 수원에 21 역전승…13경기 무패 스포츠\n",
      "아가메즈 20득점 우리카드 KB손보 잡고 5연승·2위 스포츠\n",
      "토종 거포 서재덕 공익 근무 시작…신인 김명관 활약 스포츠\n",
      "통합우승 도전 박미희 흥국생명 감독 챔프 1차전 꼭  스포츠\n",
      "마야 충분히 쉬어…현대건설 토종 선수들 투혼으로 4 스포츠\n",
      "아우베스 PSG 합류는 아내가 파리를 좋아해서…펩 감독께 스포츠\n",
      "배구 대표팀 내년 1월 올림픽 예선전 때 24일간 소집으 스포츠\n",
      "월드컵 축구협회 멕시코전 오심 있었다…FIFA에 공식 스포츠\n",
      "MLB 양키스 콜에 역대 투수 최고액 7년 2억4천500 스포츠\n",
      "월드컵 전훈 마친 신태용 감독 훈련 성과에 만족…90 스포츠\n",
      "e스포츠협회 선수 행정지원 강화한다…관리시스템 정비\n",
      "고예림 26점 현대건설 5연승으로 5년 만에 정상 탈 스포츠\n",
      "네이마르 PSG이적 후 가장 먼저 한 일 등번호 10번 스포츠\n",
      "극과 극 스포츠강원은 폭설 부산은 개나리\n",
      "프로배구 개막 ③ 남자부 대한항공·현대캐피탈 탄탄…여자 스포츠\n",
      "스포츠10대뉴스 ⑨쌀딩크 박항서 열풍 베트남을 휩쓸다\n",
      "아시안게임 3대3 남자농구 태국 꺾고 결승 진출…은메 스포츠\n",
      "99년생 깜짝선발 NC 김재균 더 준비해서 선발로 뛰 스포츠\n",
      "6천700만분의 1 확률…MLB 코치 한 라운드서 두 스포츠\n",
      "데이터 활용·FA 제도 개선·AI…KBO 윈터미팅 다양한 스포츠\n",
      "이달의 투수상 노리는 류현진 31일 메츠전 5월 마지막  스포츠\n",
      "숨은 주역 도로공사 문정원 3경기 15세트…죽을 것  스포츠\n",
      "20년 만의 잠실 홈런왕 김재환 KBO리그 MVP…신 스포츠\n",
      "전북 최강희 감독 톈진 분석 끝…ACL 예선 1위 위해  스포츠\n",
      "펠리페 없어도 토종 삼각편대 활약…우리카드 현대 3 스포츠\n",
      "이치로 MLB 도쿄 개막전에서 1타수 무안타 1볼넷…시애 스포츠\n",
      "월드컵 ④ K리거 소속팀서 선의의 경쟁…유럽파는  스포츠\n",
      "DB 1·2위 맞대결서 SK 제압…김주성 마지막 학생체  스포츠\n",
      "신장 194㎝ 13세 농구 유망주 서울 SK가 찜…K 스포츠\n",
      "kt SK 4연패 빠뜨리고 4연승…헤인즈 빛바랜 트리플  스포츠\n",
      "도르트문트만 만나면 못 말리는 손…왜 잘하는지 나도  스포츠\n",
      "알리 28점 GS칼텍스 3연승 행진…알레나 없는 인삼 스포츠\n",
      "아시안게임 장윤호 공백 막는 이진현 120 능력 스포츠\n",
      "SK 켈리 4년 걸린 포스트시즌 첫승 슬프지만 의미 커 스포츠\n",
      "U20월드컵 이탈리아 우승후보 프랑스 꺾고 8강 진출 스포츠\n",
      "대역전극 KB손보 시즌 첫 연승…도로공사도 IBK에  스포츠\n",
      "ESPN 휴스턴 사인 훔치기 올해도 조사 대상…다른 구 스포츠\n",
      "MLB닷컴 오늘 개막한다면 추신수 3번·최지만 4번·강정 스포츠\n",
      "월드컵 자신만만 멕시코 언론…한국 F조 최약체 꼬리 스포츠\n",
      "ACL 16강행 좌절 제주 조성환 감독 리그에서 반등 스포츠\n",
      "임도헌라바리니 보령 VNL 기간 남녀 배구대표팀 사령탑 스포츠\n",
      "한국 여자배구 폴란드 31로 제압…VNL 3승 12패로 스포츠\n",
      "우리은행 여자프로농구 정규리그 6년 연속 1위…역대 최다 스포츠\n",
      "프로농구 kt 로건 없이도 삼성 완파…벌써 지난해 10승 스포츠\n",
      "프로농구 구단들 기대 이하 외국인 선수들 과감한 손 스포츠\n",
      "12연패 탈출 견인 김학민 KB손보의 기둥…책임감  스포츠\n",
      "영상 베트남 영웅 박항서 다른 나라서 성과 있으니 스포츠\n",
      "아시안게임 조별리그 사이 미니 휴식기…허재號 컨디션 스포츠\n",
      "아시안게임 남자배구 대만과 리턴매치서 극적인 승리…결 스포츠\n",
      "멀어진 정규리그 우승 현대캐피탈 KB에 풀세트 접전  스포츠\n",
      "기대 모은 NBA 출신 그레이 3점슛 12개 모두 실패  스포츠\n",
      "만만치 않았던 10월 새 얼굴들…벤투호 UAE행 경쟁은 스포츠\n",
      "ESPN 역대 NBA 최강팀은 20162017시즌 골든 스포츠\n",
      "추신수 연봉 236억원으로 MLB 31위…류현진은 53위 스포츠\n",
      "아시안게임 베트남 기적 박항서 조국을 사랑하지만  스포츠\n",
      "女배구 드림팀 5일 태국과 대결…1승 1패 한국 이번 스포츠\n",
      "K리그 득점 1위 묶은 아마추어 김해시청…FA컵 16강 스포츠\n",
      "아시안게임 이란전 앞둔 김학범 최악 상황도 대비…날씨 스포츠\n",
      "프로농구 SK 76.2 확률 잡았다…KCC 꺾고 4강  스포츠\n",
      "월드컵 티켓 확보 대륙별 경쟁 본격화…아시아 최소 7장 스포츠\n",
      "프로농구 결산 ③ 엇박자 행정에 팬들은 외면…정규리그  스포츠\n",
      "기업은행 7시즌 만에 PS 탈락…GS칼텍스 5년 만에  스포츠\n",
      "월드컵 통쾌한 반란 실패한 신태용 감독 골 운 따 스포츠\n",
      "로버츠 다저스 감독 류현진 2차전 혹은 3차전 등판할  스포츠\n",
      "표승주 2주 부상 진단…시름 깊어지는 김우재 IBK기업은 스포츠\n",
      "셔저 6이닝 노히트 불꽃투…MLB 워싱턴 NLCS서 쾌조 스포츠\n",
      "남자배구 임도헌 감독 조 추첨 결과 큰 의미없어…무조건 스포츠\n",
      "현대캐피탈 삼성화재 꺾고 1위 탈환…IBK기업은행 3연승 스포츠\n",
      "MLB 휴스턴 벌랜더 앞세워 ALDS 첫 승리…애틀랜타  스포츠\n",
      "데뷔전서 시속 153㎞…안우진 실력 떠나 좋은 사람부터 스포츠\n",
      "웃음바다 된 MLB 감독 기자회견 트럼프 대통령 탄핵 찬 스포츠\n",
      "화웨이 워치 GT 스포츠 국내 출시…24만9천원\n",
      "영상 코리안 몬스터 류현진 한국인 빅리거 4번째로 스포츠\n",
      "류현진 옛동료 그란달에 홈런 허용…밀워키전 5이닝4실점3 스포츠\n",
      "문 대통령 스포츠가 정치·이념 장벽 뛰어넘는 것 보여줄 것\n",
      "월드컵 주장 기성용 멕시코 생각보다 강해…잘 준비할  스포츠\n",
      "월드컵 외국 언론 VAR 역풍 맞은 한국 16강 가 스포츠\n",
      "인터뷰 류현진 그나마 최소실점 막아…버텨야 한다고 마 스포츠\n",
      "GS칼텍스 1라운드 전승 이끈 강소휘 생애 첫 라운드 스포츠\n",
      "프로배구개막 ③최고의 외국인 거포는…비예나·레오 가빈 스포츠\n",
      "메시 바르셀로나서 5년 더 뛴다…2021∼2022년까지  스포츠\n",
      "반갑다 작은거인 클리블랜드 토머스 지각데뷔에 3연 스포츠\n",
      "아시안게임 여자농구 이문규 감독 첫 경기 모든 선수  스포츠\n",
      "롯데 PS 불씨 살린 노경은 오늘 경기 잡으면 결과 아무 스포츠\n",
      "미국 CBS스포츠 류현진 2년간 4천만달러 계약 예상\n",
      "아시안게임 3대3농구 여자대표팀 조1위로 8강 진출… 스포츠\n",
      "이승우 세리에A 베로나와 4년 이적 계약…오늘 메디컬테스 스포츠\n",
      "배구협회 대표팀 포기 시도 김호철 감독에 1년 자격정 스포츠\n",
      "ML 크리스 데이비스 오늘도 무안타…61타석 연속 무안타 스포츠\n",
      "호날두 유럽 챔스 2경기 연속 멀티골…레알 도르트문트  스포츠\n",
      "프로농구 결산 ② 허훈·안영준 뜨고…김주성은 은퇴로 스포츠\n",
      "류현진 32이닝서 연속 이닝 무실점 마감…박찬호 넘기 실 스포츠\n",
      "스포츠 라이벌 소개한 책 신들의 전쟁 발간\n",
      "여자배구 현대건설 FA 고예림 영입…최대어 양효진은 잔류 스포츠\n",
      "영상 감격 또 감격 스포츠백두산 정상에 선 두 정상\n",
      "아시안게임 라건아 고군분투 남자농구 이란에 막혀  스포츠\n",
      "아시안게임 선동열 감독 고정 마무리 없이 상황에 따라 스포츠\n",
      "김현 1골 1도움 아산 부산에 역전승…K리그2 선두  스포츠\n",
      "한국 여자축구 아시안컵 한일전 00 무승부…첫 승 무산 스포츠\n",
      "선구자 박찬호 개막전 등판 앞둔 류현진 응원 파이팅 몬 스포츠\n",
      "프로축구 수원 서정원 후임에 이임생 감독 선임…2년 계약 스포츠\n",
      "프로배구 FA 30일 공시…여자부 원톱 양효진 현대건설 잔 스포츠\n",
      "CBS스포츠 하락세 류현진 체인지업 예전 같지 않아\n",
      "아시안게임 겸손한 황의조 흥민이가 좋은 패스…승우도  스포츠\n",
      "3점포 13개 KEB하나은행 OK저축은행 꺾고 2연승 스포츠\n",
      "원주DB 우승 이끈 버튼 NBA 데뷔 득점…OKC 소속으 스포츠\n",
      "최주환 맹타후랭코프 역투 두산 SK에 반격…KS 승 스포츠\n",
      "류현진 스트라스버그 부러워…1억달러 이야기 나도 듣고  스포츠\n",
      "프로배구 OK저축은행 김세진 전 감독 후임 선임 지연  스포츠\n",
      "권창훈 2년6개월 만에 A매치 득점…더 좋은 모습 보이 스포츠\n",
      "월드컵 멕시코전 필승 해법…손흥민 살려주고·로사노 차 스포츠\n",
      "류현진 CBS 스포츠 전반기 NL 사이영상 투표 1위\n",
      "아시안게임 필리핀 NBA 출신 클락슨 합류 불발…허재 스포츠\n",
      "브라운 45점 폭발…프로농구 전자랜드 삼성 제압하고 3연 스포츠\n",
      "아가메즈 몸상태는 신영철 100 아냐 최태웅 정 스포츠\n",
      "김신욱 4경기 연속골 신태용호 라트비아에 10 승리 스포츠\n",
      "장신 세터 김명관 프로배구 신인 전체 1순위로 한국전 스포츠\n",
      "추신수 시즌 8호 홈런 쾅 아시아 최초 200홈런에 3 스포츠\n",
      "아시안게임 교도소서도 대∼한민국…축구 베트남전 생중 스포츠\n",
      "11승 예감 류현진 20일 리그 최약체 마이애미전 선 스포츠\n",
      "월드컵 신태용호 12일 러시아 입성…김학범호 11일 전 스포츠\n",
      "PSG 데뷔전 맹활약 네이마르 바르사 떠나면 죽는다고  스포츠\n",
      "외신기자단에 MR 스포츠 소개하는 대성동 학생\n",
      "프로배구 2라운드 종료…우리카드 도약·GS칼텍스 강세 지속 스포츠\n",
      "프로농구 첫 600승 유재학 감독 아쉽게 진 경기는 다  스포츠\n",
      "카드뉴스 e스포츠 아시안게임 넘어 올림픽 입성할까\n",
      "3기 벤투호 기성용·이승우 제외…장현수 대신 권경원 발탁 스포츠\n",
      "4명 결장 첫 평가전 앞둔 신태용호 비공개 훈련으로  스포츠\n",
      "MLB닷컴 최지만 우투수 전담 DH로 가치…추신수도 D 스포츠\n",
      "가을 사나이 박정권 끝내기 홈런…SK 넥센 꺾고 PO 스포츠\n",
      "NFL 대신 MLB로 오라…오클랜드 머리에 216억원 스포츠\n",
      "킹 제임스 황제 조던 넘었다…867경기 연속 두 자 스포츠\n",
      "프로농구 13일 개막…14일 원주 경기 윤아 시구에 모모랜 스포츠\n",
      "아시안게임 도전 멈춘 3대3농구 여자대표팀 최초라는  스포츠\n",
      "넥센 한화 꺾고 4년 만의 PO행…8타점 임병욱 시리즈  스포츠\n",
      "U16 축구대표팀 AFC 챔피언십 첫 경기서 호주에 3 스포츠\n",
      "NBA 샬럿 멤피스 상대로 61점 차 대승…팀 역대 최대 스포츠\n",
      "인터뷰 욕심 생긴 류현진 올스타전 자주 해봤으면 좋 스포츠\n",
      "MLB 휴스턴·양키스 ALDS 첫 승리…애틀랜타 NLDS서 스포츠\n",
      "알렉스 28점 폭발 KB손보 OK저축은행 꺾고 KOV 스포츠\n",
      "영상 베트남 총리 박항서 감독에 훈장…양국 국민 친 스포츠\n",
      "SK 문경은 감독 헤인즈 몸 상태 완전 회복…복귀 시점 스포츠\n",
      "이동국 마흔되니 축구가 는다…500경기·10골 이상 목표 스포츠\n",
      "33일 만에 웃은 kt 조동현 감독 분위기 바꿀 수 있는 스포츠\n",
      "정현식 K스포츠 前사무총장 안종범 의혹 은폐 시도 주장종합2보\n",
      "류현진 MLB 토론토 최초 99번 다나…창단 후 아무 스포츠\n",
      "오재일 홈런포 두 방 두산 어린이날 3연전 스윕…LG 스포츠\n",
      "디우프 38점 맹폭 KGC인삼공사 GS칼텍스 꺾고 결 스포츠\n",
      "331표 양의지 2018 골든글러브 최다 득표…득표율 9 스포츠\n",
      "두산 패하고도 매직넘버 1…한화 KIA 꺾고 3위  스포츠\n",
      "아시안게임 NBA 평균 14득점 클락슨 필리핀 대표팀 스포츠\n",
      "아시안게임 황의조·황희찬 이구동성 말레이시아전 패배  스포츠\n",
      "MVP 김정은 촌스럽다고 하실지 몰라도 끝나기 전부터 울 스포츠\n",
      "V리그 4번째 800호 블로킹 신영석 오래 뛰는 게  스포츠\n",
      "아시안게임 박지수 여자농구 단일팀 합류할 듯…4강부터 스포츠\n",
      "아마추어 김해시청·양평FC FA컵 32강서 언더독  스포츠\n",
      "프로배구 현대캐피탈우리카드 반가운 복귀 vs 부상 걱정 스포츠\n",
      "대표팀서 내 모습 찾은 김신욱 A매치 2경기 연속골로 스포츠\n",
      "아시안게임 여자축구 윤덕여 감독 좋은 결과 가져오지  스포츠\n",
      "3점 슛 0개 현대모비스…2연패 빠지며 독주 주춤 스포츠\n",
      "도드람 20192020 V리그 1라운드 남자부 MVP  스포츠\n",
      "월드컵 짝퉁이 진짜를 이겼다…신태용 닮은꼴 뢰프 스포츠\n",
      "한국 여자배구 VNL 5주차 출격 14명 확정…4주차와  스포츠\n",
      "커리 42점·듀랜트 25점 골든스테이트 클리블랜드 꺾 스포츠\n",
      "통일 한국 세계 축구 강국 될 것 폭스스포츠\n",
      "FIFA 심판위원장 비디오판독 효과 있지만 개선 필요는 스포츠\n",
      "NBA 미네소타 존스 르브론 앞에서 슬램덩크 내 이름을 스포츠\n",
      "커리 0.5초 남기고 결승포 골든스테이트 클리퍼스 꺾 스포츠\n",
      "NBA 인디애나 골든스테이트 천적 등극…시즌 2연승 스포츠\n",
      "다저스 로버츠 감독 류현진 담당 포수 최고 환경 만들어 스포츠\n",
      "끝까지 간다…도로공사 흥국생명 정규리그 우승 확정 저 스포츠\n",
      "아시안게임 금빛 피날레 선동열 감독 선수들 능력  스포츠\n",
      "월드컵 문대통령 멕시코전 때 붉은색 유니폼 입고 선수 스포츠\n",
      "관중석에 공 던진 NBA 어빙 벌금 2천800만원 이게  스포츠\n",
      "네이마르 PSG와 계약 완료…총액 6천억 가장 비싼 선수 스포츠\n",
      "FC바르셀로나 미드필더 투란 기내서 스포츠기자 폭행\n",
      "2019년 KBO리그 3월 29일 개막…올스타 휴식기 7일 스포츠\n",
      "더 달라 못 준다 MLB의 연봉 조정신청…KBO는 7 스포츠\n",
      "5년전 MVP김선형·올시즌 신인왕 안영준 의기투합 DB꺾 스포츠\n",
      "아궤로 UCL 나폴리전 결승포…통산 178골로 맨시티 사 스포츠\n",
      "말컹 극장골 경남 전남과 33 무승부…승점 50  스포츠\n",
      "류현진 12일 애리조나전 등판…SK 출신 켈리와 첫 선발 스포츠\n",
      "아쉬운 에이스 대결…양현종 6⅓이닝 6실점 차우찬 5이닝 스포츠\n",
      "남녀 배구 PS 출전팀 중 홈에서 더 많이 이긴 팀은 현대 스포츠\n",
      "흥국생명 통합우승 꿈…도로공사 GS칼텍스 챔프전은  스포츠\n",
      "독일 스포츠연구팀 축구선수 문신하면 기량 35 떨어져\n",
      "추신수 타율 0.265로 시즌 마감…최지만은 19홈런·6 스포츠\n",
      "월드컵 독일 잘 아는 손흥민 대결은 영광이지만 결과 스포츠\n",
      "류현진 NLDS 3차전서 5이닝 2실점…승리 요건 안고  스포츠\n",
      "촛불 3년 스포츠사회불평등 해소 촉구\n",
      "인터뷰 류현진 개막전 부담없었다…박찬호 선배와 비교  스포츠\n",
      "프로배구 거포 가빈 입국…아가메즈와 대결 자신 있다 스포츠\n",
      "아시안게임 김연경 18점 여자배구 인도네시아 격파 스포츠\n",
      "영상 류현진 콜로라도 제물로 13승…빅리그 데뷔 첫  스포츠\n",
      "수원 서정원 감독 권창훈 빠른 템포 적응하면 실력 보여 스포츠\n",
      "진통제 맞고 103구 던진 셔저의 투혼…믿기 힘든 투 스포츠\n",
      "천병혁의 야구세상 개막전에서 기립박수 받은 SF 감독… 스포츠\n",
      "이승우 바르사 B팀 훈련 명단 포함…합류 대신 이적 추진 스포츠\n",
      "아시안게임 여자농구 단일팀 대만 꺾고 결승 진출…은메 스포츠\n",
      "휴스턴 신인 알바레스 데뷔 후 5경기서 4홈런…MLB 역 스포츠\n",
      "헤인즈 25점 SK·펠프스 30점 삼성 나란히 연 스포츠\n",
      "프로배구 현대캐피탈 1위 복귀…OK저축은행 봄 배구 탈락 스포츠\n",
      "MVP 양현종의 욕심 평균자책점·이닝·WHIP는 더  스포츠\n",
      "김신욱 1골 2도움 전북 AFC 챔스리그 조 1위로  스포츠\n",
      "두산 김재환 KBO리그 최초 3년 연속 300루타…시즌  스포츠\n",
      "류현진 복귀전서 옐리치에 연타석 솔로포 헌납…빛바랜 9K 스포츠\n",
      "고원도시 태백시 스포츠 유치로 419억 파급 효과\n",
      "MLB 투타겸업 오타니 2020년엔 던지는 날 방망이 스포츠\n",
      "NBA 마지막 날 미네소타덴버 맞대결 이기면 PO 패 스포츠\n",
      "대한항공 박기원 감독 질책보다 격려 정지석 그렇게 크 스포츠\n",
      "NBA 토론토 르브론 제임스의 클리블랜드에 34점 차 대 스포츠\n",
      "아시안게임 반쪽 코트 가득 채운 음악과 함성…첫 선 보 스포츠\n",
      "평균자책점 1위 LG 소사 한국 타자들에 대해 많이  스포츠\n",
      "프로농구 DB 패배를 잊었다…KCC 꺾고 13연승 질주 스포츠\n",
      "라운드 전승에 1 석진욱 감독 선수에 부담 주고 싶 스포츠\n",
      "한국 여자배구 올림픽 전초전 VNL 개막전서 터키에 0 스포츠\n",
      "KBO출신 켈리 MLB 데뷔시즌 마지막 등판서 승리…13 스포츠\n",
      "아시안게임 김학범 선수들이 덤빌까 걱정 vs 모리야 스포츠\n",
      "박주영 득점에도 서울은 11경기째 무승…강원과 11 무승 스포츠\n",
      "U20월드컵 베네수엘라 독일 제압…멕시코 바누아투에 스포츠\n",
      "4경기 연속골 손흥민 BBC·스카이스포츠 선정 맨오 스포츠\n",
      "불운한 양현종 4⅓이닝 4실점 비자책…브리검은 6이닝 스포츠\n",
      "킹캉 강정호 MLB 복귀 후 914일 만에 홈런 쾅 스포츠\n",
      "류현진 ERA 타이틀 깜짝 선물…사이영상과 관계없이 성공 스포츠\n",
      "석진욱 감독 1R 분위기 난다…배구대표팀 차출 기간 방심 스포츠\n",
      "류현진 미국 개막전 선발투수 중 랭킹 19위야후스포츠\n",
      "류현진 SF전서 공 87개로 7이닝 2실점 2승 보인다 스포츠\n",
      "대한항공 OK저축은행 꺾고 컵대회 전승 우승…MVP 비예 스포츠\n",
      "네이마르 2골 2도움 PK 유도…PSG 툴루즈에 62  스포츠\n",
      "두산 vs SK 한국시리즈 변수는 홈런 홈런 그리고 스포츠\n",
      "류현진 메츠전 7⅔이닝 무실점…NL 다승 단독1위·5월  스포츠\n",
      "김세진 OK저축은행 감독 PS 가려면 10경기에서 8승은 스포츠\n",
      "아시안게임 필리핀 선수단장 NBA 선수 클락슨 출전 스포츠\n",
      "거래소 제일기획에 스포츠단 법인분리설 공시 요구\n",
      "삼성 신인 양창섭 4이닝 1실점 당찬 호투…만족은 NO 스포츠\n",
      "쐐기골 남태희 벤투 감독님이 추구하는 축구 빨리 파악 스포츠\n",
      "1강 전북 최강희 감독 트레블은 욕심 더블이 현실적 스포츠\n",
      "야마구치 미국행 길 열렸다…요미우리 구단 첫 MLB 포스 스포츠\n",
      "아시안게임 한국야구 자신감 여전 남은 5경기 다 이기 스포츠\n",
      "류현진 사타구니 부상 재발해 자진 강판…1⅔이닝 2실점 스포츠\n",
      "제천 화재 참사 스포츠센터 건물·터 14일 경매 진행\n",
      "손흥민 차범근과 타이기록…리그 12호 시즌 19호골 작 스포츠\n",
      "국내 3점슛 깜짝 1위 인삼공사 배병준 힘들어도 포기 스포츠\n",
      "두산 LG전 15연승…KBO리그 역대 특정팀 최다 연승  스포츠\n",
      "아시안게임 베트남 박항서 기술은 한국에 부족…체력으로 스포츠\n",
      "차량털이범에 당한 전 MLB 거포 A.로드…피해액만 6억원 스포츠\n",
      "美제재에 베네수 프로야구 못 열릴라…與정치인 우리라도 뛴 스포츠\n",
      "아스널 벵거 감독 경징계 비판에 감옥에 가도 가볍다 스포츠\n",
      "흥국생명 2위로도약…김희진 1점 IBK기업은행 5연패 스포츠\n",
      "FIFA 랭킹 99위 팀에 발목잡힌 미국…32년 만에 월드 스포츠\n",
      "손흥민 리그 10호골·시즌 17호골…亞 최초 EPL 두자 스포츠\n",
      "비예나 30득점 대한항공 현대캐피탈 31로 꺾고 개 스포츠\n",
      "나경복 21점 우리카드 현대캐피탈에 32 역전승…개 스포츠\n",
      "한화 김태균 역대 10번째 300홈런…평균 비거리 117 스포츠\n",
      "식스맨 파워 KGC인삼공사 SK 꺾고 3연승…루키 변 스포츠\n",
      "여자프로배구 GS칼텍스 국내 스포츠 브랜드와 스폰서십\n",
      "류현진 시즌 끝난 뒤에도 亞 투수 최초 기록…꿈같았던 2 스포츠\n",
      "키가 줄어 행복합니다…KBL 시대착오 행정이 만든 스포츠\n",
      "U20월드컵 베네수엘라 연장 접전 끝에 일본 꺾고 8 스포츠\n",
      "선동열 이제 때가 된 것 같다…야구대표팀 감독 전격 사 스포츠\n",
      "챔프 2차전 승리 지휘 김종민 감독 원정 1승 1패에 스포츠\n",
      "FIFA 2026년 월드컵부터 출전국 48개국으로 확대… 스포츠\n",
      "MLB 콜로라도 올스타 에러나도와 8년 2천900억원에  스포츠\n",
      "월드컵 김영권 독일 키커 선정 3차전 베스트11…골키 스포츠\n",
      "LG전자 3년간 영국 FA컵 후원…스포츠 마케팅 강화\n",
      "FIFA IOC의 러시아 평창 참가 불허 결정 월드 스포츠\n",
      "KIA SK와 2연전서 12홈런 39득점…넥센은 팀 최다 스포츠\n",
      "DB 벤슨의 이유있는 자신감…2차전도 벤슨 vs 메이스 스포츠\n",
      "프로야구 전망대 LG 롯데삼성넥센 상대 2주차  스포츠\n",
      "프로야구결산 ③ 두산 개인타이틀 싹쓸이…MVP도 집안 스포츠\n",
      "최지만 시즌 14호 동점 스리런…MLB 개인통산 100타 스포츠\n",
      "조용히 떠오른 J리그 득점2위 황의조 내 위치서 최선 다 스포츠\n",
      "김연경 출전 교통정리…AG는 출전·네이션스리그 일부 불참 스포츠\n",
      "리베라 득표율 100 신화·첫 만장일치로 MLB 명예의 스포츠\n",
      "호날두 20162017시즌 1천57억원 벌었다…축구선 스포츠\n",
      "LA 언론 곤경에 빠진 류현진 최근 3경기 평균자책점  스포츠\n",
      "아시안게임 방심은 금물…3회 연속 AG 金 노리는  스포츠\n",
      "MLB 워싱턴 와일드카드결정전 진출…류현진 PS 첫 상대 스포츠\n",
      "나경복 개인 첫 트리플크라운…우리카드 구단 최다 타이  스포츠\n",
      "신년인터뷰 축구대표팀 벤투 감독 아시안컵 우승이 새해 스포츠\n",
      "대포 5방 7득점 SK 삼성 상대로 이틀 연속 홈런 파티 스포츠\n",
      "아시안게임 손흥민 앞세운 김학범호 2연패 최다우승 스포츠\n",
      "남자배구 한국전력 샐러리캡 최소소진율 70 미달…48 스포츠\n",
      "프로농구전망대 삼성 원정 3연전에서 6강행 가능성 타 스포츠\n",
      "역시 가을좀비 세인트루이스 NLDS 1차전서 애틀랜타 스포츠\n",
      "MLB 다저스 시즌 96승째…커쇼는 6⅓이닝 2실점 14승 스포츠\n",
      "프로농구 인삼공사 6위 다툼 삼성 격파…전자랜드 S 스포츠\n",
      "MLB 애틀랜타 좌완 마무리 윌 스미스와 3년간 467억 스포츠\n",
      "아시안게임 16골 북한 김광민 감독 인터뷰 요청에  스포츠\n",
      "아시안게임 선동열 감독 성실한 차우찬 잘 쉬고 예전 스포츠\n",
      "U18 女농구대표팀 세계선수권 진출…호주에 1점 차 승 스포츠\n",
      "대한항공 비예나·정지석 폭발…현대건설 이다영 10득점 활약 스포츠\n",
      "아시안게임 우승주역 8명 김학범호에서 벤투호로 이동… 스포츠\n",
      "프로농구 인삼공사·LG 나란히 승리…선두 0.5경기 차 추 스포츠\n",
      "U20월드컵 피 흘리는 국민 위해…베네수엘라가 보여 스포츠\n",
      "프로농구 전자랜드 디펜딩챔피언 SK 상대로 35점 차 대 스포츠\n",
      "다이빙 최강자는…송도 전국해양스포츠대회 25일 개막\n",
      "토트넘 26일 홍콩서 키치와 친선전…손흥민 출전 기대감 스포츠\n",
      "4강 PO 1차전 따낸 DB 이상범 베테랑의 힘…수비보완 스포츠\n",
      "류현진 투수들의 무덤서 6이닝 무실점 호투에도 빈손 스포츠\n",
      "산에 올라가기 전에 10승 채울까…류현진 23일 콜로라도 스포츠\n",
      "법원 MBC정상화위 효력정지 스포츠사측 이의신청\n",
      "아시안게임 베트남과 4강전 앞둔 김학범의 승부수 한  스포츠\n",
      "北축구 한광성 伊세리에A 칼리아리와 정식 계약…2022년 스포츠\n",
      "U20월드컵 대역전승 잠비아·日격파 우루과이 16강  스포츠\n",
      "WNBA 박지수 시애틀 전서 6점·12R…한 경기 최다  스포츠\n",
      "듀랜트·커리 55점 합작…골든스테이트 클리블랜드 원정서  스포츠\n",
      "연속타자 피홈런 류현진 50일 만에 패전 멍에…5⅔이 스포츠\n",
      "크리스털 팰리스 4연패 수렁…첫 선발 이청용 치명적 백패 스포츠\n",
      "데뷔 후 최다 13점 구본승 한국전력이 기대하는 신 스포츠\n",
      "월드컵 신태용 유임 질문에 독일 잡았지만…마음 정리 스포츠\n",
      "OK저축은행 새 사령탑 팀을 잘 아는 석진욱 수석코치  스포츠\n",
      "정운찬 총재 병역 국민정서 반영 못해 죄송…미래협의회  스포츠\n",
      "남태희 1골1도움 알두하일 ACL 16강 1차전 4 스포츠\n",
      "프로배구 차기 시즌 남자부 10월 12일여자부 10월 1 스포츠\n",
      "통일농구 방북단 귀환…조명균 체육교류 계속 이어질 것 스포츠\n",
      "프로배구개막 ②30년 지기·대학 선후배 등으로 얽힌 V 스포츠\n",
      "MLB 월드시리즈 우승 휴스턴 감독 SK 와이번스 스프링 스포츠\n",
      "2위 우리카드 선두 대한항공에 시즌 첫 승…현대건설은 3 스포츠\n",
      "아시안게임 장신 센터 박지수가 160㎝…웹사이트  스포츠\n",
      "MLB 휴스턴 잭 그레인키 영입…WS 우승후보 0순위 스포츠\n",
      "새로 뽑을 U23 축구 감독 아시안게임·도쿄올림픽 겸 스포츠\n",
      "아시안게임 단일팀 에이스 로숙영 지수 선수가 다  스포츠\n",
      "푸른 피를 가진 남자 존 테리 첼시 떠난다…MLS구단 스포츠\n",
      "추신수 양키스 상대 시즌 28호 2루타시즌 21호 홈런 스포츠\n",
      "정규리그 우승 1 이상범 감독 11일 경기에 다 쏟 스포츠\n",
      "프로농구 메이스 다음 시즌도 뛴다…199.9cm로 신장제 스포츠\n",
      "주말 N 여행 강원권 늦더위 날릴 레저스포츠의 묘기\n",
      "아시안게임 승우·희찬 연장전 골골 한국 일본 꺾고 스포츠\n",
      "배구 FA 등급제 효과…센터 김세영·레프트 김미연 흥국생명 스포츠\n",
      "프로야구 2경기 태풍으로 취소…KIASK 6일 더블헤더 스포츠\n",
      "베트남 축구 AG 첫 4강에 발칵…땡큐 박항서 전 스포츠\n",
      "여자배구 용병 농사 웃을 팀은…검증된 거포 vs 뉴페이 스포츠\n",
      "개막 4경기 연속 5세트 KB손보 떨쳐내야 할 풀세 스포츠\n",
      "NBA 르브론 제임스 조던 넘었다…867경기 연속 두 자 스포츠\n",
      "U20월드컵 오귀스탱 2골 프랑스 베트남 꺾고 1 스포츠\n",
      "K리그 클래식 3월 1일 개막…월드컵 시즌 51일간  스포츠\n",
      "우리카드 예비 PO 대결서 최민호 복귀 현대캐피탈 3 스포츠\n",
      "디애슬레틱 FA 류현진 계약 전망…가치는 3년 644억 스포츠\n",
      "김학민 22점 KB손해보험 선두 대한항공 31 제압 스포츠\n",
      "프로야구 SK 힐만 감독·김광현 소아암 환자 위해 모발 스포츠\n",
      "헤일리 24점 현대건설 흥국생명 32로 꺾고 2연승 스포츠\n",
      "다우디 효과 현대캐피탈 3위 점프…기업은행은 선두 G 스포츠\n",
      "아시안게임 박병호·이정후·함덕주 국제용 계보 이은  스포츠\n",
      "월드컵 월드컵 보고 꿈 키운 조현우 나도 누군가의 꿈 스포츠\n",
      "미국 SI 류현진 목욕물 온도까지 분석…믿기 힘든 훈련 스포츠\n",
      "4강 확률 95.2 사수 위한 전자랜드의 키워드 차 스포츠\n",
      "1부 승격 좌절된 프로축구 아산 시민구단 창단에 최선 다 스포츠\n",
      "알렉사에 묻고 삼성 TV가 답한다…스포츠 채널로 바꿔줘\n",
      "문선민 2골 인천 절대 1강 전북에 32 격파…시즌 스포츠\n",
      "다시 하나된 남북 여자농구 선수들…AG 우승 향해 평화의 스포츠\n",
      "스포츠10대뉴스 ①류현진 亞투수 최초 MLB 평균자책점 1위\n",
      "롯데 벼랑 끝에서 기사회생…두산 3연속 전 구단 상대 승 스포츠\n",
      "목에 담 증세 오승환 투런포 두 방 허용…⅔이닝 4실 스포츠\n",
      "르브론 40득점 트리플 더블…클리블랜드 동부 3위 수 스포츠\n",
      "흥국생명 2시즌 만에 정규리그 정상 탈환…5번째 우승종 스포츠\n",
      "호랑이 만나면 펄펄…이정후 KIA라서 더 잘하려는 건 아 스포츠\n",
      "MLB 텍사스 추신수 시즌 22호 홈런 쾅…개인 최다 타 스포츠\n",
      "2018 MVP 김재환 약물 논란 제가 짊어지고 갈 책 스포츠\n",
      "MWC19 SK텔레콤 싱가포르 통신사 싱텔과 e스포츠 협력\n",
      "2023 아시안컵 한국서 개최 대학생들 AFC 46개국 스포츠\n",
      "아시안게임 SKB 옥수수 축구 8강전서 역대 최고 스포츠\n",
      "프로농구 결산 ① SK 18년 만에 우승과 DB 돌풍… 스포츠\n",
      "8강 탈락 남자배구 U21 세계선수권서 브라질에도  스포츠\n",
      "아시안게임 황의조의 단일대회 2차례 해트트릭은 한국 남 스포츠\n",
      "아시안게임 로숙영·김한별 분전에도…여자농구 단일팀 대 스포츠\n",
      "영상 뇌종양 아동 위해 날계란 맞은 류현진…강정호도  스포츠\n",
      "아시안게임 농구 단일팀 박지수 북측 친구가 평양서 못 스포츠\n",
      "2018년 마지막 경기 승리를…벤투호 호주 최종 담금질 스포츠\n",
      "펠리페 33득점 한국전력 삼성화재 꺾고 유종의 미 스포츠\n",
      "포항 울산 제압 4경기 무패 선두…전북 상주 꺾고 3승 스포츠\n",
      "게시판 관광공사 봄철 레저스포츠 여행상품 공모\n",
      "류현진 전 에이전트 광고모델료 약 2억 가로채 고소… 스포츠\n",
      "프로농구 개막 ④ 해설위원 우승후보 모비스·KGC· 스포츠\n",
      "골든스테이트 NBA 2연패 달성…듀랜트 2년 연속 MVP 스포츠\n",
      "선발 복귀전서 2골 1도움 펄펄…염기훈 K리그1 18 스포츠\n",
      "아시안게임 여자농구 이문규 감독 박지수·로숙영 호흡이 스포츠\n",
      "월드컵 기성용 종아리 근육 늘어나 2주 진단…독일전  스포츠\n",
      "아시안게임 박항서호 베트남 네팔 꺾고 2연승…3 스포츠\n",
      "비예나 28점 대한항공 컵대회 3연승…OK도 2위로  스포츠\n",
      "아시안게임 우즈베크전 눈물 김학범의 고백 선수들  스포츠\n",
      "인터뷰 류현진 노히트 게임 놓쳐 아쉽지만 실망은 없어 스포츠\n",
      "월드컵 태극전사 23인 4년 전보다 K리거 늘고 평균연령 스포츠\n",
      "연타석포 임병욱 승리 기쁘지만 이정후 큰 부상  스포츠\n",
      "아시안게임 소문대로 로숙영…농구 단일팀 첫 실전서  스포츠\n",
      "월드컵 D30 ⑥ 신태용호와 결전 치를 강호들의 준비 스포츠\n",
      "아시안게임 한일전 한국인 감독 맞대결…김학범호  스포츠\n",
      "브라운 39점 전자랜드 6강 PO 3차전 승리…1승 스포츠\n",
      "류현진 NLDS 3차전 선발 확정…커쇼 불펜 등판 고려 스포츠\n",
      "프로야구 잠실·수원·문학 경기 미세먼지로 취소…역대 최초 스포츠\n",
      "클리블랜드 보스턴과 7차전 8779 제압…4년 연속 파 스포츠\n",
      "아시안게임 코리아 선수들은 포기하지 않았고 관중은 스포츠\n",
      "2군에서 2천378타석…최주환 퓨처스에서 보낸 시간이 내 스포츠\n",
      "46세 이치로 MLB 개막전 출전 역대 7번째 45 스포츠\n",
      "영상 류현진 베테랑 포수 마틴과 출격…워싱턴은 15 스포츠\n",
      "월드컵개막 ② 16강 특명 태극전사 최강 멤버로 통 스포츠\n",
      "6연승 류중일 LG 감독 빈자리 메우는 모습 강한  스포츠\n",
      "넥센 소속 유명 프로야구 선수 2명 인천서 성폭행 의혹  스포츠\n",
      "아산 무궁화 K리그2 우승 확정…존폐 위기로 승격은  스포츠\n",
      "無관중 경기·국기 물결…축구장에도 카탈루냐 독립투표 폭 스포츠\n",
      "CBS 스포츠 류현진 속한 다저스 선발진 MLB 역대  스포츠\n",
      "KBO 선수 장사 히어로즈 솜방망이 징계…제재금 5천만 스포츠\n",
      "로하스 40홈런 폭발…KBO 19년 만에 40홈런타자 4 스포츠\n",
      "프로야구결산 ② 40홈런 5명·2점대 방어율 1명…타고 스포츠\n",
      "프로농구전망대 부상에도 흔들림 없는 현대모비스 기록  스포츠\n",
      "아시안게임 이승우·황의조손흥민·나상호 김학범호 필승 스포츠\n",
      "대전 느리울중·거창 해성여중 KOVO 유소년 배구대회 남 스포츠\n",
      "월드컵 베이스캠프 복귀 비행기 이륙 전 살아난 신태용호 스포츠\n",
      "ESPN·MLB닷컴 NL 우승은 다저스…하지만 WS 우승 스포츠\n",
      "리버풀 쿠티뉴 팀 복귀 환영받을 것…바르사는 네번째  스포츠\n",
      "아시안게임 여자농구 단일팀도 메달 보인다…태국 꺾고 스포츠\n",
      "女배구대표팀 세계 1위 세르비아와 VNL 2차전서 13 스포츠\n",
      "월드컵 한국 뼈아픈 PK골 허용…스웨덴에 01 패배 스포츠\n",
      "아쉬운 7회 후랭코프 6⅓이닝 2실점 호투에도 패전  스포츠\n",
      "아시안게임 광복절에 처음 뜬 여자농구 단일팀 화합과  스포츠\n",
      "첫 라이브피칭 류현진 2월 시범경기 등판도 문제없어 스포츠\n",
      "SK 최정 라인업 복귀…힐만 감독 두산 타선 오늘은  스포츠\n",
      "월드컵 D30 ① 신태용호 2번째 원정 16강 진출 스포츠\n",
      "38점 폭발한 거포 디우프 인삼공사 봄 배구 청부사 스포츠\n",
      "월드컵 대헤아 조현우의 재발견…A매치 9경기만에  스포츠\n",
      "KCC 2차 연장 접전 끝에 KGC인삼공사 꺾고 3연패  스포츠\n",
      "손흥민 대세 입증…프리미어리거 랭킹 1위 스카이스포츠\n",
      "6월에만 54개…롯데 KBO리그 월간 최다 홈런 신기 스포츠\n",
      "다저스 명운 안은 류현진 굳센 결의 불펜 등판 해야죠 스포츠\n",
      "배구협회 프로팀 이적 시도 김호철 감독 스포츠공정위에 회부\n",
      "한국 남녀배구 2020년 시작 20년만의 올림픽 동반진 스포츠\n",
      "프로배구 KB손해보험 용병 거포 브람 입국… 15일 홈 스포츠\n",
      "손흥민 과감한 돌파 토트넘 맨유에 21 승리…EPL 스포츠\n",
      "아시안게임 박항서 매직 베트남 시리아 꺾고 4강  스포츠\n",
      "이종범 LG 코치로 현장 복귀…아들 이정후와 서울 라이 스포츠\n",
      "기사회생 KCC 추승균 감독 리바운드 압도…분위기 가 스포츠\n",
      "FIFA 러 월드컵 후원사 확보에 어려움…브라질 월드컵 스포츠\n",
      "아시안게임 한국 야구 벼랑 끝서 일본 제압…결승 진 스포츠\n",
      "모의고사 마친 벤투호 이젠 실전…아시안컵 위해 내달 중순  스포츠\n",
      "메이스 34점·17리바운드…LG SK 상대로 1라운드 역 스포츠\n",
      "프로야구결산 ① 두산 독주·한화 도약…KIA 부진·NC 스포츠\n",
      "아시안게임 말레이전 교훈 떠올리는 김학범호 승리 뒤  스포츠\n",
      "한화 KIA에 2천83일 만에 3연전 싹쓸이…kt NC 스포츠\n",
      "아시안게임 땅볼 수비 조심해…이만수 부회장 선동열 스포츠\n",
      "아궤로 멀티골 맨시티 FA컵 16강서 허더즈필드 5 스포츠\n",
      "영상 류현진 내가 홈런 친 후 팀 대량 득점 중요한 스포츠\n",
      "2018년 한국시리즈 4차전은 역대 KS 200번째 경기… 스포츠\n",
      "류현진 6이닝 2실점홈런성 2루타로 첫 타점…7승 눈앞 스포츠\n",
      "강정호 24일에는 팀 훈련만…25일 출전 사실상 확정 스포츠\n",
      "아시안게임 여자축구 인도네시아 상대로 손화연·이현영  스포츠\n",
      "위기의 류현진 4⅓이닝 3실점 조기 강판…ERA 2.45로 스포츠\n",
      "한화 11년 만의 PS 진출 매직넘버 3…3위 확보 스포츠\n",
      "LG 전자랜드 연승 저지하며 첫 승…김종규·메이스 50점 스포츠\n",
      "제임스 NBA 퍼스트 팀에 통산 12번째 선정돼…역대 최 스포츠\n",
      "최근 4승 1패 오리온 사상 최초로 10연패 하고도 PO 스포츠\n",
      "아시안게임 인맥 축구 논란 딛고 득점왕 오른 황의조  스포츠\n",
      "월드컵 김신욱손흥민 투톱 신태용호 세네갈에 0 스포츠\n",
      "광란의 다저스 3경기 연속 끝내기 홈런…콜로라도에 63 스포츠\n",
      "하퍼 효과…MLB 필라델피아 24시간 만에 티켓 10만 스포츠\n",
      "대한항공 FA 최대어 정지석 등 4명 잔류 확정…손현종  스포츠\n",
      "극적인 역전승 도로공사 GS칼텍스 꺾고 2년 연속 챔 스포츠\n",
      "아시안게임 천군만마 박지수 합류 로숙영과 함께 단 스포츠\n",
      "캡틴 신영석 한국 남자 배구는 안된다는 편견 깨고 스포츠\n",
      "아시안게임 우즈베크전 퇴장·대패 악몽…장윤호 반드시  스포츠\n",
      "아시안게임 남자농구 덮친 NBA 변수…라틀리프 두 스포츠\n",
      "U20월드컵 프랑스 뉴질랜드 꺾고 3연승…E조 1위  스포츠\n",
      "1위 현대모비스 2위 kt에 짜릿한 한 점 차 승리…파죽 스포츠\n",
      "아시안게임 한국소프트볼 일본에 콜드게임 패배…준결승  스포츠\n",
      "2018 WKBL 학교 스포츠클럽 리그전 17일 개최\n",
      "콜 넥스트VR CEO 스포츠 뉴스 모두 VR로 보게될 것\n",
      "물러가는 동장군 스포츠.서울 한파주의보 해제\n",
      "박지수 WNBA 단장 설문조사에서 기대되는 외국 선수 공 스포츠\n",
      "류현진 3경기 연속 5회 못 넘기고 강판…날아간 13승· 스포츠\n",
      "대재앙 후 드리운 트라우마 그리고 치유 스포츠연극 안녕 후쿠시마\n",
      "아시안게임 임영희 통일 농구로 얼굴 익혀서 서먹한 건 스포츠\n",
      "최장신 거포 러츠의 압도적 높이…GS칼텍스 고공 배구 스포츠\n",
      "500호골 넣은 메시 팔꿈치 가격에 멍들고 이도 빠져 스포츠\n",
      "스마트폰으로 간편하게…모바일 e스포츠 뜰까\n",
      "아시안게임 라건아 라틀리프 한국농구 점점 강해지 스포츠\n",
      "페루 아르헨 팬 무서워…FIFA에 월드컵예선 경기장 변 스포츠\n",
      "하든 28점 휴스턴 마이애미 꺾고 3연승…서부 선두  스포츠\n",
      "긴장 풀어주자…월드컵 16강 기원 10만 온라인 응원 스포츠\n",
      "득점왕 사이먼 2㎝ 차로 한국 복귀 불발 다시 오고 싶 스포츠\n",
      "연타석포 강정호 첫 단추 잘 끼워…공수 모두 이 기분 스포츠\n",
      "손흥민 BBC 축구전문가 선정 2017 EPL 베스트  스포츠\n",
      "與 질서있는 국정수습 스포츠野 탄핵연대로 응답\n",
      "프로농구 1위 DB·2위 KCC 나란히 승리…DB 매직넘버 스포츠\n",
      "檢 정현식 K스포츠 前사무총장 소환…안종범과 가끔 연락종합\n",
      "아시안게임 여자축구 윤덕여 감독 3∼4위전 최선 다해 스포츠\n",
      "프로농구 개막 ② 라건아·강병현·박상오 등 이적생 새 스포츠\n",
      "영상 전창진 전 감독 팬들에게 많이 죄송…KBL 등 스포츠\n",
      "이재영 26득점 흥국생명 IBK 4연승 저지·선두 탈 스포츠\n",
      "여자배구 GS칼텍스 알리 부상 딛고 IBK기업은행에 3 스포츠\n",
      "도쿄행 첫 관문 주인공은 나…김학범호 48인 오디션 스포츠\n",
      "도로공사 2시즌 연속 PS 진출 확정…GS칼텍스는 불안한 스포츠\n",
      "도로공사 흥국생명 30으로 완파…챔프전 1승 1패로 승 스포츠\n",
      "배구협회 김호철 감독 OK저축은행 감독 제안설 진위파 스포츠\n",
      "월드컵 구자철 포기하지 않았고 할 수도 없다…멕시코 스포츠\n",
      "류현진 MLB 첫 올 MLB 팀서 두 번째 팀 선발투 스포츠\n",
      "외인·주전 세터 없어도 KB손보 2연승…한국전력 4 스포츠\n",
      "아시안게임 동반 2연패 노리는 남녀농구 12∼13일  스포츠\n",
      "월드컵 신태용호 잔디 손상 우려 탓에 독일전 공식 훈 스포츠\n",
      "프로축구 아산 승격 자격 박탈…성남 3년 만에 1부 복 스포츠\n",
      "서울 수원과 슈퍼매치서 승리…전북은 10연승 신기록 무산 스포츠\n",
      "김학범 U23 감독 AG 우승 자신있다…변수 없는한 손 스포츠\n",
      "최정 6년 106억원에 SK와 잔류 계약…KBO 공식 최 스포츠\n",
      "아쉬운 銅 남자농구·감동의 銀 여자농구 이젠 월드 스포츠\n",
      "중국행 최강희 전북 차기 감독 내가 추천하는 건 맞 스포츠\n",
      "월드컵 인기 없던 두 감독 申 vs 오소리오…운명을 스포츠\n",
      "피홈런 2개 류현진 5⅔이닝 4실점…시즌 두 번째 많 스포츠\n",
      "월드컵 홍철이 전한 태극전사의 희망가 1라도…불가능 스포츠\n",
      "MLB·NBA 선수 트레이드서 이익 낸 구단은 양도소득세 스포츠\n",
      "배신자 vs 대환영 네이마르 이적에 스페인·프랑스 극 스포츠\n",
      "3⅔이닝 퍼펙트 진명호 2천59일만의 승리…롯데 시즌  스포츠\n",
      "K리그와 지역사회의 상생…종합형 스포츠클럽 추진\n",
      "추신수 132ｍ짜리 대형 투런포…시즌 6호·통산 195호 스포츠\n",
      "수원 ACL 4강서 가시마에 23 역전패…추가시간 결승 스포츠\n",
      "아시안게임 우승 느낌 아는 김선형 고참이 걱정이 많으 스포츠\n",
      "아시안게임 동메달 허재 감독 아쉬운 대회…집중해준 선 스포츠\n",
      "류현진 평균자책점 1위 지켜준 강정호 소로카에게 멀티출루 스포츠\n",
      "U20월드컵 잠비아 이란에 42 역전승…이탈리아  스포츠\n",
      "파다르 대신 허수봉 현대캐피탈 4시즌 연속 챔프전 진 스포츠\n",
      "30년 지기 대결 승자는 최태웅 감독…석진욱 감독은 첫 패 스포츠\n",
      "러프 연타석홈런 등 5안타 폭발…삼성 한화 마운드 초토 스포츠\n",
      "말컹 2골 1도움 경남 서울에 32 승리…인천은 꼴 스포츠\n",
      "울산 수원과 33 무승부로 ACL행…이동국 502경기  스포츠\n",
      "3점포 되살아난 kt LG에 15점차 승리…5명이 두 자 스포츠\n",
      "배구 대표팀 12월 22일 소집…올림픽 예선 기간 V리그 스포츠\n",
      "LG전 14연승 두산 우승 매직넘버 5…LG는 KIA 스포츠\n",
      "ESPN 류현진 삼진은 적지만 장점이 더 많아…영입하면 스포츠\n",
      "위기의 클리블랜드 이번엔 OKC에 24점 차 대패 굴 스포츠\n",
      "이재영 만장일치 MVP…흥국생명 12년 만에 통합우승  스포츠\n",
      "신영석 복귀 현대캐피탈 한국전력에 설욕하고 2위 탈환 스포츠\n",
      "아시안게임 여자농구 코리아 인니 완파…종합대회 단 스포츠\n",
      "기적의 작전타임 최태웅 감독 2차전 승리에 모든 걸  스포츠\n",
      "이재영 챔프전 첫 우승 도전 vs 박정아 5번째 우승 스포츠\n",
      "김연경 12점 엑자시바시 챔프 3차전 패배…시리즈 1 스포츠\n",
      "아시안게임 체육회 코리아하우스서 여자농구 단일팀 합동 스포츠\n",
      "표적 등판 성공 kt 박세진 넥센 상대로 5⅓이닝 1 스포츠\n",
      "지소연 UEFA 여자 챔피언스리그 16강 1차전 풀타임… 스포츠\n",
      "아시안게임 OCA 여자농구 단일팀 스포츠 통합의 힘 스포츠\n",
      "최진수 트리플더블급 활약…오리온 인삼공사 잡고 연패 탈출 스포츠\n",
      "현대건설 정규리그 기준 팀 최다 14연패…이번 시즌은 8 스포츠\n",
      "MLB 다저스 6회 6득점으로 역전승…18연전 강행군서  스포츠\n",
      "KIA전 8연승 두산 장원준 공을 때린다는 느낌든다 스포츠\n",
      "2위와 7.5경기 차 현대모비스 20112012시즌 동 스포츠\n",
      "WNBA 라스베이거스 박지수 등 훈련 명단 발표…경쟁률  스포츠\n",
      "프로농구 KCC DB와의 맞대결 승리…선두 추격 불씨 살 스포츠\n",
      "막내와 20살 차 정대영 연경이와 올림픽 한 번 더  스포츠\n",
      "아시안게임 손흥민 보자…교민 응원 속에 태극전사  스포츠\n",
      "두산 KS 직행 매직넘버 15…KIA 양창섭 넘어  스포츠\n",
      "거포 산체스 쿠바 대표로 올림픽 예선 참가…KB손보도 스포츠\n",
      "비싼 몸 아센시오…레알 최소 이적료 6천700억원 상 스포츠\n",
      "두산 후랭코프 13연승 뒤 첫 패전 위기…kt전 2⅔이닝 스포츠\n",
      "언제든 나가겠다던 정우람 한화 11년 만의 PS 승리 스포츠\n",
      "월드컵 다시 시작된 희망 고문…두 골 차 이상 승리 스포츠\n",
      "김연경 폭발 한국 여자배구 중국 완파하고 아시아선수권 스포츠\n",
      "강백호 프로 데뷔 첫 타석서 2018시즌 전체 첫 홈런  스포츠\n",
      "날아간 류현진 11승…구원 바에스 홈런 2방 맞고 동점 허 스포츠\n",
      "아시안게임 일본만 만나면 펄펄…이승우의 당돌한 자신감 스포츠\n",
      "스포츠10대뉴스 ⑩SK 한국시리즈 정상…힐만 외국인 스포츠\n",
      "임동혁 19점 한국남자배구 일본 잡고…F조 1위로 8 스포츠\n",
      "차범근 언제까지 히딩크인가…우수한 지도자에게 기회 줘야 스포츠\n",
      "류현진에 폭풍 찬사…역대 두 번째 13경기 연속 2실점 이 스포츠\n",
      "생일 맞은 국민은행 안덕수 감독 챔프전 멋있게 준비하겠다 스포츠\n",
      "NBA 미네소타 덴버 꺾고 14년 만에 플레이오프행 감 스포츠\n",
      "농구장서 2019년 맞이…창원 농구영신 경기 5천300 스포츠\n",
      "아시안게임 윤덕여호 16일 대만과 1차전…9골의 전설 스포츠\n",
      "류현진 빨리 계약하고파…MLB닷컴연평균 2천만달러 투 스포츠\n",
      "수원 제주 꺾고 FA컵 4강 막차…신화용 승부차기 3연 스포츠\n",
      "아시안게임 차해원 여자배구 감독 인도네시아 절대 쉬운 스포츠\n",
      "아시안게임 여자농구 코리아 인도에 시원한 대승…선 스포츠\n",
      "아시안게임 3점포 폭발 맏형 허일영 동생들 위해서 스포츠\n",
      "복사근 부상 아가메즈 6일 재검진…상태 보고 PO  스포츠\n",
      "NBA 로즈 고향팀 시카고 원정서 24점…고향 팬들 M 스포츠\n",
      "아시안게임 토트넘도 휴우…병역 해결한 손흥민 몸 스포츠\n",
      "린드블럼 vs 박종훈 2018 KS 서막 여는 1차전 선 스포츠\n",
      "유쾌한 전태풍 kt 양홍석에게 너 누구니 전자랜드 선 스포츠\n",
      "OK저축은행 배구단 김세진 감독 사표 수리…차기 사령탑 스포츠\n",
      "다우디 현대 연패 탈출 견인…인삼공사는 디우프 덕에 3연 스포츠\n",
      "아시안게임 캡틴 손흥민 오늘은 울지 않았다…태극기 들 스포츠\n",
      "가빈 드래프트 1순위로 한국전력행…8년 만에 V리그 유턴 스포츠\n",
      "페널티킥 갈등 네이마르·카바니 골 앞에서 불화 끝 스포츠\n",
      "성폭행의혹 넥센 박동원·조상우 경찰출석…조상우 폭행없 스포츠\n",
      "비예나 28점 대한항공 컵대회 3전 전승으로 준결승  스포츠\n",
      "김지한 19득점 깜짝 활약…현대캐피탈 KB손보에 3 스포츠\n",
      "월드컵 추가 골 어시스트한 주세종 돼지꿈 꿔주신 할머 스포츠\n",
      "프랜차이즈 최다승·두 번째 FA 앞둔 윤성환 계속  스포츠\n",
      "월드컵 징계 해제 정몽준 한국스웨덴전 관전…복귀 스포츠\n",
      "신영석 15점 한국 亞선수권 8강 첫 경기서 대만 완 스포츠\n",
      "15년 전엔 선수 이젠 감독…평양 간 허재 감회 새롭네 스포츠\n",
      "프로농구전망대 1천383일만에 승률 5할 돌파…kt  스포츠\n",
      "워싱턴 NLCS 파죽의 3연승…창단 첫 월드시리즈까지 1 스포츠\n",
      "말컹 비켜 강원의 소양강 폭격기 제리치 단숨에 득 스포츠\n",
      "아시안게임 김학범호 태극전사들의 반성 20명 모두 잘 스포츠\n",
      "KBO 월드컵에도 한화 돌풍에 관중 선방…3년 연속 80 스포츠\n",
      "프로농구 전망대 우울한 오빠 문경은이상민 성탄절에 스포츠\n",
      "삼성전자 스포츠밴드 갤럭시 핏·갤럭시 핏e 31일 출시\n",
      "허경민 역전 3루타 두산 롯데 꺾고 3연승…곽빈 데뷔 스포츠\n",
      "이용찬 1이닝 1실점 조기 강판…PS 개시 후 최다연속  스포츠\n",
      "OK저축은행·GS칼텍스 개막 후 무패행진…남녀 배구 선두  스포츠\n",
      "부상 고려하지 않은 ZiPS 오타니 타자로 20홈런·투 스포츠\n",
      "제2의 김연경 꿈꾸는 특급 신인 정호영 신인왕 도 스포츠\n",
      "손흥민 프리미어리거 시즌랭킹 34위 스카이스포츠\n",
      "하나은행 축구 금메달 기념 적금가입고객에 최대 연 2.5 스포츠\n",
      "SK 힐만 감독 넥센 스피드·2스트라이크 이후 대처 좋 스포츠\n",
      "류현진 23일 콜로라도전 등판으로 변경…ERA 1위 확정 스포츠\n",
      "제구 흔들 두산 선발 이용찬 조기 강판…1이닝 1실점 스포츠\n",
      "문 대통령 스포츠외교무대 평창서 다자 정상외교 펼친다\n",
      "전국구스타 류현진 22서 교체…7이닝 8탈삼진 2실점 스포츠\n",
      "DB의 기둥 김주성 정규리그 우승하고 처음 울었어요 스포츠\n",
      "아시안게임 라오스 야구 스리랑카에 패배…짧지만 강렬한 스포츠\n",
      "아시안게임 첫 경기 완승 허재 감독의 눈은 이미 단 스포츠\n",
      "한전에 진땀승 대한항공 선두로…도공 IBK 꺾고 3위 스포츠\n",
      "박지수 WNBA 신인 드래프트 지명 후 라스베이거스로 트 스포츠\n",
      "9승 무패 두산 후랭코프 등판 때마다 승리해서 기뻐 스포츠\n",
      "100번째 등판 류현진 통증 느껴 자진 강판…1⅔이닝 스포츠\n",
      "아르헨 우루과이와 00 비겨…브라질 에콰도르 20  스포츠\n",
      "류현진 사이영상 단독 2위로 수정…아시아 최초 1위표 스포츠\n",
      "아시안게임 돌아온 수문장 조현우 무실점으로 금메달 스포츠\n",
      "아시안게임 남북단일팀 격려 행사 참가보다 경기 집중이 스포츠\n",
      "MLB PS 출전 10개 팀 확정…WC 순위·최고 승률 경 스포츠\n",
      "마지막 승부 힐만 감독 우승하면 어떤 말이 나올지 모 스포츠\n",
      "500경기 출전 이동국 바로 앞에 다가온 경기가 가장 스포츠\n",
      "푸홀스 개인 통산 1천993타점…라이브볼 시대 루스  스포츠\n",
      "옐리치 하루에 도루 3개…MLB 첫 5030클럽에 홈런  스포츠\n",
      "해결사 양효진 시즌 개인 최다 29점…현대건설 선두 스포츠\n",
      "프로배구 개막 ② 매일 즐기는 프로배구…이적생이 이끌  스포츠\n",
      "김연경 23점 한국 일본 30으로 완파…VNL 9연 스포츠\n",
      "1승 2패 워싱턴 감독 걱정 없다 4차전은 셔저가  스포츠\n",
      "말컹 해트트릭 경남 포항 30으로 꺾고 10경기 무 스포츠\n",
      "한국전력 가빈 39점 맹폭에 KB손보 속수무책 11연패 스포츠\n",
      "현주엽 감독 배번 물려받았던 LG 김종규 등번호 다시 바 스포츠\n",
      "한국 이란 꺾고 6년 만에 아시아 남자핸드볼선수권 4강행 스포츠\n",
      "김연경 5세트 8점 등 19점 폭발…엑자시바시 챔프전 기 스포츠\n",
      "아시안게임 박항서 매직 베트남 일본도 넘다…10 스포츠\n",
      "WNBA 박지수 30초 출전…라스베이거스는 개막 4연패 끊 스포츠\n",
      "류현진 청색 점퍼 입고 귀국 2013년 성적14승이 스포츠\n",
      "DB kt 대파하고 3연승…단독 6위 PO 진출 보인다 스포츠\n",
      "오승환 복근 통증으로 열흘짜리 부상자 명단…MLB 진출  스포츠\n",
      "웨스트브룩·조지 68점 합작…NBA 오클라호마시티 파죽의 스포츠\n",
      "전충렬 수석대표 남북 통일농구경기 7월 36일 사이 개 스포츠\n",
      "2018년 최악의 스포츠 팀은 MLB 볼티모어\n",
      "아시안게임 10장 더 확보한 AD 카드…야구대표팀 코치 스포츠\n",
      "배구여제 김연경 10일 터키 챔피언스컵 출격…리그 1 스포츠\n",
      "코리안 몬스터 류현진 한국인 빅리거 4번째로 올스타  스포츠\n",
      "1승 11패 한국 여자배구 VNL 5주차서 벼랑 끝 스포츠\n",
      "현대캐피탈 3연승으로 2년 만에 챔프전 정상 탈환…전광인 스포츠\n",
      "1천500경기 앞둔 추신수 빅리그에서 한경기만 뛰길  스포츠\n",
      "폭스스포츠 아시안컵 최고스타는 손흥민\n",
      "2018 KBO리그 어린이날에 시즌 관중 200만명 돌파 스포츠\n",
      "女배구 대표팀 VNL 5주차에 정예멤버 구성…올림픽 출전 스포츠\n",
      "500경기 앞둔 이동국 한 방 기대감 주는 선수로 남 스포츠\n",
      "FC서울 10명이 싸운 부산에 31 역전승…1부 잔류 스포츠\n",
      "최다 이닝 윌슨 vs 데뷔 첫 QS 김태훈 잠실  스포츠\n",
      "아시안게임 첫 경기 앞둔 라건아 인도네시아 팬이라도  스포츠\n",
      "극적 역전승 도로공사 GS칼텍스 꺾고 2년 연속 챔프 스포츠\n",
      "스페셜올림픽 전 배구국가대표 김성민 발달장애선수들 가 스포츠\n",
      "파죽지세 DB vs 18년 기다린 SK…전문가들도 백중세 스포츠\n",
      "아가메즈 33득점 우리카드 KB손해보험 완파…3위 굳 스포츠\n",
      "아시안게임 김학범호 최종상대 키르기스스탄 바레인과 2 스포츠\n",
      "AG 축구대표팀 감독 김학범 막중한 사명감…꼭 금메달 따 스포츠\n",
      "프로농구 FA 최진수·조성민 소속팀과 재계약…문태종 결렬 스포츠\n",
      "일본 스포츠청장관도 고교야구 투구수 제한 환영\n",
      "월드컵 네이마르·크로스 무릎 꿇린 멕시코 GK 오초아를 스포츠\n",
      "월드컵 패기의 황소 황희찬 준비 많이 했다…자신감 스포츠\n",
      "아시안게임 한국야구 중국 이기면 동률팀 규정으로도 결 스포츠\n",
      "혈연농구 논란 극복 못한 농구 대통령 허재 씁쓸한 퇴 스포츠\n",
      "이재영·루시아 쌍포김나희 맹공…흥국생명 GS칼텍스에 첫 스포츠\n",
      "아시안게임 응원석엔 하나된 함성 벤치엔 우정의 미소… 스포츠\n",
      "아시안게임 베트남전 앞둔 태극전사 부상 열외 없이  스포츠\n",
      "데상트 3대3 농구 2018 코리아 3X3 프리미어 리 스포츠\n",
      "연합뉴스 양지웅 기자 이달의 보도사진상 스포츠 액션 우수상 수상\n",
      "박용만 두산 회장 최태원 SK 회장에 KS 우승축하 기 스포츠\n",
      "월드컵 흥민아 한골만 멕시코전 앞둔 광화문 8천 스포츠\n",
      "아시안게임 3대3농구대표팀 집단 배탈 증세 선수촌  스포츠\n",
      "떠나는 구본능 전 KBO총재 외적 성장했으나 산업화 숙제 스포츠\n",
      "아시안게임 운명의 축구 한일 결승전…상기해야 할 20 스포츠\n",
      "다둥이 아빠 호날두 아빠 된다는 것 형언할 수 없는 스포츠\n",
      "NBC해설위원 마르티노 내년 2월 미 축구협회 회장선거에 스포츠\n",
      "실내 영업금지에 스포츠·레저업 소상공인 매출 반토막\n",
      "아시안게임 매너·세리머니…연이은 논란 겪은 황희찬 욕 스포츠\n",
      "아시안게임 수비수 이시영·정태욱 공격에서도 한 몫 해 스포츠\n",
      "이석수 미르·K스포츠재단 육영·일해재단과 비슷하다 생각\n",
      "아시안게임 개회식 기수 임영희 여자농구 단일팀 분위 스포츠\n",
      "이희용의 글로벌시대 프로야구 데뷔 60년 맞은 장훈의  스포츠\n",
      "75분 뛴 손흥민 결승골에 기여…토트넘 본머스 10 제 스포츠\n",
      "야수 최대어 렌던도 잭폿…LAA와 7년 2억4천500만달러 스포츠\n",
      "5년 만에 돌아온 여자농구 김소니아 더티 워크 맡겨만  스포츠\n",
      "월드컵 자신감 충만 멕시코 마지막 공식훈련도 유 스포츠\n",
      "영상 미국 스포츠 역대 최고계약은 메이웨더 여섯 경기 스포츠\n",
      "김연주 부활 3점포 5개…여자농구 신한은행 7연패 수 스포츠\n",
      "이재성 독일 2부 홀슈타인 킬로 이적…8월 5일 고별경기 스포츠\n",
      "아시안게임 승우·의조 골골골…한국 박항서 매직  스포츠\n",
      "아시안게임 김학범호 결승 한일전서 전반전 00 팽팽 스포츠\n",
      "전반기 40경기 포심 0개 송은범 후반기에는 다시  스포츠\n",
      "류현진 역사적인 MLB 올스타 선발 데뷔전서 1이닝 무실 스포츠\n",
      "현대자동차 모터스포츠 WTCR 종합우승WRC 준우승\n",
      "1위 자리 지킨 대한항공 박기원 감독 우리는 톱니바퀴 같 스포츠\n",
      "KIA 최근 10승 중 9승이 역전승…8회 이후 뒤집기승 스포츠\n",
      "류현진 단짝 러셀 마틴 NLDS 4차전 선발 제외…베테랑 스포츠\n",
      "아시안게임 이만수 부회장 라오스 1승하면 상의 탈의  스포츠\n",
      "MLB 투수 셔저의 쓴소리 투자 인색한 팀은 떠돌이 팬만 스포츠\n",
      "렛츠고 피싱 낚시는 스포츠다…배스의 재발견\n",
      "정치인 대신 스포츠스타…트럼프공화당전당대회 이색행사로\n",
      "KCC 반격 이끈 에밋 1차전 아쉬움 씻은 건 단장님 조 스포츠\n",
      "운명론 하승진·PO 단골 유재학 미디어데이 입담 스포츠\n",
      "산악영화제와 함께 열린 전국스포츠클라이밍대회\n",
      "U20월드컵 FIFA 우루과이·베네수엘라 주먹다짐 스포츠\n",
      "AG 금빛 지휘 김학범 성숙해진 손흥민·업그레이드된 황의 스포츠\n",
      "대한항공 OK저축은행 꺾고 컵대회 우승…MVP 비예나종 스포츠\n",
      "SK 로맥 인천상륙작전서 대포 두 방…문학서 뛰는 게  스포츠\n",
      "FC안양 정희웅 K리그2 18라운드 MVP…부천전서 1골 스포츠\n",
      "KIA 양현종 시즌 최다 피안타 악전고투 끝에 시즌 4승 스포츠\n",
      "월드컵 목발 치운 기성용·멍든 루디 훈련에 동행…벼 스포츠\n",
      "日스포츠계 뒤숭숭…도쿄올림픽 뇌물의혹 다케다 JOC회장 퇴임론\n",
      "2경기 만에 교체 kt 헤르난데즈…역대 기록은 한 경기 뛰 스포츠\n",
      "SK 정의윤 첫 선발…두산은 김재환 옆구리 부상으로 선발 스포츠\n",
      "왕성 식욕 에버턴 vs 지지부진 맨유…EPL 이적시 스포츠\n",
      "감독이 신뢰한 날 무너진 박정배…SK 마무리 플랜 B  스포츠\n",
      "여자축구 최강 현대제철 스포츠토토에 30 완승\n",
      "인권위 스포츠인권 현장조사…학교운동부 훈련실태 등 점검\n",
      "본점 폐쇄되면 스포츠…은행들 비상대응체계 가동\n",
      "2천319번째 안타 박용택 양준혁 넘어 개인 통산 안 스포츠\n",
      "U20월드컵 클린스만 진정한 우승후보 없어…그래서 재 스포츠\n",
      "호날두 챔피언스리그 APOEL전 출전 … 지단 레알 감독 스포츠\n",
      "신정락 1천356일 만에 선발 등판…류중일 감독 4일  스포츠\n",
      "전자랜드 역전승 이끈 유도훈 감독 한 마디 너네는 선수  스포츠\n",
      "프로축구 광주 이승모 의식 잃었다가 깨어나…목뼈 실금 부 스포츠\n",
      "승부조작 이태양 문우람 누명벗을 수 있게 재심해달라 스포츠\n",
      "아시안게임 야구대표팀 14안타에 잔루 13개…응집력은  스포츠\n",
      "울산 박정인·포항 김찬 등 15명 우선지명으로 내년 K리 스포츠\n",
      "NBA 댈러스 부세크 코치 선임…여성 코치 기용한 세 번 스포츠\n",
      "600블로킹 한송이 포지션 변경 싫었는데…새 직업 찾 스포츠\n",
      "SK 강지광 첫 1군 등판서 시속 155㎞…1이닝 2실점 스포츠\n"
     ]
    }
   ],
   "source": [
    "for i in dataset['title']:\n",
    "    if \"스포츠\" in i:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdb89171",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataset_val = train_test_split(dataset,test_size = 0.2,random_state = RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33b13e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_key, label_key, bert_tokenizer):\n",
    "        \n",
    "        self.sentences = [ bert_tokenizer(i,truncation=True,return_token_type_ids=False) for i in dataset[sent_key] ]\n",
    "        \n",
    "        if not label_key == None:\n",
    "            self.mode = \"train\"\n",
    "        else:\n",
    "            self.mode = \"test\"\n",
    "            \n",
    "        if self.mode == \"train\":\n",
    "            self.labels = [np.int64(i) for i in dataset[label_key]]\n",
    "        else:\n",
    "            self.labels = [np.int64(0) for i in dataset[sent_key]]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if self.mode == \"train\":\n",
    "            self.sentences[i][\"label\"] = self.labels[i]\n",
    "            return self.sentences[i]\n",
    "#             return ( self.sentences[i] , self.labels[i] )\n",
    "        else:\n",
    "            return self.sentences[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57a107bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = BERTDataset(dataset_train, \"title\", \"topic_idx\", tokenizer)\n",
    "data_val = BERTDataset(dataset_val, \"title\", \"topic_idx\", tokenizer)\n",
    "data_test = BERTDataset(test, \"title\", None, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "965f2103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels = 7\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9456a5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"glue\", \"qnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a5758a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4b4fd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name = \"accuracy\"\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"test-nli\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "797d847a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c80d551b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/klue/bert-base/resolve/main/config.json from cache at C:\\Users\\or7l0/.cache\\huggingface\\transformers\\fbd0b2ef898c4653902683fea8cc0dd99bf43f0e082645b913cda3b92429d1bb.7cee10e8ea7ffa278f8be4b141000263f2b18795e5ef5e025352b2af6851f8fb\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForPretraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/klue/bert-base/resolve/main/pytorch_model.bin from cache at C:\\Users\\or7l0/.cache\\huggingface\\transformers\\05b36ee62545d769939a7746eca739b844a40a7a7553700f110b58b28ed6a949.7cb231256a5dbe886e12b902d05cb1241f330d8c19428508f91b2b28c1cfe0b6\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=args,\n",
    "    train_dataset=data_train,\n",
    "    eval_dataset=data_val,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0b1d180",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-02 20:57:11,635]\u001b[0m A new study created in memory with name: no-name-d8c37bed-8fb2-4042-b345-b43a57476330\u001b[0m\n",
      "Trial:\n",
      "loading configuration file https://huggingface.co/klue/bert-base/resolve/main/config.json from cache at C:\\Users\\or7l0/.cache\\huggingface\\transformers\\fbd0b2ef898c4653902683fea8cc0dd99bf43f0e082645b913cda3b92429d1bb.7cee10e8ea7ffa278f8be4b141000263f2b18795e5ef5e025352b2af6851f8fb\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForPretraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/klue/bert-base/resolve/main/pytorch_model.bin from cache at C:\\Users\\or7l0/.cache\\huggingface\\transformers\\05b36ee62545d769939a7746eca739b844a40a7a7553700f110b58b28ed6a949.7cb231256a5dbe886e12b902d05cb1241f330d8c19428508f91b2b28c1cfe0b6\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 36523\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2284\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2284' max='2284' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2284/2284 06:54, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.478600</td>\n",
       "      <td>0.343172</td>\n",
       "      <td>0.885555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.281700</td>\n",
       "      <td>0.329987</td>\n",
       "      <td>0.887197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>0.330917</td>\n",
       "      <td>0.889169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.194700</td>\n",
       "      <td>0.342439</td>\n",
       "      <td>0.890373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test-nli\\run-0\\checkpoint-571\n",
      "Configuration saved in test-nli\\run-0\\checkpoint-571\\config.json\n",
      "Model weights saved in test-nli\\run-0\\checkpoint-571\\pytorch_model.bin\n",
      "tokenizer config file saved in test-nli\\run-0\\checkpoint-571\\tokenizer_config.json\n",
      "Special tokens file saved in test-nli\\run-0\\checkpoint-571\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test-nli\\run-0\\checkpoint-1142\n",
      "Configuration saved in test-nli\\run-0\\checkpoint-1142\\config.json\n",
      "Model weights saved in test-nli\\run-0\\checkpoint-1142\\pytorch_model.bin\n",
      "tokenizer config file saved in test-nli\\run-0\\checkpoint-1142\\tokenizer_config.json\n",
      "Special tokens file saved in test-nli\\run-0\\checkpoint-1142\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test-nli\\run-0\\checkpoint-1713\n",
      "Configuration saved in test-nli\\run-0\\checkpoint-1713\\config.json\n",
      "Model weights saved in test-nli\\run-0\\checkpoint-1713\\pytorch_model.bin\n",
      "tokenizer config file saved in test-nli\\run-0\\checkpoint-1713\\tokenizer_config.json\n",
      "Special tokens file saved in test-nli\\run-0\\checkpoint-1713\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test-nli\\run-0\\checkpoint-2284\n",
      "Configuration saved in test-nli\\run-0\\checkpoint-2284\\config.json\n",
      "Model weights saved in test-nli\\run-0\\checkpoint-2284\\pytorch_model.bin\n",
      "tokenizer config file saved in test-nli\\run-0\\checkpoint-2284\\tokenizer_config.json\n",
      "Special tokens file saved in test-nli\\run-0\\checkpoint-2284\\special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from test-nli\\run-0\\checkpoint-2284 (score: 0.8903734530719527).\n",
      "\u001b[32m[I 2021-08-02 21:04:09,008]\u001b[0m Trial 0 finished with value: 0.8903734530719527 and parameters: {'learning_rate': 1.7557178174533417e-05, 'num_train_epochs': 4, 'seed': 15, 'per_device_train_batch_size': 64}. Best is trial 0 with value: 0.8903734530719527.\u001b[0m\n",
      "Trial:\n",
      "loading configuration file https://huggingface.co/klue/bert-base/resolve/main/config.json from cache at C:\\Users\\or7l0/.cache\\huggingface\\transformers\\fbd0b2ef898c4653902683fea8cc0dd99bf43f0e082645b913cda3b92429d1bb.7cee10e8ea7ffa278f8be4b141000263f2b18795e5ef5e025352b2af6851f8fb\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForPretraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/klue/bert-base/resolve/main/pytorch_model.bin from cache at C:\\Users\\or7l0/.cache\\huggingface\\transformers\\05b36ee62545d769939a7746eca739b844a40a7a7553700f110b58b28ed6a949.7cb231256a5dbe886e12b902d05cb1241f330d8c19428508f91b2b28c1cfe0b6\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 36523\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 45655\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45655' max='45655' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45655/45655 45:21, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.486600</td>\n",
       "      <td>0.536607</td>\n",
       "      <td>0.878874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.431500</td>\n",
       "      <td>0.560367</td>\n",
       "      <td>0.883145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.264200</td>\n",
       "      <td>0.696654</td>\n",
       "      <td>0.878765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.151400</td>\n",
       "      <td>0.780365</td>\n",
       "      <td>0.879641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.073700</td>\n",
       "      <td>0.916854</td>\n",
       "      <td>0.875589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test-nli\\run-1\\checkpoint-9131\n",
      "Configuration saved in test-nli\\run-1\\checkpoint-9131\\config.json\n",
      "Model weights saved in test-nli\\run-1\\checkpoint-9131\\pytorch_model.bin\n",
      "tokenizer config file saved in test-nli\\run-1\\checkpoint-9131\\tokenizer_config.json\n",
      "Special tokens file saved in test-nli\\run-1\\checkpoint-9131\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test-nli\\run-1\\checkpoint-18262\n",
      "Configuration saved in test-nli\\run-1\\checkpoint-18262\\config.json\n",
      "Model weights saved in test-nli\\run-1\\checkpoint-18262\\pytorch_model.bin\n",
      "tokenizer config file saved in test-nli\\run-1\\checkpoint-18262\\tokenizer_config.json\n",
      "Special tokens file saved in test-nli\\run-1\\checkpoint-18262\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test-nli\\run-1\\checkpoint-27393\n",
      "Configuration saved in test-nli\\run-1\\checkpoint-27393\\config.json\n",
      "Model weights saved in test-nli\\run-1\\checkpoint-27393\\pytorch_model.bin\n",
      "tokenizer config file saved in test-nli\\run-1\\checkpoint-27393\\tokenizer_config.json\n",
      "Special tokens file saved in test-nli\\run-1\\checkpoint-27393\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test-nli\\run-1\\checkpoint-36524\n",
      "Configuration saved in test-nli\\run-1\\checkpoint-36524\\config.json\n",
      "Model weights saved in test-nli\\run-1\\checkpoint-36524\\pytorch_model.bin\n",
      "tokenizer config file saved in test-nli\\run-1\\checkpoint-36524\\tokenizer_config.json\n",
      "Special tokens file saved in test-nli\\run-1\\checkpoint-36524\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test-nli\\run-1\\checkpoint-45655\n",
      "Configuration saved in test-nli\\run-1\\checkpoint-45655\\config.json\n",
      "Model weights saved in test-nli\\run-1\\checkpoint-45655\\pytorch_model.bin\n",
      "tokenizer config file saved in test-nli\\run-1\\checkpoint-45655\\tokenizer_config.json\n",
      "Special tokens file saved in test-nli\\run-1\\checkpoint-45655\\special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from test-nli\\run-1\\checkpoint-18262 (score: 0.8831453290986748).\n",
      "\u001b[32m[I 2021-08-02 21:49:33,453]\u001b[0m Trial 1 finished with value: 0.8755886540357025 and parameters: {'learning_rate': 2.380894925329773e-05, 'num_train_epochs': 5, 'seed': 12, 'per_device_train_batch_size': 4}. Best is trial 0 with value: 0.8903734530719527.\u001b[0m\n",
      "Trial:\n",
      "loading configuration file https://huggingface.co/klue/bert-base/resolve/main/config.json from cache at C:\\Users\\or7l0/.cache\\huggingface\\transformers\\fbd0b2ef898c4653902683fea8cc0dd99bf43f0e082645b913cda3b92429d1bb.7cee10e8ea7ffa278f8be4b141000263f2b18795e5ef5e025352b2af6851f8fb\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForPretraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/klue/bert-base/resolve/main/pytorch_model.bin from cache at C:\\Users\\or7l0/.cache\\huggingface\\transformers\\05b36ee62545d769939a7746eca739b844a40a7a7553700f110b58b28ed6a949.7cb231256a5dbe886e12b902d05cb1241f330d8c19428508f91b2b28c1cfe0b6\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 36523\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11415\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11415' max='11415' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11415/11415 14:15, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.374200</td>\n",
       "      <td>0.346169</td>\n",
       "      <td>0.889826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.345256</td>\n",
       "      <td>0.888183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.260800</td>\n",
       "      <td>0.358340</td>\n",
       "      <td>0.889059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.224900</td>\n",
       "      <td>0.383639</td>\n",
       "      <td>0.890702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.183700</td>\n",
       "      <td>0.392091</td>\n",
       "      <td>0.889716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test-nli\\run-2\\checkpoint-2283\n",
      "Configuration saved in test-nli\\run-2\\checkpoint-2283\\config.json\n",
      "Model weights saved in test-nli\\run-2\\checkpoint-2283\\pytorch_model.bin\n",
      "tokenizer config file saved in test-nli\\run-2\\checkpoint-2283\\tokenizer_config.json\n",
      "Special tokens file saved in test-nli\\run-2\\checkpoint-2283\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test-nli\\run-2\\checkpoint-4566\n",
      "Configuration saved in test-nli\\run-2\\checkpoint-4566\\config.json\n",
      "Model weights saved in test-nli\\run-2\\checkpoint-4566\\pytorch_model.bin\n",
      "tokenizer config file saved in test-nli\\run-2\\checkpoint-4566\\tokenizer_config.json\n",
      "Special tokens file saved in test-nli\\run-2\\checkpoint-4566\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test-nli\\run-2\\checkpoint-6849\n",
      "Configuration saved in test-nli\\run-2\\checkpoint-6849\\config.json\n",
      "Model weights saved in test-nli\\run-2\\checkpoint-6849\\pytorch_model.bin\n",
      "tokenizer config file saved in test-nli\\run-2\\checkpoint-6849\\tokenizer_config.json\n",
      "Special tokens file saved in test-nli\\run-2\\checkpoint-6849\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test-nli\\run-2\\checkpoint-9132\n",
      "Configuration saved in test-nli\\run-2\\checkpoint-9132\\config.json\n",
      "Model weights saved in test-nli\\run-2\\checkpoint-9132\\pytorch_model.bin\n",
      "tokenizer config file saved in test-nli\\run-2\\checkpoint-9132\\tokenizer_config.json\n",
      "Special tokens file saved in test-nli\\run-2\\checkpoint-9132\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test-nli\\run-2\\checkpoint-11415\n",
      "Configuration saved in test-nli\\run-2\\checkpoint-11415\\config.json\n",
      "Model weights saved in test-nli\\run-2\\checkpoint-11415\\pytorch_model.bin\n",
      "tokenizer config file saved in test-nli\\run-2\\checkpoint-11415\\tokenizer_config.json\n",
      "Special tokens file saved in test-nli\\run-2\\checkpoint-11415\\special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from test-nli\\run-2\\checkpoint-9132 (score: 0.8907020041616471).\n",
      "\u001b[32m[I 2021-08-02 22:03:51,433]\u001b[0m Trial 2 finished with value: 0.8897163508925638 and parameters: {'learning_rate': 6.178202300127894e-06, 'num_train_epochs': 5, 'seed': 24, 'per_device_train_batch_size': 16}. Best is trial 0 with value: 0.8903734530719527.\u001b[0m\n",
      "Trial:\n",
      "loading configuration file https://huggingface.co/klue/bert-base/resolve/main/config.json from cache at C:\\Users\\or7l0/.cache\\huggingface\\transformers\\fbd0b2ef898c4653902683fea8cc0dd99bf43f0e082645b913cda3b92429d1bb.7cee10e8ea7ffa278f8be4b141000263f2b18795e5ef5e025352b2af6851f8fb\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForPretraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/klue/bert-base/resolve/main/pytorch_model.bin from cache at C:\\Users\\or7l0/.cache\\huggingface\\transformers\\05b36ee62545d769939a7746eca739b844a40a7a7553700f110b58b28ed6a949.7cb231256a5dbe886e12b902d05cb1241f330d8c19428508f91b2b28c1cfe0b6\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 36523\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5710\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5710' max='5710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5710/5710 10:03, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.366000</td>\n",
       "      <td>0.348841</td>\n",
       "      <td>0.878765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.245400</td>\n",
       "      <td>0.358874</td>\n",
       "      <td>0.881612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.144100</td>\n",
       "      <td>0.450891</td>\n",
       "      <td>0.876684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>0.588864</td>\n",
       "      <td>0.876903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>0.689786</td>\n",
       "      <td>0.875041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test-nli\\run-3\\checkpoint-1142\n",
      "Configuration saved in test-nli\\run-3\\checkpoint-1142\\config.json\n",
      "Model weights saved in test-nli\\run-3\\checkpoint-1142\\pytorch_model.bin\n",
      "tokenizer config file saved in test-nli\\run-3\\checkpoint-1142\\tokenizer_config.json\n",
      "Special tokens file saved in test-nli\\run-3\\checkpoint-1142\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test-nli\\run-3\\checkpoint-2284\n",
      "Configuration saved in test-nli\\run-3\\checkpoint-2284\\config.json\n",
      "Model weights saved in test-nli\\run-3\\checkpoint-2284\\pytorch_model.bin\n",
      "tokenizer config file saved in test-nli\\run-3\\checkpoint-2284\\tokenizer_config.json\n",
      "Special tokens file saved in test-nli\\run-3\\checkpoint-2284\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test-nli\\run-3\\checkpoint-3426\n",
      "Configuration saved in test-nli\\run-3\\checkpoint-3426\\config.json\n",
      "Model weights saved in test-nli\\run-3\\checkpoint-3426\\pytorch_model.bin\n",
      "tokenizer config file saved in test-nli\\run-3\\checkpoint-3426\\tokenizer_config.json\n",
      "Special tokens file saved in test-nli\\run-3\\checkpoint-3426\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test-nli\\run-3\\checkpoint-4568\n",
      "Configuration saved in test-nli\\run-3\\checkpoint-4568\\config.json\n",
      "Model weights saved in test-nli\\run-3\\checkpoint-4568\\pytorch_model.bin\n",
      "tokenizer config file saved in test-nli\\run-3\\checkpoint-4568\\tokenizer_config.json\n",
      "Special tokens file saved in test-nli\\run-3\\checkpoint-4568\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test-nli\\run-3\\checkpoint-5710\n",
      "Configuration saved in test-nli\\run-3\\checkpoint-5710\\config.json\n",
      "Model weights saved in test-nli\\run-3\\checkpoint-5710\\pytorch_model.bin\n",
      "tokenizer config file saved in test-nli\\run-3\\checkpoint-5710\\tokenizer_config.json\n",
      "Special tokens file saved in test-nli\\run-3\\checkpoint-5710\\special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from test-nli\\run-3\\checkpoint-2284 (score: 0.8816120906801007).\n",
      "\u001b[32m[I 2021-08-02 22:13:57,606]\u001b[0m Trial 3 finished with value: 0.8750410688862118 and parameters: {'learning_rate': 5.105881530714971e-05, 'num_train_epochs': 5, 'seed': 1, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 0.8903734530719527.\u001b[0m\n",
      "Trial:\n",
      "loading configuration file https://huggingface.co/klue/bert-base/resolve/main/config.json from cache at C:\\Users\\or7l0/.cache\\huggingface\\transformers\\fbd0b2ef898c4653902683fea8cc0dd99bf43f0e082645b913cda3b92429d1bb.7cee10e8ea7ffa278f8be4b141000263f2b18795e5ef5e025352b2af6851f8fb\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForPretraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/klue/bert-base/resolve/main/pytorch_model.bin from cache at C:\\Users\\or7l0/.cache\\huggingface\\transformers\\05b36ee62545d769939a7746eca739b844a40a7a7553700f110b58b28ed6a949.7cb231256a5dbe886e12b902d05cb1241f330d8c19428508f91b2b28c1cfe0b6\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 36523\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3426\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3426' max='3426' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3426/3426 06:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.349800</td>\n",
       "      <td>0.338850</td>\n",
       "      <td>0.887526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.284200</td>\n",
       "      <td>0.334596</td>\n",
       "      <td>0.887636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.234300</td>\n",
       "      <td>0.330192</td>\n",
       "      <td>0.892345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test-nli\\run-4\\checkpoint-1142\n",
      "Configuration saved in test-nli\\run-4\\checkpoint-1142\\config.json\n",
      "Model weights saved in test-nli\\run-4\\checkpoint-1142\\pytorch_model.bin\n",
      "tokenizer config file saved in test-nli\\run-4\\checkpoint-1142\\tokenizer_config.json\n",
      "Special tokens file saved in test-nli\\run-4\\checkpoint-1142\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test-nli\\run-4\\checkpoint-2284\n",
      "Configuration saved in test-nli\\run-4\\checkpoint-2284\\config.json\n",
      "Model weights saved in test-nli\\run-4\\checkpoint-2284\\pytorch_model.bin\n",
      "tokenizer config file saved in test-nli\\run-4\\checkpoint-2284\\tokenizer_config.json\n",
      "Special tokens file saved in test-nli\\run-4\\checkpoint-2284\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test-nli\\run-4\\checkpoint-3426\n",
      "Configuration saved in test-nli\\run-4\\checkpoint-3426\\config.json\n",
      "Model weights saved in test-nli\\run-4\\checkpoint-3426\\pytorch_model.bin\n",
      "tokenizer config file saved in test-nli\\run-4\\checkpoint-3426\\tokenizer_config.json\n",
      "Special tokens file saved in test-nli\\run-4\\checkpoint-3426\\special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from test-nli\\run-4\\checkpoint-3426 (score: 0.8923447596101194).\n",
      "\u001b[32m[I 2021-08-02 22:20:04,462]\u001b[0m Trial 4 finished with value: 0.8923447596101194 and parameters: {'learning_rate': 1.155244705586811e-05, 'num_train_epochs': 3, 'seed': 26, 'per_device_train_batch_size': 32}. Best is trial 4 with value: 0.8923447596101194.\u001b[0m\n",
      "Trial:\n",
      "loading configuration file https://huggingface.co/klue/bert-base/resolve/main/config.json from cache at C:\\Users\\or7l0/.cache\\huggingface\\transformers\\fbd0b2ef898c4653902683fea8cc0dd99bf43f0e082645b913cda3b92429d1bb.7cee10e8ea7ffa278f8be4b141000263f2b18795e5ef5e025352b2af6851f8fb\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForPretraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/klue/bert-base/resolve/main/pytorch_model.bin from cache at C:\\Users\\or7l0/.cache\\huggingface\\transformers\\05b36ee62545d769939a7746eca739b844a40a7a7553700f110b58b28ed6a949.7cb231256a5dbe886e12b902d05cb1241f330d8c19428508f91b2b28c1cfe0b6\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 36523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 571\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='571' max='571' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [571/571 01:42, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.489000</td>\n",
       "      <td>0.343016</td>\n",
       "      <td>0.887416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test-nli\\run-5\\checkpoint-571\n",
      "Configuration saved in test-nli\\run-5\\checkpoint-571\\config.json\n",
      "Model weights saved in test-nli\\run-5\\checkpoint-571\\pytorch_model.bin\n",
      "tokenizer config file saved in test-nli\\run-5\\checkpoint-571\\tokenizer_config.json\n",
      "Special tokens file saved in test-nli\\run-5\\checkpoint-571\\special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from test-nli\\run-5\\checkpoint-571 (score: 0.8874164932647026).\n",
      "\u001b[32m[I 2021-08-02 22:21:50,091]\u001b[0m Trial 5 finished with value: 0.8874164932647026 and parameters: {'learning_rate': 1.4501420971229825e-05, 'num_train_epochs': 1, 'seed': 28, 'per_device_train_batch_size': 64}. Best is trial 4 with value: 0.8923447596101194.\u001b[0m\n",
      "Trial:\n",
      "loading configuration file https://huggingface.co/klue/bert-base/resolve/main/config.json from cache at C:\\Users\\or7l0/.cache\\huggingface\\transformers\\fbd0b2ef898c4653902683fea8cc0dd99bf43f0e082645b913cda3b92429d1bb.7cee10e8ea7ffa278f8be4b141000263f2b18795e5ef5e025352b2af6851f8fb\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForPretraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/klue/bert-base/resolve/main/pytorch_model.bin from cache at C:\\Users\\or7l0/.cache\\huggingface\\transformers\\05b36ee62545d769939a7746eca739b844a40a7a7553700f110b58b28ed6a949.7cb231256a5dbe886e12b902d05cb1241f330d8c19428508f91b2b28c1cfe0b6\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 36523\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18264\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13699' max='18264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13697/18264 14:08 < 04:43, 16.14 it/s, Epoch 3.00/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.390700</td>\n",
       "      <td>0.386583</td>\n",
       "      <td>0.887855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.335400</td>\n",
       "      <td>0.414767</td>\n",
       "      <td>0.888512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.248000</td>\n",
       "      <td>0.467206</td>\n",
       "      <td>0.888840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test-nli\\run-6\\checkpoint-4566\n",
      "Configuration saved in test-nli\\run-6\\checkpoint-4566\\config.json\n",
      "Model weights saved in test-nli\\run-6\\checkpoint-4566\\pytorch_model.bin\n",
      "tokenizer config file saved in test-nli\\run-6\\checkpoint-4566\\tokenizer_config.json\n",
      "Special tokens file saved in test-nli\\run-6\\checkpoint-4566\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test-nli\\run-6\\checkpoint-9132\n",
      "Configuration saved in test-nli\\run-6\\checkpoint-9132\\config.json\n",
      "Model weights saved in test-nli\\run-6\\checkpoint-9132\\pytorch_model.bin\n",
      "tokenizer config file saved in test-nli\\run-6\\checkpoint-9132\\tokenizer_config.json\n",
      "Special tokens file saved in test-nli\\run-6\\checkpoint-9132\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "\u001b[32m[I 2021-08-02 22:36:09,074]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "Trial:\n",
      "loading configuration file https://huggingface.co/klue/bert-base/resolve/main/config.json from cache at C:\\Users\\or7l0/.cache\\huggingface\\transformers\\fbd0b2ef898c4653902683fea8cc0dd99bf43f0e082645b913cda3b92429d1bb.7cee10e8ea7ffa278f8be4b141000263f2b18795e5ef5e025352b2af6851f8fb\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForPretraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/klue/bert-base/resolve/main/pytorch_model.bin from cache at C:\\Users\\or7l0/.cache\\huggingface\\transformers\\05b36ee62545d769939a7746eca739b844a40a7a7553700f110b58b28ed6a949.7cb231256a5dbe886e12b902d05cb1241f330d8c19428508f91b2b28c1cfe0b6\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 36523\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36524\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9132' max='36524' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 9130/36524 09:00 < 27:01, 16.89 it/s, Epoch 1.00/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.511300</td>\n",
       "      <td>0.500885</td>\n",
       "      <td>0.884240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "\u001b[32m[I 2021-08-02 22:45:19,586]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "Trial:\n",
      "loading configuration file https://huggingface.co/klue/bert-base/resolve/main/config.json from cache at C:\\Users\\or7l0/.cache\\huggingface\\transformers\\fbd0b2ef898c4653902683fea8cc0dd99bf43f0e082645b913cda3b92429d1bb.7cee10e8ea7ffa278f8be4b141000263f2b18795e5ef5e025352b2af6851f8fb\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForPretraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/klue/bert-base/resolve/main/pytorch_model.bin from cache at C:\\Users\\or7l0/.cache\\huggingface\\transformers\\05b36ee62545d769939a7746eca739b844a40a7a7553700f110b58b28ed6a949.7cb231256a5dbe886e12b902d05cb1241f330d8c19428508f91b2b28c1cfe0b6\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 36523\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1713\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='572' max='1713' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 572/1713 01:30 < 03:01, 6.28 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.423800</td>\n",
       "      <td>0.338109</td>\n",
       "      <td>0.883036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "\u001b[32m[I 2021-08-02 22:47:00,544]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "Trial:\n",
      "loading configuration file https://huggingface.co/klue/bert-base/resolve/main/config.json from cache at C:\\Users\\or7l0/.cache\\huggingface\\transformers\\fbd0b2ef898c4653902683fea8cc0dd99bf43f0e082645b913cda3b92429d1bb.7cee10e8ea7ffa278f8be4b141000263f2b18795e5ef5e025352b2af6851f8fb\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForPretraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/klue/bert-base/resolve/main/pytorch_model.bin from cache at C:\\Users\\or7l0/.cache\\huggingface\\transformers\\05b36ee62545d769939a7746eca739b844a40a7a7553700f110b58b28ed6a949.7cb231256a5dbe886e12b902d05cb1241f330d8c19428508f91b2b28c1cfe0b6\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 36523\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2284' max='9132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2283/9132 02:39 < 07:59, 14.28 it/s, Epoch 1.00/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.362700</td>\n",
       "      <td>0.350852</td>\n",
       "      <td>0.884788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "\u001b[32m[I 2021-08-02 22:49:50,361]\u001b[0m Trial 9 pruned. \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "best_run = trainer.hyperparameter_search(n_trials=10, direction=\"maximize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58e4aa55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BestRun(run_id='4', objective=0.8923447596101194, hyperparameters={'learning_rate': 1.155244705586811e-05, 'num_train_epochs': 3, 'seed': 26, 'per_device_train_batch_size': 32})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d412605f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/klue/bert-base/resolve/main/config.json from cache at C:\\Users\\or7l0/.cache\\huggingface\\transformers\\fbd0b2ef898c4653902683fea8cc0dd99bf43f0e082645b913cda3b92429d1bb.7cee10e8ea7ffa278f8be4b141000263f2b18795e5ef5e025352b2af6851f8fb\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForPretraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/klue/bert-base/resolve/main/pytorch_model.bin from cache at C:\\Users\\or7l0/.cache\\huggingface\\transformers\\05b36ee62545d769939a7746eca739b844a40a7a7553700f110b58b28ed6a949.7cb231256a5dbe886e12b902d05cb1241f330d8c19428508f91b2b28c1cfe0b6\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 36523\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3426\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3426' max='3426' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3426/3426 06:07, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.349800</td>\n",
       "      <td>0.338850</td>\n",
       "      <td>0.887526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.284200</td>\n",
       "      <td>0.334596</td>\n",
       "      <td>0.887636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.234300</td>\n",
       "      <td>0.330192</td>\n",
       "      <td>0.892345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test-nli\\checkpoint-1142\n",
      "Configuration saved in test-nli\\checkpoint-1142\\config.json\n",
      "Model weights saved in test-nli\\checkpoint-1142\\pytorch_model.bin\n",
      "tokenizer config file saved in test-nli\\checkpoint-1142\\tokenizer_config.json\n",
      "Special tokens file saved in test-nli\\checkpoint-1142\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test-nli\\checkpoint-2284\n",
      "Configuration saved in test-nli\\checkpoint-2284\\config.json\n",
      "Model weights saved in test-nli\\checkpoint-2284\\pytorch_model.bin\n",
      "tokenizer config file saved in test-nli\\checkpoint-2284\\tokenizer_config.json\n",
      "Special tokens file saved in test-nli\\checkpoint-2284\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test-nli\\checkpoint-3426\n",
      "Configuration saved in test-nli\\checkpoint-3426\\config.json\n",
      "Model weights saved in test-nli\\checkpoint-3426\\pytorch_model.bin\n",
      "tokenizer config file saved in test-nli\\checkpoint-3426\\tokenizer_config.json\n",
      "Special tokens file saved in test-nli\\checkpoint-3426\\special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from test-nli\\checkpoint-3426 (score: 0.8923447596101194).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3426, training_loss=0.3176889391719286, metrics={'train_runtime': 367.9209, 'train_samples_per_second': 297.806, 'train_steps_per_second': 9.312, 'total_flos': 1644324533546112.0, 'train_loss': 0.3176889391719286, 'epoch': 3.0})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for n, v in best_run.hyperparameters.items():\n",
    "    setattr(trainer.args, n, v)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e704194",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='572' max='286' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [286/286 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3301921486854553,\n",
       " 'eval_accuracy': 0.8923447596101194,\n",
       " 'eval_runtime': 7.7326,\n",
       " 'eval_samples_per_second': 1180.839,\n",
       " 'eval_steps_per_second': 36.986,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc8f3feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 9131\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "pred = trainer.predict(data_test)\n",
    "pred = pred[0]\n",
    "pred = np.argmax(pred,1)\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "submission['topic_idx'] = pred\n",
    "submission.to_csv(\"results/klue-bert-hyperparameter-tuning-with-preprocessing-0803.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb785bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
